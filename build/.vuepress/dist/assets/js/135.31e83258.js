(window.webpackJsonp=window.webpackJsonp||[]).push([[135],{516:function(s,e,t){"use strict";t.r(e);var a=t(13),i=Object(a.a)({},(function(){var s=this,e=s.$createElement,t=s._self._c||e;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("h3",{attrs:{id:"redis的底层数据结构"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#redis的底层数据结构"}},[s._v("#")]),s._v(" redis的底层数据结构")]),s._v(" "),t("p",[s._v("原文地址：https://juejin.im/post/5cff17f3f265da1b7a4b69f9")]),s._v(" "),t("p",[s._v("总体图：")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://txxs.github.io/pic/tofutureinterview/1-5.png",alt:"1"}})]),s._v(" "),t("h4",{attrs:{id:"string字符串"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#string字符串"}},[s._v("#")]),s._v(" string字符串")]),s._v(" "),t("p",[s._v("字符串类型是redis最常用的数据类型，在Redis中，字符串是可以修改的，在底层它是以字节数组的形式存在的。Redis中的字符串被称为简单动态字符串「SDS」，这种结构很像Java中的ArrayList，其长度是动态可变的.")]),s._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v("struct SDS<T> {\n  T capacity; // 数组容量\n  T len; // 数组长度\n  byte[] content; // 数组内容\n}\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br")])]),t("h4",{attrs:{id:"list"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#list"}},[s._v("#")]),s._v(" List")]),s._v(" "),t("p",[s._v("Redis中List对象的底层是由quicklist(快速列表)实现的，快速列表支持从链表头和尾添加元素，并且可以获取指定位置的元素内容。那么，快速列表的底层是如何实现的呢？为什么能够达到如此快的性能？罗马不是一日建成的，quicklist也不是一日实现的，起初redis的list的底层是ziplist（压缩列表）或者是  linkedlist（双端列表）。")]),s._v(" "),t("p",[s._v("ziplist 压缩列表:当一个列表中只包含少量列表项，且是小整数值或长度比较短的字符串时，redis就使用ziplist（压缩列表）来做列表键的底层实现。压缩列表顾名思义是进行了压缩，每一个节点之间没有指针的指向，而是多个元素相邻，没有缝隙。所以 ziplist是Redis为了节约内存而开发的，是由一系列特殊编码的连续内存块组成的顺序型数据结构。")]),s._v(" "),t("p",[s._v("双端列表（linkedlist）:双端列表大家都很熟悉，这里的双端列表和java中的linkedlist很类似。双端链表有以下特性：节点带有prev、next指针、head指针和tail指针，获取前置节点、后置节点、表头节点和表尾节点、获取长度的复杂度都是O(1)。")]),s._v(" "),t("p",[s._v("压缩列表占用内存少，但是是顺序型的数据结构，插入删除元素的操作比较复杂，所以压缩列表适合数据比较小的情况，当数据比较多的时候，双端列表的高效插入删除还是更好的选择.在Redis开发者的眼中，数据结构的选择，时间上、空间上都要达到极致，所以，他们将压缩列表和双端列表合二为一，创建了快速列表（quicklist）。和java中的hashmap一样，结合了数组和链表的优点。")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://txxs.github.io/pic/tofutureinterview/1-6.png",alt:"1"}})]),s._v(" "),t("p",[s._v("quicklist 默认的压缩深度是 0，也就是不压缩。压缩的实际深度由配置参数list-compress-depth决定。为了支持快速的 push/pop 操作，quicklist 的首尾两个 ziplist 不压缩，此时深度就是 1。如果深度为 2，表示 quicklist 的首尾第一个 ziplist 以及首尾第二个 ziplist 都不压缩。")]),s._v(" "),t("h4",{attrs:{id:"hash"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hash"}},[s._v("#")]),s._v(" Hash")]),s._v(" "),t("p",[s._v("Hash数据类型的底层实现是ziplist（压缩列表）或字典（也称为hashtable或散列表）。这里压缩列表或者字典的选择，也是根据元素的数量大小决定的。每个值的字节数不超过64的时候，默认使用的数据结构是ziplist。当我们加入了字节数超过64的值的数据时，默认的数据结构已经成为了hashtable。Hash对象只有同时满足下面两个条件时，才会使用ziplist（压缩列表）：")]),s._v(" "),t("ul",[t("li",[s._v("哈希中元素数量小于512个；")]),s._v(" "),t("li",[s._v("哈希中所有键值对的键和值字符串长度都小于64字节。")])]),s._v(" "),t("p",[s._v("redis中的dict 结构内部包含两个 hashtable，通常情况下只有一个 hashtable 是有值的。但是在 dict 扩容缩容时，需要分配新的 hashtable，然后进行渐进式搬迁，这时两个 hashtable 存储的分别是旧的 hashtable 和新的 hashtable。待搬迁结束后，旧的 hashtable 被删除，新的 hashtable 取而代之。")]),s._v(" "),t("h3",{attrs:{id:"set"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#set"}},[s._v("#")]),s._v(" Set")]),s._v(" "),t("p",[s._v("Set数据类型的底层可以是intset(整数集)或者是hashtable(散列表也叫哈希表)。当数据都是整数并且数量不多时，使用intset作为底层数据结构；当有除整数以外的数据或者数据量增多时，使用hashtable作为底层数据结构。intset底层实现为有序、无重复数的数组。 intset的整数类型可以是16位的、32位的、64位的。如果数组里所有的整数都是16位长度的，新加入一个32位的整数，那么整个16的数组将升级成一个32位的数组。升级可以提升intset的灵活性，又可以节约内存，但不可逆。")]),s._v(" "),t("h4",{attrs:{id:"zset-最重要"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#zset-最重要"}},[s._v("#")]),s._v(" Zset(最重要)")]),s._v(" "),t("p",[s._v("Redis中的Zset，也叫做有序集合。它的底层是ziplist（压缩列表）或skiplist（跳跃表）。压缩列表前文已经介绍过了，同理是在元素数量比较少的时候使用。此处主要介绍跳跃列表。")]),s._v(" "),t("p",[s._v("原文地址：https://blog.csdn.net/weixin_38008100/article/details/94629753")]),s._v(" "),t("p",[s._v("先来看一个有序链表，如下图（最左侧的灰色节点表示一个空的头结点）：")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://txxs.github.io/pic/tofutureinterview/1-7.png",alt:"1"}})]),s._v(" "),t("p",[s._v("假如我们每相邻两个节点增加一个指针，让指针指向下下个节点，如下图：")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://txxs.github.io/pic/tofutureinterview/1-8.png",alt:"1"}})]),s._v(" "),t("p",[s._v("这样所有新增加的指针连成了一个新的链表，但它包含的节点个数只有原来的一半（上图中是7, 19, 26）。现在当我们想查找数据的时候，可以先沿着这个新链表进行查找。当碰到比待查数据大的节点时，再回到原来的链表中进行查找。比如，我们想查找23，查找的路径是沿着下图中标红的指针所指向的方向进行的：")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://txxs.github.io/pic/tofutureinterview/1-9.png",alt:"1"}})]),s._v(" "),t("ul",[t("li",[s._v("23首先和7比较，再和19比较，比它们都大，继续向后比较。")]),s._v(" "),t("li",[s._v("但23和26比较的时候，比26要小，因此回到下面的链表（原链表），与22比较。")]),s._v(" "),t("li",[s._v("23比22要大，沿下面的指针继续向后和26比较。23比26小，说明待查数据23在原链表中不存在，而且它的插入位置应该在22和26之间。")])]),s._v(" "),t("p",[s._v("skiplist正是受这种多层链表的想法的启发而设计出来的。实际上，按照上面生成链表的方式，上面每一层链表的节点个数，是下面一层的节点个数的一半，这样查找过程就非常类似于一个二分查找，使得查找的时间复杂度可以降低到O(log n)。但是，这种方法在插入数据的时候有很大的问题。新插入一个节点之后，就会打乱上下相邻两层链表上节点个数严格的2:1的对应关系。如果要维持这种对应关系，就必须把新插入的节点后面的所有节点（也包括新插入的节点）重新进行调整，这会让时间复杂度重新蜕化成O(n)。删除数据也有同样的问题。skiplist为了避免这一问题，它不要求上下相邻两层链表之间的节点个数有严格的对应关系，而是为每个节点随机出一个层数(level)。比如，一个节点随机出的层数是3，那么就把它链入到第1层到第3层这三层链表中。为了表达清楚，下图展示了如何通过一步步的插入操作从而形成一个skiplist的过程：\n"),t("img",{attrs:{src:"https://txxs.github.io/pic/tofutureinterview/1-10.png",alt:"1"}})]),s._v(" "),t("h3",{attrs:{id:"redis支持的数据结构有哪些"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#redis支持的数据结构有哪些"}},[s._v("#")]),s._v(" Redis支持的数据结构有哪些？")]),s._v(" "),t("p",[s._v('整数类型\tREDIS_ENCODING_INT\t"int"')]),s._v(" "),t("p",[s._v('embstr字符串类型\tREDIS_ENCODING_EMBSTR\t"embstr"')]),s._v(" "),t("p",[s._v('简单动态字符串\tREDIS_ENCODING_RAW\t"raw"')]),s._v(" "),t("p",[s._v('字典类型\tREDIS_ENCODING_HT\t"hashtable"')]),s._v(" "),t("p",[s._v('双端链表\tREDIS_ENCODING_LINKEDLIST\t"linkedlist"')]),s._v(" "),t("p",[s._v('压缩列表\tREDIS_ENCODING_ZIPLIST\t"ziplist"')]),s._v(" "),t("p",[s._v('整数集合\tREDIS_ENCODING_INTSET\t"intset"')]),s._v(" "),t("p",[s._v('跳表和字典\tREDIS_ENCODING_SKIPLIST\t"skiplist"')]),s._v(" "),t("h3",{attrs:{id:"redis的数据类型有哪些"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#redis的数据类型有哪些"}},[s._v("#")]),s._v(" redis的数据类型有哪些？")]),s._v(" "),t("p",[s._v("String、list、hash、set、zet注意和上边题目的区分")]),s._v(" "),t("p",[s._v("发现Redis支持的数据结构不止5种，而是8种，后三种类型分别是：")]),s._v(" "),t("ul",[t("li",[s._v("位数组（或简称位图）：使用特殊命令可以处理字符串值，如位数组：您可以设置和清除各个位，将所有位设置为1，查找第一个位或未设置位，等等。")]),s._v(" "),t("li",[s._v("HyperLogLogs：这是一个概率数据结构，用于估计集合的基数。不要害怕，它比看起来更简单。")]),s._v(" "),t("li",[s._v("Streams：仅附加的类似于地图的条目集合，提供抽象日志数据类型。")])]),s._v(" "),t("h3",{attrs:{id:"redis实现延迟队列"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#redis实现延迟队列"}},[s._v("#")]),s._v(" redis实现延迟队列")]),s._v(" "),t("p",[s._v("项目中用到的：数据放在zset中，其中member放的是时间戳，定时任务执行lua脚本拿到当前小于当前时间的数据，发送到kafka中，如果还需要处理，消费处理业务完成之后放入redis中，更新member的sore值，满足的数据继续发送kafka。")]),s._v(" "),t("p",[s._v("原文地址：https://medium.com/@cheukfung/redis%E5%BB%B6%E8%BF%9F%E9%98%9F%E5%88%97-c940850a264f")]),s._v(" "),t("p",[s._v("Sorted Set是一个有序的集合，元素的排序基于加入集合时指定的score。通过ZRANGEBYSCORE命令，我们可以取得score在指定区间内的元素。将集合中的元素做为消息，score视为延迟的时间，这便是一个延迟队列的模型。")]),s._v(" "),t("p",[s._v("消费者通过ZRANGEBYSCORE获取消息。如果时间未到，将得不到消息；当时间已到或已超时，都可以得到消息：使用ZRANGEBYSCORE取得消息后，消息并没有从集合中删出。需要调用ZREM删除消息：美中不足的是，消费者组合使用ZRANGEBYSCORE和ZREM的过程不是原子的，当有多个消费者时会存在竞争，可能使得一条消息被消费多次。此时需要使用Lua脚本保证消费操作的原子性：score存储的是当前时间+处理时间，查询的范围是0-当前时间，只有到了当前时间才能被查出来")]),s._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v("if #message > 0 then\n  redis.call('ZREM', KEYS[1], message[1]);\n  return message;\nelse\n  return {};\nend\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br")])]),t("h3",{attrs:{id:"余额并发扣减一致性能否使用redis事务"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#余额并发扣减一致性能否使用redis事务"}},[s._v("#")]),s._v(" 余额并发扣减一致性能否使用redis事务")]),s._v(" "),t("p",[s._v("一致性的核心观点是：使用CAS乐观锁，在写回余额时加上旧余额的比对，可以在不影响吞吐量的前提下，保证余额的一致性。用更新的时间戳最为靠谱，zset中的score")]),s._v(" "),t("p",[s._v("redis如何实现事务性？本质也是乐观锁。")]),s._v(" "),t("p",[s._v("在redis客户端执行：查改就会有并发问题了，incr一条命令就没有什么问题，或者用lua脚本")]),s._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v("$money = GET key\n$money = $money - $diff\nSET key $money\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br")])]),t("p",[s._v("在并发量大的时候，会遇到和《并发扣款，如何保证数据的一致性？》中描述的并发一致性问题。redis的WATCH和EXEC可以提供类似事务的机制：")]),s._v(" "),t("ul",[t("li",[s._v("WATCH观察key是否被改动")]),s._v(" "),t("li",[s._v("如果提交时key被改动，EXEC将返回null，表示事务失败")])]),s._v(" "),t("p",[s._v("上面保证一致性的余额扣减可能类似于这样执行：")]),s._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v("WATCH key\n$money = GET key\n$money = $money - $diff\nMULTI\nSET key $money\nEXEC\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br")])]),t("p",[s._v("说明：Redis执行multi命令标志事务开始，当客户端切换至事务状态后，服务端会将除了 exec、discard、watch 和 multi 以外的命令放进一个先进先出的事务队列中，并返回 QUEUED 给客户端。")]),s._v(" "),t("p",[s._v("在WATCH之后，EXEC执行之前，如果key的值发生变化，则EXEC会失败。redis的WATCH为何能够保证事务性，本质上，它使用的就是乐观锁CAS机制。redis的性能之所以高，还是redis内存访问与mysql数据落盘的差异导致的。内存访问的不足是，数据具备“易失性”，如果重启，可能导致数据的丢失。当然redis也可以固化数据，但如果每次都刷盘，redis反而性能会下降很多。")]),s._v(" "),t("p",[s._v("可以使用redis的事务性扣减余额，但在CAS机制上比mysql没有优势，高性能是因为其内存存储的原因，带来的副作用是数据有丢失风险。")]),s._v(" "),t("p",[s._v("原文地址，非常好，相当于官方文档了：http://redisbook.com/preview/dict/collision_resolution.html")]),s._v(" "),t("h3",{attrs:{id:"redis哈希解决键冲突"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#redis哈希解决键冲突"}},[s._v("#")]),s._v(" redis哈希解决键冲突")]),s._v(" "),t("p",[s._v("当有两个或以上数量的键被分配到了哈希表数组的同一个索引上面时， 我们称这些键发生了冲突（collision）。")]),s._v(" "),t("p",[s._v("Redis 的哈希表使用链地址法（separate chaining）来解决键冲突： ** 每个哈希表节点都有一个 next 指针， 多个哈希表节点可以用 next 指针构成一个单向链表， 被分配到同一个索引上的多个节点可以用这个单向链表连接起来， 这就解决了键冲突的问题 ** 。")]),s._v(" "),t("p",[s._v("举个例子， 假设程序要将键值对 k2 和 v2 添加到图 4-6 所示的哈希表里面， 并且计算得出 k2 的索引值为 2 ， 那么键 k1 和 k2 将产生冲突， 而解决冲突的办法就是使用 next 指针将键 k2 和 k1 所在的节点连接起来， 如图 4-7 所示。")]),s._v(" "),t("p",[s._v("因为 dictEntry 节点组成的链表没有指向链表表尾的指针， 所以为了速度考虑， 程序总是将新节点添加到链表的表头位置（复杂度为 O(1)）， 排在其他已有节点的前面。")]),s._v(" "),t("h3",{attrs:{id:"redis-rehash与hashmap扩容的区别"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#redis-rehash与hashmap扩容的区别"}},[s._v("#")]),s._v(" redis rehash与hashmap扩容的区别")]),s._v(" "),t("p",[s._v("都是开辟空间复制，hashmap是一次复制完成，另外一个则是慢慢的复制完成")]),s._v(" "),t("h4",{attrs:{id:"redis-rehash"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#redis-rehash"}},[s._v("#")]),s._v(" redis rehash：")]),s._v(" "),t("p",[s._v("redis的rehash,是将ht[0]的数据搬到ht[1] (ht[1]是ht[2]两倍)，扩容过程中新加入的元素直接往ht[1]里面添加。")]),s._v(" "),t("p",[s._v("首先我们看下字典、跟哈希表的结构定义。")]),s._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v("/*\n * 字典\n */\ntypedef struct dict {\n\n    // 类型特定函数\n    dictType *type;\n\n    // 私有数据\n    void *privdata;\n\n    // 哈希表\n    dictht ht[2];\n\n    // rehash 索引\n    // 当 rehash 不在进行时，值为 -1\n    int rehashidx; /* rehashing not in progress if rehashidx == -1 */\n\n    // 目前正在运行的安全迭代器的数量\n    int iterators; /* number of iterators currently running */\n\n} dict;\n\n\n// 哈希表\ntypedef struct dictht {\n    \n    // 哈希表数组\n    dictEntry **table;\n\n    // 哈希表大小\n    unsigned long size;\n    \n    // 哈希表大小掩码，用于计算索引值\n    // 总是等于 size - 1\n    unsigned long sizemask;\n\n    // 该哈希表已有节点的数量\n    unsigned long used;\n\n} dictht;\n\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br"),t("span",{staticClass:"line-number"},[s._v("28")]),t("br"),t("span",{staticClass:"line-number"},[s._v("29")]),t("br"),t("span",{staticClass:"line-number"},[s._v("30")]),t("br"),t("span",{staticClass:"line-number"},[s._v("31")]),t("br"),t("span",{staticClass:"line-number"},[s._v("32")]),t("br"),t("span",{staticClass:"line-number"},[s._v("33")]),t("br"),t("span",{staticClass:"line-number"},[s._v("34")]),t("br"),t("span",{staticClass:"line-number"},[s._v("35")]),t("br"),t("span",{staticClass:"line-number"},[s._v("36")]),t("br"),t("span",{staticClass:"line-number"},[s._v("37")]),t("br"),t("span",{staticClass:"line-number"},[s._v("38")]),t("br"),t("span",{staticClass:"line-number"},[s._v("39")]),t("br"),t("span",{staticClass:"line-number"},[s._v("40")]),t("br"),t("span",{staticClass:"line-number"},[s._v("41")]),t("br"),t("span",{staticClass:"line-number"},[s._v("42")]),t("br")])]),t("p",[s._v("随着操作的不断执行， 哈希表保存的键值对会逐渐地增多或者减少， 为了让哈希表的负载因子（load factor）维持在一个合理的范围之内，当哈希表保存的键值对数量太多或者太少时， 程序需要对哈希表的大小进行相应的扩展或者收缩。扩展和收缩哈希表的工作可以通过执行 rehash （重新散列）操作来完成， Redis 对字典的哈希表执行 rehash 的步骤如下：")]),s._v(" "),t("ul",[t("li",[s._v("为字典的 ht[1] 哈希表分配空间， 这个哈希表的空间大小取决于要执行的操作， 以及 ht[0] 当前包含的键值对数量 （也即是 ht[0].used 属性的值）：\n如果执行的是扩展操作， 那么 ht[1] 的大小为第一个大于等于 ht[0].used * 2 的 2^n （2 的 n 次方幂）；\n如果执行的是收缩操作， 那么 ht[1] 的大小为第一个大于等于 ht[0].used 的 2^n 。")]),s._v(" "),t("li",[s._v("将保存在 ht[0] 中的所有键值对 rehash 到 ht[1] 上面： rehash 指的是重新计算键的哈希值和索引值， 然后将键值对放置到 ht[1] 哈希表的指定位置上。")]),s._v(" "),t("li",[s._v("当 ht[0] 包含的所有键值对都迁移到了 ht[1] 之后 （ht[0] 变为空表）， 释放 ht[0] ， 将 ht[1] 设置为 ht[0] ， 并在 ht[1] 新创建一个空白哈希表， 为下一次 rehash 做准备。")])]),s._v(" "),t("p",[s._v("但是，这个rehash动作并不是一次性、集中式地完成的， 而是分多次、渐进式地完成的。为了避免 rehash 对服务器性能造成影响， 服务器不是一次性将 ht[0] 里面的所有键值对全部 rehash 到 ht[1] ， 而是分多次、渐进式地将 ht[0] 里面的键值对慢慢地 rehash 到 ht[1] 。")]),s._v(" "),t("p",[s._v("以下是哈希表渐进式 rehash 的详细步骤：")]),s._v(" "),t("ul",[t("li",[s._v("为 ht[1] 分配空间， 让字典同时持有 ht[0] 和 ht[1] 两个哈希表。")]),s._v(" "),t("li",[s._v("在字典中维持一个索引计数器变量 rehashidx ， 并将它的值设置为 0 ， 表示 rehash 工作正式开始。")]),s._v(" "),t("li",[s._v("在 rehash 进行期间， 每次对字典执行添加、删除、查找或者更新操作时， 程序除了执行指定的操作以外， 还会顺带将 ht[0] 哈希表在 rehashidx 索引上的所有键值对 rehash 到 ht[1] ， 当 rehash 工作完成之后， 程序将 rehashidx 属性的值增一。")]),s._v(" "),t("li",[s._v("随着字典操作的不断执行， 最终在某个时间点上， ht[0] 的所有键值对都会被 rehash 至 ht[1] ， 这时程序将 rehashidx 属性的值设为 -1 ， 表示 rehash 操作已完成。")])]),s._v(" "),t("h3",{attrs:{id:"jdk-hashmap"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#jdk-hashmap"}},[s._v("#")]),s._v(" jdk hashmap")]),s._v(" "),t("p",[s._v("hashmap的resize，创建一个新的数组，将旧的搬到新的数组中。当向容器添加元素的时候，会判断当前容器的元素个数，如果大于等于阈值---即当前数组的长度乘以加载因子的值的时候，就要自动扩容啦。扩容(resize)就是重新计算容量，向HashMap对象里不停的添加元素，而HashMap对象内部的数组无法装载更多的元素时，对象就需要扩大数组的长度，以便能装入更多的元素。当然Java里的数组是无法自动扩容的，方法是使用一个新的数组代替已有的容量小的数组，就像我们用一个小桶装水，如果想装更多的水，就得换大水桶。")]),s._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v("void resize(int newCapacity) {   //传入新的容量  \n    Entry[] oldTable = table;    //引用扩容前的Entry数组  \n    int oldCapacity = oldTable.length;  \n    if (oldCapacity == MAXIMUM_CAPACITY) {  //扩容前的数组大小如果已经达到最大(2^30)了  \n        threshold = Integer.MAX_VALUE; //修改阈值为int的最大值(2^31-1)，这样以后就不会扩容了  \n        return;  \n    }  \n  \n    Entry[] newTable = new Entry[newCapacity];  //初始化一个新的Entry数组  \n    transfer(newTable);                         //！！将数据转移到新的Entry数组里  \n    table = newTable;                           //HashMap的table属性引用新的Entry数组  \n    threshold = (int) (newCapacity * loadFactor);//修改阈值  \n}  \n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br")])]),t("p",[s._v("原文地址：https://www.itcodemonkey.com/article/3833.html")]),s._v(" "),t("h3",{attrs:{id:"为什么使用redis"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#为什么使用redis"}},[s._v("#")]),s._v(" 为什么使用redis")]),s._v(" "),t("p",[s._v("分析:博主觉得在项目中使用redis，主要是从两个角度去考虑:性能和并发。当然，redis还具备可以做分布式锁等其他功能，但是如果只是为了分布式锁这些其他功能，完全还有其他中间件(如zookpeer等)代替，并不是非要使用redis。因此，这个问题主要从性能和并发两个角度去答。")]),s._v(" "),t("p",[s._v("（一）如下图所示，我们在碰到需要执行耗时特别久，且结果不频繁变动的SQL，就特别适合将运行结果放入缓存。这样，后面的请求就去缓存中读取，使得请求能够迅速响应。")]),s._v(" "),t("p",[s._v("（二）并发：如下图所示，在大并发的情况下，所有的请求直接访问数据库，数据库会出现连接异常。这个时候，就需要使用redis做一个缓冲操作，让请求先访问到redis，而不是直接访问数据库。")]),s._v(" "),t("h3",{attrs:{id:"使用redis有什么缺点"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#使用redis有什么缺点"}},[s._v("#")]),s._v(" 使用redis有什么缺点")]),s._v(" "),t("p",[s._v("分析:大家用redis这么久，这个问题是必须要了解的，基本上使用redis都会碰到一些问题，常见的也就几个。回答:主要是四个问题")]),s._v(" "),t("ul",[t("li",[s._v("(一)缓存和数据库双写一致性问题（内存队列，双删除）")]),s._v(" "),t("li",[s._v("(二)缓存雪崩问题：原文地址：https://juejin.im/post/5b961172f265da0ab7198f4d，1、也是像解决缓存穿透一样加锁排队，实现同上;2、建立备份缓存，缓存A和缓存B，A设置超时时间，B不设值超时时间，先从A读缓存，A没有读B，并且更新A缓存和B缓存;")]),s._v(" "),t("li",[s._v("(三)缓存击穿问题（setnx）")]),s._v(" "),t("li",[s._v("(四)缓存的并发竞争问题：原文地址：https://my.oschina.net/jiagouzhan/blog/2990419，第一种方案：分布式锁+时间戳；第二种方案：利用消息队列")])]),s._v(" "),t("h3",{attrs:{id:"单线程的redis为什么这么快"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#单线程的redis为什么这么快"}},[s._v("#")]),s._v(" 单线程的redis为什么这么快")]),s._v(" "),t("p",[s._v("分析:这个问题其实是对redis内部机制的一个考察。其实根据博主的面试经验，很多人其实都不知道redis是单线程工作模型。所以，这个问题还是应该要复习一下的。回答:主要是以下三点")]),s._v(" "),t("ul",[t("li",[s._v("(一)纯内存操作")]),s._v(" "),t("li",[s._v("(二)单线程操作，避免了频繁的上下文切换")]),s._v(" "),t("li",[s._v("(三)采用了非阻塞I/O多路复用机制")])]),s._v(" "),t("h3",{attrs:{id:"redis和数据库双写一致性问题"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#redis和数据库双写一致性问题"}},[s._v("#")]),s._v(" Redis和数据库双写一致性问题")]),s._v(" "),t("p",[s._v("分析:一致性问题是分布式常见问题，还可以再分为最终一致性和强一致性。数据库和缓存双写，就必然会存在不一致的问题。答这个问题，先明白一个前提。就是如果对数据有强一致性要求，不能放缓存。我们所做的一切，只能保证最终一致性。另外，我们所做的方案其实从根本上来说，只能说降低不一致发生的概率，无法完全避免。因此，有强一致性要求的数据，不能放缓存。")]),s._v(" "),t("p",[s._v("回答:《分布式之数据库和缓存双写一致性方案解析》给出了详细的分析，在这里简单的说一说。首先，采取正确更新策略，先更新数据库，再删缓存。其次，因为可能存在删除缓存失败的问题，提供一个补偿措施即可，例如利用消息队列。这个文章不错：https://www.itcodemonkey.com/article/3580.html")]),s._v(" "),t("h3",{attrs:{id:"缓存雪崩"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#缓存雪崩"}},[s._v("#")]),s._v(" 缓存雪崩")]),s._v(" "),t("p",[s._v("即缓存同一时间大面积的失效，这个时候又来了一波请求，结果请求都怼到数据库上，从而导致数据库连接异常。解决方案:")]),s._v(" "),t("ul",[t("li",[t("p",[s._v("(一)给缓存的失效时间，加上一个随机值，避免集体失效。")])]),s._v(" "),t("li",[t("p",[s._v("(二)使用互斥锁，但是该方案吞吐量明显下降了。")])]),s._v(" "),t("li",[t("p",[s._v("(三)双缓存。我们有两个缓存，缓存A和缓存B。缓存A的失效时间为20分钟，缓存B不设失效时间。自己做缓存预热操作。然后细分以下几个小点")]),s._v(" "),t("p",[s._v("I 从缓存A读数据库，有则直接返回")]),s._v(" "),t("p",[s._v("II A没有数据，直接从B读数据，直接返回，并且异步启动一个更新线程。")]),s._v(" "),t("p",[s._v("III 更新线程同时更新缓存A和缓存B。")])])]),s._v(" "),t("h3",{attrs:{id:"缓存穿透"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#缓存穿透"}},[s._v("#")]),s._v(" 缓存穿透")]),s._v(" "),t("p",[s._v("即黑客故意去请求缓存中不存在的数据，导致所有的请求都怼到数据库上，从而数据库连接异常。解决方案:")]),s._v(" "),t("ul",[t("li",[s._v("(一)利用互斥锁，缓存失效的时候，先去获得锁，得到锁了，再去请求数据库。没得到锁，则休眠一段时间重试")]),s._v(" "),t("li",[s._v("(二)采用异步更新策略，无论key是否取到值，都直接返回。value值中维护一个缓存失效时间，缓存如果过期，异步起一个线程去读数据库，更新缓存。需要做缓存预热(项目启动前，先加载缓存)操作。")]),s._v(" "),t("li",[s._v("(三)提供一个能迅速判断请求是否有效的拦截机制，比如，利用布隆过滤器，内部维护一系列合法有效的key。迅速判断出，请求所携带的Key是否合法有效。如果不合法，则直接返回。")])]),s._v(" "),t("h3",{attrs:{id:"如何解决redis的并发竞争key问题"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#如何解决redis的并发竞争key问题"}},[s._v("#")]),s._v(" 如何解决redis的并发竞争key问题")]),s._v(" "),t("p",[s._v("分析:这个问题大致就是，同时有多个子系统去set一个key。这个时候要注意什么呢？大家思考过么。需要说明一下，博主提前百度了一下，发现答案基本都是推荐用redis事务机制。博主不推荐使用redis的事务机制。因为我们的生产环境，基本都是redis集群环境，做了数据分片操作。你一个事务中有涉及到多个key操作的时候，这多个key不一定都存储在同一个redis-server上。因此，redis的事务机制，十分鸡肋。")]),s._v(" "),t("ul",[t("li",[s._v("(1)如果对这个key操作，不要求顺序：这种情况下，准备一个分布式锁，大家去抢锁，抢到锁就做set操作即可，比较简单。")]),s._v(" "),t("li",[s._v("(2)如果对这个key操作，要求顺序：假设有一个key1,系统A需要将key1设置为valueA,系统B需要将key1设置为valueB,系统C需要将key1设置为valueC.")])]),s._v(" "),t("p",[s._v("期望按照key1的value值按照 valueA--\x3evalueB--\x3evalueC的顺序变化。这种时候我们在数据写入数据库的时候，需要保存一个时间戳。假设时间戳如下")]),s._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v("系统A key 1 {valueA  3:00}\n系统B key 1 {valueB  3:05}\n系统C key 1 {valueC  3:10}\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br")])]),t("p",[s._v("那么，假设这会系统B先抢到锁，将key1设置为{valueB 3:05}。接下来系统A抢到锁，发现自己的valueA的时间戳早于缓存中的时间戳，那就不做set操作了。以此类推。其他方法，比如利用队列，将set方法变成串行访问也可以。总之，灵活变通。")]),s._v(" "),t("h3",{attrs:{id:"redis的数据类型-以及每种数据类型的使用场景"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#redis的数据类型-以及每种数据类型的使用场景"}},[s._v("#")]),s._v(" redis的数据类型，以及每种数据类型的使用场景")]),s._v(" "),t("p",[s._v("分析：是不是觉得这个问题很基础，其实我也这么觉得。然而根据面试经验发现，至少百分八十的人答不上这个问题。建议，在项目中用到后，再类比记忆，体会更深，不要硬记。基本上，一个合格的程序员，五种类型都会用到。")]),s._v(" "),t("p",[s._v("(一)String:这个其实没啥好说的，最常规的set/get操作，value可以是String也可以是数字。"),t("strong",[s._v("一般做一些复杂的计数功能的缓存")]),s._v("。")]),s._v(" "),t("p",[s._v("(二)hash:这里value存放的是结构化的对象，比较方便的就是操作其中的某个字段。"),t("strong",[s._v("博主在做单点登录的时候，就是用这种数据结构存储用户信息，以cookieId作为key，设置30分钟为缓存过期时间，能很好的模拟出类似session的效果")]),s._v("。")]),s._v(" "),t("p",[s._v("(三)list:使用List的数据结构，可以做简单的"),t("strong",[s._v("消息队列的功能")]),s._v("。另外还有一个就是，可以利用lrange命令，做基于redis的分页功能，性能极佳，用户体验好。")]),s._v(" "),t("p",[s._v("(四)set:因为set堆放的是一堆不重复值的集合。所以可以做全局去重的功能。为什么不用JVM自带的Set进行去重？"),t("strong",[s._v("因为我们的系统一般都是集群部署，使用JVM自带的Set，比较麻烦，难道为了一个做一个全局去重，再起一个公共服务，太麻烦了")]),s._v("。另外，"),t("strong",[s._v("就是利用交集、并集、差集等操作")]),s._v("，可以计算共同喜好，全部的喜好，自己独有的喜好等功能。")]),s._v(" "),t("p",[s._v("(五)sortedset:sortedset多了一个权重参数score,"),t("strong",[s._v("集合中的元素能够按score进行排列")]),s._v("。可以做排行榜应用，取TOPN操作。另外，参照另一篇《分布式之延时任务方案解析》，该文指出了sorted set可以用来做延时任务。最后一个应用就是可以做范围查找。")]),s._v(" "),t("p",[s._v("总的来说：排序，计数，延时队列，分布式锁、全页面缓存、会话Session存储、pub/sub")]),s._v(" "),t("p",[s._v("Redis在真实世界的最终用法即我将在这篇文章中提出的pub / sub。这是Redis内置的最强大的功能之一；得到的可能是无限的。你可以创建一个实时聊天系统，在社交网络上触发好友请求的通知等等。这个功能是Redis提供的最被低估的功能之一，但功能非常强大，而且使用简单。")]),s._v(" "),t("p",[s._v("首先是整页缓存。如果你正在使用服务器端呈现的内容，则不需要为每个单独的请求重新渲染每个页面。使用如Redis这样的缓存，你可以缓存经常请求的内容，从而大大减少请求最多的页面的延迟，并且大多数框架针对Redis缓存页面都有hooks。")]),s._v(" "),t("h3",{attrs:{id:"redis-内存模型-非常好一定要好好看"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#redis-内存模型-非常好一定要好好看"}},[s._v("#")]),s._v(" Redis 内存模型（非常好一定要好好看）")]),s._v(" "),t("p",[s._v("原文地址：https://www.itcodemonkey.com/article/2828.html")]),s._v(" "),t("p",[s._v("关于Redis数据存储的细节，涉及到内存分配器（如jemalloc）、简单动态字符串（SDS）、5种对象类型及内部编码、redisObject。在讲述具体内容之前，先说明一下这几个概念之间的关系。")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://txxs.github.io/pic/tofutureinterview/1-14.png",alt:"1"}})]),s._v(" "),t("p",[s._v("（1）dictEntry：Redis是Key-Value数据库，因此对每个键值对都会有一个dictEntry，里面存储了指向Key和Value的指针；next指向下一个dictEntry，与本Key-Value无关。一个键值对就是一个这个，一个String就是一个这个，list或者set对数据结构都在在这个基础上拓展，压缩列表，双向列表；跳表")]),s._v(" "),t("p",[s._v("（2）Key：图中右上角可见，Key（”hello”）并不是直接以字符串存储，而是存储在SDS结构中。")]),s._v(" "),t("p",[s._v("（3）redisObject：Value(“world”)既不是直接以字符串存储，也不是像Key一样直接存储在SDS中，而是存储在redisObject中。实际上，不论Value是5种类型的哪一种，都是通过redisObject来存储的；而redisObject中的type字段指明了Value对象的类型，ptr字段则指向对象所在的地址。不过可以看出，字符串对象虽然经过了redisObject的包装，但仍然需要通过SDS存储。实际上，redisObject除了type和ptr字段以外，还有其他字段图中没有给出，如用于指定对象内部编码的字段；后面会详细介绍。")]),s._v(" "),t("h4",{attrs:{id:"redisobject"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#redisobject"}},[s._v("#")]),s._v(" redisObject")]),s._v(" "),t("p",[s._v("前面说到，Redis对象有5种类型；无论是哪种类型，Redis都不会直接存储，而是通过redisObject对象进行存储。redisObject对象非常重要，Redis对象的类型、内部编码、内存回收、共享对象等功能，都需要redisObject支持，下面将通过redisObject的结构来说明它是如何起作用的。")]),s._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v("typedef struct redisObject {\n　　unsigned type:4;\n　　unsigned encoding:4;\n　　unsigned lru:REDIS_LRU_BITS; /* lru time (relative to server.lruclock) */\n　　int refcount;\n　　void *ptr;\n} robj;\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br")])]),t("ul",[t("li",[s._v("（1）type:type字段表示对象的类型，占4个比特；目前包括REDIS_STRING(字符串)、REDIS_LIST (列表)、REDIS_HASH(哈希)、REDIS_SET(集合)、REDIS_ZSET(有序集合)。")]),s._v(" "),t("li",[s._v("（2）encoding：encoding表示对象的内部编码，占4个比特。对于Redis支持的每种类型，都有至少两种内部编码，例如对于字符串，有int、embstr、raw三种编码。")]),s._v(" "),t("li",[s._v("（3）lru：lru记录的是对象最后一次被命令程序访问的时间，占据的比特数不同的版本有所不同")])]),s._v(" "),t("h4",{attrs:{id:"字符串"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#字符串"}},[s._v("#")]),s._v(" 字符串")]),s._v(" "),t("p",[s._v("字符串是最基础的类型，因为所有的键都是字符串类型，且字符串之外的其他几种复杂类型的元素也是字符串。"),t("strong",[s._v("字符串长度不能超过512MB")]),s._v("。")]),s._v(" "),t("h4",{attrs:{id:"列表"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#列表"}},[s._v("#")]),s._v(" 列表")]),s._v(" "),t("p",[s._v("列表（list）用来存储多个有序的字符串，每个字符串称为元素；一个列表可以存储2^32-1个元素。Redis中的列表支持两端插入和弹出，并可以获得指定位置（或范围）的元素，可以充当数组、队列、栈等。列表的内部编码可以是压缩列表（ziplist）或双端链表（linkedlist）。")]),s._v(" "),t("p",[s._v("压缩列表：压缩列表是Redis为了节约内存而开发的，是由一系列特殊编码的连续内存块(而不是像双端链表一样每个节点是指针)组成的顺序型数据结构；具体结构相对比较复杂，略。与双端链表相比，压缩列表可以节省内存空间，但是进行修改或增删操作时，复杂度较高；因此当节点数量较少时，可以使用压缩列表；但是节点数量多时，还是使用双端链表划算。")]),s._v(" "),t("h4",{attrs:{id:"哈希"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#哈希"}},[s._v("#")]),s._v(" 哈希")]),s._v(" "),t("p",[s._v("哈希（作为一种数据结构），不仅是redis对外提供的5种对象类型的一种（与字符串、列表、集合、有序结合并列），也是Redis作为Key-Value数据库所使用的数据结构。为了说明的方便，在本文后面当使用“内层的哈希”时，代表的是redis对外提供的5种对象类型的一种；使用“外层的哈希”代指Redis作为Key-Value数据库所使用的数据结构。")]),s._v(" "),t("p",[s._v("压缩列表前面已介绍。与哈希表相比，压缩列表用于元素个数少、元素长度小的场景；其优势在于集中存储，节省空间；同时，虽然对于元素的操作复杂度也由O(n)变为了O(1)，但由于哈希中元素数量较少，因此操作的时间并没有明显劣势。")]),s._v(" "),t("p",[s._v("hashtable：一个hashtable由1个dict结构、2个dictht结构、1个dictEntry指针数组（称为bucket）和多个dictEntry结构组成。")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://txxs.github.io/pic/tofutureinterview/1-15.png",alt:"1"}})]),s._v(" "),t("h4",{attrs:{id:"集合-set"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#集合-set"}},[s._v("#")]),s._v(" 集合(set)")]),s._v(" "),t("p",[s._v("集合（set）与列表类似，都是用来保存多个字符串，但集合与列表有两点不同：集合中的元素是无序的，因此不能通过索引来操作元素；集合中的元素不能有重复。一个集合中最多可以存储2^32-1个元素；除了支持常规的增删改查，Redis还支持多个集合取交集、并集、差集。集合的内部编码可以是整数集合（intset）或哈希表（hashtable）。")]),s._v(" "),t("p",[s._v("整数集合适用于集合所有元素都是整数且集合元素数量较小的时候，与哈希表相比，整数集合的优势在于集中存储，节省空间；同时，虽然对于元素的操作复杂度也由O(n)变为了O(1)，但由于集合数量较少，因此操作的时间并没有明显劣势。")]),s._v(" "),t("h4",{attrs:{id:"有序集合"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#有序集合"}},[s._v("#")]),s._v(" 有序集合")]),s._v(" "),t("p",[s._v("有序集合与集合一样，元素都不能重复；但与集合不同的是，有序集合中的元素是有顺序的。与列表使用索引下标作为排序依据不同，有序集合为每个元素设置一个分数（score）作为排序依据。")]),s._v(" "),t("p",[s._v("有序集合的内部编码可以是压缩列表（ziplist）或跳跃表（skiplist）。")]),s._v(" "),t("p",[s._v("跳跃表是一种有序数据结构，通过在每个节点中维持多个指向其他节点的指针，从而达到快速访问节点的目的。除了跳跃表，实现有序数据结构的另一种典型实现是平衡树；大多数情况下，跳跃表的效率可以和平衡树媲美，且跳跃表实现比平衡树简单很多，因此redis中选用跳跃表代替平衡树。跳跃表支持平均O(logN)、最坏O(N)的复杂点进行节点查找，并支持顺序操作。Redis的跳跃表实现由zskiplist和zskiplistNode两个结构组成：前者用于保存跳跃表信息（如头结点、尾节点、长度等），后者用于表示跳跃表节点。具体结构相对比较复杂，略。")]),s._v(" "),t("h3",{attrs:{id:"redis-内存碎片率"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#redis-内存碎片率"}},[s._v("#")]),s._v(" redis 内存碎片率")]),s._v(" "),t("p",[s._v("如果内存碎片率过高（jemalloc在1.03左右比较正常），说明内存碎片多，内存浪费严重；这时便可以考虑重启redis服务，在内存中对数据进行重排，减少内存碎片。")]),s._v(" "),t("p",[s._v("如果内存碎片率小于1，说明redis内存不足，部分数据使用了虚拟内存（即swap）；由于虚拟内存的存取速度比物理内存差很多（2-3个数量级），此时redis的访问速度可能会变得很慢。因此必须设法增大物理内存（可以增加服务器节点数量，或提高单机内存），或减少redis中的数据。")]),s._v(" "),t("p",[s._v("要减少redis中的数据，除了选用合适的数据类型、利用共享对象等，还有一点是要设置合理的数据回收策略（maxmemory-policy），当内存达到一定量后，根据不同的优先级对内存进行回收。")]),s._v(" "),t("h3",{attrs:{id:"redis持久化再讲-非常好"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#redis持久化再讲-非常好"}},[s._v("#")]),s._v(" redis持久化再讲（非常好）")]),s._v(" "),t("p",[s._v("原文地址：https://www.itcodemonkey.com/article/4145.html")]),s._v(" "),t("h4",{attrs:{id:"rdb持久化-redis默认的方式"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#rdb持久化-redis默认的方式"}},[s._v("#")]),s._v(" RDB持久化（redis默认的方式）")]),s._v(" "),t("p",[s._v("RDB持久化是将当前进程中的数据生成快照保存到硬盘(因此也称作快照持久化)，保存的文件后缀是rdb；当Redis重新启动时，可以读取快照文件恢复数据。")]),s._v(" "),t("p",[s._v("1、触发条件：RDB持久化的触发分为手动触发和自动触发两种。")]),s._v(" "),t("ol",[t("li",[s._v("手动触发")])]),s._v(" "),t("ul",[t("li",[s._v("save命令：save命令会阻塞Redis服务器进程，直到RDB文件创建完毕为止，在Redis服务器阻塞期间，服务器不能处理任何命令请求。")]),s._v(" "),t("li",[s._v("bgsave命令：而bgsave命令会创建一个子进程，由子进程来负责创建RDB文件，父进程(即Redis主进程)则继续处理请求。")])]),s._v(" "),t("ol",{attrs:{start:"2"}},[t("li",[s._v("自动触发")])]),s._v(" "),t("ul",[t("li",[s._v("save m n：自动触发最常见的情况是在配置文件中通过save m n，指定当m秒内发生n次变化时，会触发bgsave。save m n的实现原理：Redis的save m n，是通过serverCron函数、dirty计数器、和lastsave时间戳来实现的")]),s._v(" "),t("li",[s._v("在主从复制场景下，如果从节点执行全量复制操作，则主节点会执行bgsave命令，并将rdb文件发送给从节点")]),s._v(" "),t("li",[s._v("执行shutdown命令时，自动执行rdb持久化")])]),s._v(" "),t("h4",{attrs:{id:"aof持久化"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#aof持久化"}},[s._v("#")]),s._v(" AOF持久化")]),s._v(" "),t("p",[s._v("RDB持久化是将进程数据写入文件，而AOF持久化(即Append Only File持久化)，则是将Redis执行的每次写命令记录到单独的日志文件中（有点像MySQL的binlog）；当Redis重启时再次执行AOF文件中的命令来恢复数据。与RDB相比，AOF的实时性更好，因此已成为主流的持久化方案。")]),s._v(" "),t("p",[s._v("1、开启AOF：Redis服务器默认开启RDB，关闭AOF；要开启AOF，需要在配置文件中配置：appendonly yes")]),s._v(" "),t("p",[s._v("2、执行流程")]),s._v(" "),t("p",[s._v("由于需要记录Redis的每条写命令，因此AOF不需要触发，下面介绍AOF的执行流程。AOF的执行流程包括：")]),s._v(" "),t("ul",[t("li",[s._v("命令追加(append)：将Redis的写命令追加到缓冲区aof_buf；")]),s._v(" "),t("li",[s._v("文件写入(write)和文件同步(sync)：根据不同的同步策略将aof_buf中的内容同步到硬盘；")]),s._v(" "),t("li",[s._v("文件重写(rewrite)：定期重写AOF文件，达到压缩的目的。文件重写的触发：文件重写的触发，分为手动触发和自动触发：手动触发：直接调用bgrewriteaof命令，该命令的执行与bgsave有些类似：都是fork子进程进行具体的工作，"),t("strong",[s._v("且都只有在fork时阻塞")]),s._v("。")])]),s._v(" "),t("h4",{attrs:{id:"rdb和aof的优缺点"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#rdb和aof的优缺点"}},[s._v("#")]),s._v(" RDB和AOF的优缺点")]),s._v(" "),t("p",[s._v("RDB持久化")]),s._v(" "),t("p",[s._v("优点：RDB文件紧凑，体积小，网络传输快，适合全量复制；恢复速度比AOF快很多。当然，与AOF相比，RDB最重要的优点之一是对性能的影响相对较小。")]),s._v(" "),t("p",[s._v("缺点：RDB文件的致命缺点在于其数据快照的持久化方式决定了必然做不到实时持久化，而在数据越来越重要的今天，数据的大量丢失很多时候是无法接受的，因此AOF持久化成为主流。此外，RDB文件需要满足特定格式，兼容性差（如老版本的Redis不兼容新版本的RDB文件）。")]),s._v(" "),t("p",[s._v("AOF持久化")]),s._v(" "),t("p",[s._v("与RDB持久化相对应，AOF的优点在于支持秒级持久化、兼容性好，缺点是文件大、恢复速度慢、对性能影响大。")]),s._v(" "),t("h3",{attrs:{id:"set命令高级用法"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#set命令高级用法"}},[s._v("#")]),s._v(" set命令高级用法")]),s._v(" "),t("p",[s._v("你可能用的比较多的就是set key value，或者SETEX key seconds value，所以很多同学用redis实现分布式锁分为两步：首先执行SETNX key value，然后执行EXPIRE key seconds。很明显，这种实现有很严重的问题，因为两步执行不具备原子性，如果执行第一个命令后出现某些未知异常导致无法执行EXPIRE key seconds，那么分布式锁就会一直无法得到释放。")]),s._v(" "),t("p",[s._v("通过SET命令实现分布式锁的正式姿势应该是SET key value EX seconds NX（EX和PX任选，取决于对过期时间精度要求）。另外，value也有要求，最好是一个类似UUID这种具备唯一性的字符串。当然如果问你redis是否还有其他实现分布式锁的方案。你能说出redlock，那对方一定眼前一亮，心里对你竖起大拇指，但嘴上不会说。")]),s._v(" "),t("h3",{attrs:{id:"redis挂了怎么办"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#redis挂了怎么办"}},[s._v("#")]),s._v(" redis挂了怎么办")]),s._v(" "),t("ol",[t("li",[s._v("如果是后台固定数据会在配置心中，弄一份数据")]),s._v(" "),t("li",[s._v("实时数据，报警，降级，不要把mysql打死")])]),s._v(" "),t("h3",{attrs:{id:"redis-常见的性能问题都有哪些-如何解决"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#redis-常见的性能问题都有哪些-如何解决"}},[s._v("#")]),s._v(" Redis 常见的性能问题都有哪些？如何解决？")]),s._v(" "),t("p",[s._v("1).Master写内存快照，save命令调度rdbSave函数，会阻塞主线程的工作，当快照比较大时对性能影响是非常大的，会间断性暂停服务，所以Master最好不要写内存快照。")]),s._v(" "),t("p",[s._v("2).Master AOF持久化，如果不重写AOF文件，这个持久化方式对性能的影响是最小的，但是AOF文件会不断增大，AOF文件过大会影响Master重启的恢复速度。Master最好不要做任何持久化工作，包括内存快照和AOF日志文件，特别是不要启用内存快照做持久化,如果数据比较关键，某个Slave开启AOF备份数据，策略为每秒同步一次。")]),s._v(" "),t("p",[s._v("3).Master调用BGREWRITEAOF重写AOF文件，AOF在重写的时候会占大量的CPU和内存资源，导致服务load过高，出现短暂服务暂停现象。")]),s._v(" "),t("p",[s._v("4). Redis主从复制的性能问题，为了主从复制的速度和连接的稳定性，Slave和Master最好在同一个局域网内")]),s._v(" "),t("h3",{attrs:{id:"memcache与redis的区别都有哪些"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#memcache与redis的区别都有哪些"}},[s._v("#")]),s._v(" Memcache与Redis的区别都有哪些？")]),s._v(" "),t("p",[s._v("1)、存储方式：Memecache把数据全部存在内存之中，断电后会挂掉，数据不能超过内存大小。Redis有部份存在硬盘上，这样能保证数据的持久性。")]),s._v(" "),t("p",[s._v("2)、数据支持类型：Memcache对数据类型支持相对简单。Redis有复杂的数据类型。")]),s._v(" "),t("p",[s._v("3)、使用底层模型不同：它们之间底层实现方式 以及与客户端之间通信的应用协议不一样。Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。")]),s._v(" "),t("p",[s._v("4），value大小：redis最大可以达到1GB，而memcache只有1MB")]),s._v(" "),t("h3",{attrs:{id:"kv缓存都缓存了一些什么数据"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#kv缓存都缓存了一些什么数据"}},[s._v("#")]),s._v(" KV缓存都缓存了一些什么数据？")]),s._v(" "),t("p",[s._v("（1）朴素类型的数据，例如：int")]),s._v(" "),t("p",[s._v("（2）序列化后的对象，例如：User实体，本质是binary")]),s._v(" "),t("p",[s._v("（3）文本数据，例如：json或者html")]),s._v(" "),t("h3",{attrs:{id:"淘汰缓存中的这些数据-修改缓存中的这些数据-有什么差别"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#淘汰缓存中的这些数据-修改缓存中的这些数据-有什么差别"}},[s._v("#")]),s._v(" 淘汰缓存中的这些数据，修改缓存中的这些数据，有什么差别？")]),s._v(" "),t("p",[s._v("（1）淘汰某个key，操作简单，直接将key置为无效，但下一次该key的访问会cache miss")]),s._v(" "),t("p",[s._v("（2）修改某个key的内容，逻辑相对复杂，但下一次该key的访问仍会cache hit")]),s._v(" "),t("p",[t("strong",[s._v("可以看到，差异仅仅在于一次cache miss")])]),s._v(" "),t("h3",{attrs:{id:"缓存中的value数据一般是怎么修改的"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#缓存中的value数据一般是怎么修改的"}},[s._v("#")]),s._v(" 缓存中的value数据一般是怎么修改的？")]),s._v(" "),t("ol",[t("li",[s._v("朴素类型的数据，直接set修改后的值即可")]),s._v(" "),t("li",[s._v("序列化后的对象：一般需要先get数据，反序列化成对象，修改其中的成员，再序列化为binary，再set数据")]),s._v(" "),t("li",[s._v("json或者html数据：一般也需要先get文本，parse成doom树对象，修改相关元素，序列化为文本，再set数据")])]),s._v(" "),t("p",[s._v("结论：对于对象类型，或者文本类型，修改缓存value的成本较高，一般选择直接淘汰缓存。")]),s._v(" "),t("h3",{attrs:{id:"redis相比memcached有哪些优势"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#redis相比memcached有哪些优势"}},[s._v("#")]),s._v(" redis相比memcached有哪些优势？")]),s._v(" "),t("ol",[t("li",[s._v("memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型")]),s._v(" "),t("li",[s._v("redis的速度比memcached快很多")]),s._v(" "),t("li",[s._v("redis可以持久化其数据")]),s._v(" "),t("li",[s._v("Redis支持数据的备份，即master-slave模式的数据备份。")]),s._v(" "),t("li",[s._v("使用底层模型不同，它们之间底层实现方式 以及与客户端之间通信的应用协议不一样。Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。")]),s._v(" "),t("li",[s._v("value大小：redis最大可以达到1GB，而memcache只有1MB")])]),s._v(" "),t("h3",{attrs:{id:"使用过redis做异步队列么-你是怎么用的-有什么缺点"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#使用过redis做异步队列么-你是怎么用的-有什么缺点"}},[s._v("#")]),s._v(" 使用过Redis做异步队列么，你是怎么用的？有什么缺点？")]),s._v(" "),t("p",[s._v("一般使用list结构作为队列，rpush生产消息，lpop消费消息。当lpop没有消息的时候，要适当sleep一会再重试。")]),s._v(" "),t("p",[s._v("缺点：")]),s._v(" "),t("p",[s._v("在消费者下线的情况下，生产的消息会丢失，得使用专业的消息队列如rabbitmq等。")]),s._v(" "),t("h3",{attrs:{id:"能不能生产一次消费多次呢"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#能不能生产一次消费多次呢"}},[s._v("#")]),s._v(" 能不能生产一次消费多次呢？")]),s._v(" "),t("p",[s._v("使用pub/sub主题订阅者模式，可以实现1:N的消息队列。")]),s._v(" "),t("h3",{attrs:{id:"redis常见面试问题-一和二"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#redis常见面试问题-一和二"}},[s._v("#")]),s._v(" Redis常见面试问题（一和二）")]),s._v(" "),t("p",[s._v("https://www.itcodemonkey.com/article/10656.html")]),s._v(" "),t("p",[s._v("https://www.itcodemonkey.com/article/10853.html")]),s._v(" "),t("h3",{attrs:{id:"redis为什么这么快"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#redis为什么这么快"}},[s._v("#")]),s._v(" Redis为什么这么快")]),s._v(" "),t("ol",[t("li",[s._v("完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)；")]),s._v(" "),t("li",[s._v("数据结构简单，对数据操作也简单，Redis中的数据结构是专门进行设计的；")]),s._v(" "),t("li",[s._v("采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；")]),s._v(" "),t("li",[s._v("使用多路I/O复用模型，非阻塞IO；\n5、使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis直接自己构建了VM机制，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；")])]),s._v(" "),t("p",[s._v("以上几点都比较好理解，下边我们针对多路 I/O 复用模型进行简单的探讨：")]),s._v(" "),t("p",[s._v("多路 I/O 复用模型")]),s._v(" "),t("p",[s._v("多路I/O复用模型是利用 select、poll、epoll 可以同时监察多个流的 I/O 事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有 I/O 事件时，就从阻塞态中唤醒，于是程序就会轮询一遍所有的流（epoll 是只轮询那些真正发出了事件的流），并且只依次顺序的处理就绪的流，这种做法就避免了大量的无用操作。")]),s._v(" "),t("p",[s._v("这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程。采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络 IO 的时间消耗），且 Redis 在内存中操作数据的速度非常快，也就是说内存内的操作不会成为影响Redis性能的瓶颈，主要由以上几点造就了 Redis 具有很高的吞吐量。")]),s._v(" "),t("h3",{attrs:{id:"那么为什么redis是单线程的"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#那么为什么redis是单线程的"}},[s._v("#")]),s._v(" 那么为什么Redis是单线程的")]),s._v(" "),t("p",[s._v("我们首先要明白，上边的种种分析，都是为了营造一个Redis很快的氛围！官方FAQ表示，因为Redis是基于内存的操作，CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存的大小或者网络带宽。既然单线程容易实现，而且CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了（毕竟采用多线程会有很多麻烦！）")]),s._v(" "),t("p",[s._v("这里我们一直在强调的单线程，只是在处理我们的网络请求的时候只有一个线程来处理，一个正式的Redis Server运行的时候肯定是不止一个线程的，这里需要大家明确的注意一下！例如Redis进行持久化的时候会以子进程或者子线程的方式执行（具体是子线程还是子进程待读者深入研究")]),s._v(" "),t("ol",[t("li",[s._v("redis都是对内存的操作，速度极快（10W+QPS）")]),s._v(" "),t("li",[s._v("整体的时间主要都是消耗在了网络的传输上")]),s._v(" "),t("li",[s._v("如果使用了多线程，则需要多线程同步，这样实现起来会变的复杂")]),s._v(" "),t("li",[s._v("线程的加锁时间甚至都超过了对内存操作的时间")]),s._v(" "),t("li",[s._v("多线程上下文频繁的切换需要消耗更多的CPU时间")]),s._v(" "),t("li",[s._v("还有就是单线程天然支持原子操作，而且单线程的代码写起来更简单")])]),s._v(" "),t("h3",{attrs:{id:"redis事务"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#redis事务"}},[s._v("#")]),s._v(" redis事务")]),s._v(" "),t("p",[s._v("redis事务具有以下特点：")]),s._v(" "),t("ol",[t("li",[s._v("如果开始执行事务前出错，则所有命令都不执行")]),s._v(" "),t("li",[s._v("一旦开始，则保证所有命令一次性按顺序执行完而不被打断")]),s._v(" "),t("li",[s._v("如果执行过程中遇到错误，会继续执行下去，不会停止的")]),s._v(" "),t("li",[s._v("对于执行过程中遇到错误，是不会进行回滚的")])]),s._v(" "),t("p",[s._v("看完这些，真想问一句话，你这能叫事务吗？很显然，这并不是我们通常认为的事务，因为它连原子性都保证不了。保证不了原子性是因为redis不支持回滚，不过它也给出了不支持的理由。")]),s._v(" "),t("p",[s._v("不支持回滚的理由：")]),s._v(" "),t("ol",[t("li",[s._v("redis认为，失败都是由命令使用不当造成")]),s._v(" "),t("li",[s._v("redis这样做，是为了保持内部实现简单快速")]),s._v(" "),t("li",[s._v("redis还认为，回滚并不能解决所有问题")])]),s._v(" "),t("p",[s._v("哈哈，这就是霸王条款，因此，好像使用redis事务的不太多")]),s._v(" "),t("h3",{attrs:{id:"管道"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#管道"}},[s._v("#")]),s._v(" 管道")]),s._v(" "),t("p",[s._v("原文地址：https://www.itcodemonkey.com/article/14199.html")]),s._v(" "),t("p",[s._v("客户端和集群的交互过程是串行化阻塞式的，即客户端发送了一个命令后必须等到响应回来后才能发第二个命令，这一来一回就是一个往返时间。如果你有很多的命令，都这样一个一个的来进行，会变得很慢。")]),s._v(" "),t("p",[s._v("redis提供了一种管道技术，可以让客户端一次发送多个命令，期间不需要等待服务器端的响应，等所有的命令都发完了，再依次接收这些命令的全部响应。这就极大地节省了许多时间，提升了效率。聪明的你是不是意识到了另外一个问题，多个命令就是多个key啊，这不就是上面提到的多key操作嘛，那么问题来了，你如何保证这多个key都是同一个节点上的啊，哈哈，redis集群又放弃了对管道的支持。不过可以在客户端模拟实现，就是使用多个连接往多个节点同时发送命令，然后等待所有的节点都返回了响应，再把它们按照发送命令的顺序整理好，返回给用户代码。哎呀，好麻烦呀。")]),s._v(" "),t("h3",{attrs:{id:"为什么-redis-单线程却能支撑高并发"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#为什么-redis-单线程却能支撑高并发"}},[s._v("#")]),s._v(" 为什么 Redis 单线程却能支撑高并发？")]),s._v(" "),t("p",[s._v("原文地址：https://www.itcodemonkey.com/article/14363.html")]),s._v(" "),t("p",[s._v("最近在看 UNIX 网络编程并研究了一下 Redis 的实现，感觉 Redis 的源代码十分适合阅读和分析，其中 I/O多路复用（mutiplexing）部分的实现非常干净和优雅，在这里想对这部分的内容进行简单的整理。首先，"),t("strong",[s._v("Redis 是跑在单线程中的，所有的操作都是按照顺序线性执行的")]),s._v("，但是由于读写操作等待用户输入或输出都是阻塞的，所以 I/O 操作在一般情况下往往不能直接返回，这会导致某一文件的 I/O 阻塞导致整个进程无法对其它客户提供服务，而 I/O 多路复用就是为了解决这个问题而出现的。")]),s._v(" "),t("h3",{attrs:{id:"redis分布式锁要考虑的问题"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#redis分布式锁要考虑的问题"}},[s._v("#")]),s._v(" redis分布式锁要考虑的问题")]),s._v(" "),t("ol",[t("li",[s._v("原子操作:基于redis的分布式锁常用命令是")])]),s._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v("SETNX key value\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("相当于两条命令了，设置超时时间有问题，set xx模式解决")]),s._v(" "),t("ol",{attrs:{start:"2"}},[t("li",[t("p",[s._v("超时问题:在正常的业务当中，当一个线程获取到锁并且设置了锁的过期时间之后，会出现由于业务代码执行时间过长，锁由于到达超时时间自动释放的情况。自动释放之后，其他的线程就会获取到分布式锁，导致业务代码不会串行执行。如果业务上允许这样的情况偶尔发生，那程序员就开干吧，最后顶多人工干预一下，update 一下数据库。为了避免这类情况发生，在使用redis分布式锁的时候，业务方应尽量避免长时间执行的代码任务。 如果设置锁的超时时间比较长，在一定程度上可以缓解业务代码执行时间长锁自动到期的问题，但是一旦业务代码down掉，其他等待锁的线程等待的时间会比较长，这种情况下，确保获取到锁的程序不会down 成为了主要问题。")])]),s._v(" "),t("li",[t("p",[s._v("获取锁失败:当锁被一个调用方获取之后，其他调用方在获取锁失败之后，是继续轮询还是直接业务失败呢？如果是继续轮询的话，同步情况下当前线程会一直处于阻塞状态，所以这里轮询的情况还是建议使用异步。")])]),s._v(" "),t("li",[t("p",[s._v("可重入性:可重入性是指已经拥有锁的客户端再次请求加锁，如果锁支持同一个客户端重复加锁，那么这个锁就是可重入的。如果基于redis的分布式锁要想支持可重入性，需要客户端封装，可以使用threadlocal存储持有锁的信息。这个封装过程会增加代码的复杂度，所以菜菜不推荐这样做。")])]),s._v(" "),t("li",[t("p",[s._v("redis挂了:如果在多个客户端获取锁的过程中，redis 挂了怎么办呢？假如一个客户端已经获取到了锁，这个时候redis挂了（假如是redis集群），其他的redis服务器会接着提供服务，这个时候其他客户端可以在新的服务器上获取到锁了，这也导致了锁意义的丢失。有兴趣的同学可以去看看RedLock，这种方案以牺牲性能的代价解决了这个问题。")])]),s._v(" "),t("li",[t("p",[s._v("时钟跳跃问题:在某些时候，redis的服务器时间发生的跳跃，由于锁的过期时间依赖于服务器时间，所以也会出现两个客户端同时获取到锁的情况发生。")])])]),s._v(" "),t("h3",{attrs:{id:"redis-string和java-string的区别"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#redis-string和java-string的区别"}},[s._v("#")]),s._v(" redis String和java String的区别")]),s._v(" "),t("p",[s._v("原文地址：https://blog.csdn.net/cjqh_hao/article/details/89741720")]),s._v(" "),t("p",[s._v("http://redisbook.com/preview/sds/different_between_sds_and_c_string.html")]),s._v(" "),t("p",[s._v("根据传统， C 语言使用长度为 N+1 的字符数组来表示长度为 N 的字符串， 并且字符数组的最后一个元素总是空字符 '\\0' 。C 语言使用的这种简单的字符串表示方式， 并不能满足 Redis 对字符串在安全性、效率、以及功能方面的要求， 本节接下来的内容将详细对比 C 字符串和 SDS 之间的区别， 并说明 SDS 比 C 字符串更适用于 Redis 的原因。")]),s._v(" "),t("p",[s._v("一、数据结构:redis的字符串底层数据结构是sds（simple dynamic string），即简单动态字符串，其结构体定义如下：")]),s._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v("struct sdshdr {\n    // buf 中已占用空间的长度\n    int len;\n\n    // buf 中剩余可用空间的长度\n    int free;\n\n    // 数据空间\n    char buf[];\n};\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br")])]),t("p",[s._v("其中：")]),s._v(" "),t("ul",[t("li",[s._v("len：当前实际存储的字符串长度")]),s._v(" "),t("li",[s._v("free：剩余未使用的长度")]),s._v(" "),t("li",[s._v("buf：用于存储数据的字节数组")])]),s._v(" "),t("p",[s._v("SDS遵循C语言字符串以空字符结尾的惯例，保存空字符的1字节空间不计算在sds的len属性中，并且为空字符分配额外的1字节空间，以及添加空字符到字符串末尾等操作，都有SDS函数自动完成。")]),s._v(" "),t("p",[s._v("二、复杂度问题:SDS由于存储了len属性，所以获取字符长度的时间复杂度为O（1），而C字符串并不记录本身长度，故获取字符串长度需要遍历整个字符串，直到遇到空字符，时间复杂度为O（N）。SDS的长度更新是有SDS的API自动完成。\nSDS的设计是典型的利用空间换时间。")]),s._v(" "),t("p",[s._v("三、内存分配释放策略:概括为预分配+惰性释放")]),s._v(" "),t("p",[s._v("SDS的内存分配策略：")]),s._v(" "),t("ol",[t("li",[s._v("如果对SDS字符串修改后，len的值小于1MB，那么程序会分配和len同样大小的空间，此时len和free的值是相同的，例如，如果SDS的字符串长度修改为15字节，那么会分配15字节空间给free，SDS的buf属性长度为15（len）+15（free）+1（空字符） = 31字节。")]),s._v(" "),t("li",[s._v("如果SDS字符串修改后，len大于等于1MB，那么程序会分配1MB的空间给free，例如，SDS字符串长度修改为50MB那么程序会分配1MB的未使用空间给free，SDS的buf属性长度为50MB（len）+1MB（free）+1byte（空字符）。预分配策略有效减少了内存充分配操作次数。")])]),s._v(" "),t("p",[s._v("SDS的内存释放策略：当需要缩短SDS字符串时，程序并不立刻将内存释放，而是使用free属性将这些空间记录下来，以备将来使用。")]),s._v(" "),t("p",[s._v("三、缓冲区溢出问题:SDS的字符串的内存预分配策略能有效避免缓冲区溢出问题，C字符串每次操作增加长度时，都要分配足够长度的内存空间，否则就会产生缓冲区溢出（buffer overflow）。")]),s._v(" "),t("p",[s._v("四、二进制安全问题:SDS字符串API都是以处理二进制的方式处理buf数组里的数据，程序不会对其中的数据进行过滤、操作等，所以SDS是二进制数据安全的。\nC字符串的字符则必须符合某种编码（ASCII），并且字符串的中间不能包含空字符，否则字符串就会被截断，所以C字符串智能保存文本数据，而不能保存图片、音视频等数据类型。")]),s._v(" "),t("table",[t("thead",[t("tr",[t("th",[s._v("序号")]),s._v(" "),t("th",[s._v("C 字符串")]),s._v(" "),t("th",[s._v("SDS")])])]),s._v(" "),t("tbody",[t("tr",[t("td",[s._v("1")]),s._v(" "),t("td",[s._v("获取字符串长度的复杂度为 O(N)")]),s._v(" "),t("td",[s._v("获取字符串长度的复杂度为 O(1)")])]),s._v(" "),t("tr",[t("td",[s._v("2")]),s._v(" "),t("td",[s._v("API 是不安全的，可能会造成缓冲区溢出")]),s._v(" "),t("td",[s._v("API 是安全的，不会造成缓冲区溢出")])]),s._v(" "),t("tr",[t("td",[s._v("3")]),s._v(" "),t("td",[s._v("修改字符串长度 N 次必然需要执行 N 次内存重分配")]),s._v(" "),t("td",[s._v("修改字符串长度 N 次最多需要执行 N 次内存重分配")])]),s._v(" "),t("tr",[t("td",[s._v("4")]),s._v(" "),t("td",[s._v("只能保存文本数据")]),s._v(" "),t("td",[s._v("可以保存文本或者二进制数据")])]),s._v(" "),t("tr",[t("td",[s._v("5")]),s._v(" "),t("td",[s._v("可以使用所有 <string.h> 库中的函数")]),s._v(" "),t("td",[s._v("可以使用一部分 <string.h> 库中的函数")])])])]),s._v(" "),t("p",[s._v("原文地址：https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651961296&idx=1&sn=883a46db0e4b4fe8bd2de5a370e3304e&chksm=bd2d020c8a5a8b1a2938b07da1a42648d562c559d573b5700e48ea5318dac3ee246b2e6ce908&scene=21#wechat_redirect")]),s._v(" "),t("h3",{attrs:{id:"进程缓存"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#进程缓存"}},[s._v("#")]),s._v(" 进程缓存")]),s._v(" "),t("p",[s._v("将一些数据缓存在站点，或者服务的进程内，这就是进程内缓存。进程内缓存的实现载体，最简单的，可以是一个带锁的Map。又或者，可以使用第三方库，例如leveldb。redis/memcache等进程外缓存服务能存什么，进程内缓存就能存什么，可以存储json数据，可以存储html页面，可以存储对象。")]),s._v(" "),t("h3",{attrs:{id:"进程内缓存有什么优缺点"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#进程内缓存有什么优缺点"}},[s._v("#")]),s._v(" 进程内缓存有什么优缺点")]),s._v(" "),t("p",[s._v("优点：")]),s._v(" "),t("ul",[t("li",[s._v("与没有缓存相比，进程内缓存的好处是，数据读取不再需要访问后端，例如数据库。")]),s._v(" "),t("li",[s._v("与进程外缓存相比（例如redis/memcache），进程内缓存省去了网络开销，所以一来节省了内网带宽，二来响应时延会更低。")])]),s._v(" "),t("p",[s._v("缺点：")]),s._v(" "),t("ul",[t("li",[s._v("数据存了多份，一致性比较难保障")])]),s._v(" "),t("h3",{attrs:{id:"如何保证进程内缓存的数据一致性"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#如何保证进程内缓存的数据一致性"}},[s._v("#")]),s._v(" 如何保证进程内缓存的数据一致性？")]),s._v(" "),t("ul",[t("li",[s._v("第一种方案，可以通过单节点通知其他节点。如上图：写请求发生在server1，在修改完自己内存数据与数据库中的数据之后，可以主动通知其他server节点，也修改内存的数据。")]),s._v(" "),t("li",[s._v("第二种方案，可以通过MQ通知其他节点。如上图，写请求发生在server1，在修改完自己内存数据与数据库中的数据之后，给MQ发布数据变化通知，其他server节点订阅MQ消息，也修改内存数据。")]),s._v(" "),t("li",[s._v("第三种方案，为了避免耦合，降低复杂性，干脆放弃了“实时一致性”，每个节点启动一个timer，定时从后端拉取最新的数据，更新内存缓存。在有节点更新后端数据，而其他节点通过timer更新数据之间，会读到脏数据。")])]),s._v(" "),t("h3",{attrs:{id:"为什么不能频繁使用进程内缓存"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#为什么不能频繁使用进程内缓存"}},[s._v("#")]),s._v(" 为什么不能频繁使用进程内缓存？")]),s._v(" "),t("p",[s._v("分层架构设计，有一条准则：站点层、服务层要做到无数据无状态，这样才能任意的加节点水平扩展，数据和状态尽量存储到后端的数据存储服务，例如数据库服务或者缓存服务。可以看到，站点与服务的进程内缓存，实际上违背了分层架构设计的无状态准则，故一般不推荐使用。")]),s._v(" "),t("h3",{attrs:{id:"什么时候可以使用进程内缓存"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#什么时候可以使用进程内缓存"}},[s._v("#")]),s._v(" 什么时候可以使用进程内缓存？")]),s._v(" "),t("ul",[t("li",[s._v("情况一，只读数据，可以考虑在进程启动时加载到内存。画外音：此时也可以把数据加载到redis / memcache，进程外缓存服务也能解决这类问题。")]),s._v(" "),t("li",[s._v("情况二，极其高并发的，如果透传后端压力极大的场景，可以考虑使用进程内缓存。例如，秒杀业务，并发量极高，需要站点层挡住流量，可以使用内存缓存。")]),s._v(" "),t("li",[s._v("情况三，一定程度上允许数据不一致业务。例如，有一些计数场景，运营场景，页面对数据一致性要求较低，可以考虑使用进程内页面缓存。末了，再次强调，进程内缓存的适用场景并不如redis/memcache广泛，不要为了炫技而使用。")])]),s._v(" "),t("h3",{attrs:{id:"选redis还是memcache"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#选redis还是memcache"}},[s._v("#")]),s._v(" 选redis还是memcache")]),s._v(" "),t("p",[s._v("原文地址：https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651961272&idx=1&sn=79ad515b013b0ffc33324db86ba0f834&chksm=bd2d02648a5a8b728db094312f55574ec521b30e3de8aacf1d2d948a3ac24dbf30e835089fa7&scene=21#wechat_redirect")]),s._v(" "),t("ul",[t("li",[s._v("复杂数据结构:value是哈希，列表，集合，有序集合这类复杂的数据结构时，会选择redis，因为mc无法满足这些需求。")]),s._v(" "),t("li",[s._v("持久化:mc无法满足持久化的需求，只得选择redis。但是，这里要提醒的是，真的使用对了redis的持久化功能么？千万不要把redis当作数据库用：")])]),s._v(" "),t("p",[s._v("（1）redis的定期快照不能保证数据不丢失")]),s._v(" "),t("p",[s._v("（2）redis的AOF会降低效率，并且不能支持太大的数据量")]),s._v(" "),t("h3",{attrs:{id:"缓存场景-开启固化功能-有什么利弊"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#缓存场景-开启固化功能-有什么利弊"}},[s._v("#")]),s._v(" 缓存场景，开启固化功能，有什么利弊？")]),s._v(" "),t("ul",[t("li",[s._v("优点是，redis挂了再重启，内存里能够快速恢复热数据，不会瞬时将压力压到数据库上，没有一个cache预热的过程。")]),s._v(" "),t("li",[s._v("缺点是，在redis挂了的过程中，如果数据库中有数据的修改，可能导致redis重启后，数据库与redis的数据不一致。")])]),s._v(" "),t("h3",{attrs:{id:"什么时候倾向于memcache"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#什么时候倾向于memcache"}},[s._v("#")]),s._v(" 什么时候倾向于memcache？")]),s._v(" "),t("p",[s._v("纯KV，数据量非常大，并发量非常大的业务，使用memcache或许更适合。这要从mc与redis的底层实现机制差异说起。")]),s._v(" "),t("ul",[t("li",[s._v("内存分配:memcache使用预分配内存池的方式管理内存，能够省去内存分配时间。redis则是临时申请空间，可能导致碎片。从这一点上，mc会更快一些。")]),s._v(" "),t("li",[s._v("虚拟内存使用:memcache把所有的数据存储在物理内存里。redis有自己的VM机制，理论上能够存储比物理内存更多的数据，当数据超量时，会引发swap，把冷数据刷到磁盘上。从这一点上，数据量大时，mc会更快一些。")]),s._v(" "),t("li",[s._v("网络模型:memcache使用非阻塞IO复用模型，redis也是使用非阻塞IO复用模型。但由于redis还提供一些非KV存储之外的排序，聚合功能，在执行这些功能时，复杂的CPU计算，会阻塞整个IO调度。从这一点上，由于redis提供的功能较多，mc会更快一些。")]),s._v(" "),t("li",[s._v("线程模型:memcache使用多线程，主线程监听，worker子线程接受请求，执行读写，这个过程中，可能存在锁冲突。redis使用单线程，虽无锁冲突，但难以利用多核的特性提升整体吞吐量。从这一点上，mc会快一些。")])]),s._v(" "),t("h3",{attrs:{id:"缓存-你真的用对了么"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#缓存-你真的用对了么"}},[s._v("#")]),s._v(" 缓存，你真的用对了么")]),s._v(" "),t("p",[s._v("原文地址：https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651961307&idx=1&sn=2ea36d014299c7870a0b40575578469e&chksm=bd2d02078a5a8b111d0caa649ae93f050ee6d4168c43322c2cf8cd8387becdd9b78a7202daa0&scene=21#wechat_redirect")]),s._v(" "),t("p",[s._v("误用一：把缓存作为服务与服务之间传递数据的媒介：")]),s._v(" "),t("ul",[t("li",[s._v("服务1和服务2约定好key和value，通过缓存传递数据")]),s._v(" "),t("li",[s._v("服务1将数据写入缓存，服务2从缓存读取数据，达到两个服务通信的目的")])]),s._v(" "),t("p",[s._v("该方案存在的问题是：")]),s._v(" "),t("ul",[t("li",[s._v("数据管道，数据通知场景，MQ更加适合")]),s._v(" "),t("li",[s._v("多个服务关联同一个缓存实例，会导致服务耦合")])]),s._v(" "),t("p",[s._v("误用二：使用缓存未考虑雪崩：")]),s._v(" "),t("p",[s._v("提前做容量预估，如果缓存挂掉，数据库仍能扛住，才能执行上述方案。")]),s._v(" "),t("ul",[t("li",[s._v("使用高可用缓存集群，一个缓存实例挂掉后，能够自动做故障转移。")]),s._v(" "),t("li",[s._v("使用缓存水平切分，一个缓存实例挂掉后，不至于所有的流量都压到数据库上。")])]),s._v(" "),t("p",[s._v("误用三：调用方缓存数据")]),s._v(" "),t("ul",[t("li",[s._v("服务提供方缓存，向调用方屏蔽数据获取的复杂性（这个没问题）")]),s._v(" "),t("li",[s._v("服务调用方，也缓存一份数据，先读自己的缓存，再决定是否调用服务（这个有问题）")])]),s._v(" "),t("p",[s._v("该方案存在的问题是：")]),s._v(" "),t("ul",[t("li",[s._v("调用方需要关注数据获取的复杂性")]),s._v(" "),t("li",[s._v("更严重的，服务修改db里的数据，淘汰了服务cache之后，难以通知调用方淘汰其cache里的数据，从而导致数据不一致")]),s._v(" "),t("li",[s._v("有人说，服务可以通过MQ通知调用方淘汰数据，额，难道下游的服务要依赖上游的调用方，分层架构设计不是这么玩的")])]),s._v(" "),t("h3",{attrs:{id:"淘汰缓存中的这些数据-修改缓存中的这些数据-有什么差别-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#淘汰缓存中的这些数据-修改缓存中的这些数据-有什么差别-2"}},[s._v("#")]),s._v(" 淘汰缓存中的这些数据，修改缓存中的这些数据，有什么差别？")]),s._v(" "),t("ul",[t("li",[s._v("淘汰某个key，操作简单，直接将key置为无效，但下一次该key的访问会cache miss")]),s._v(" "),t("li",[s._v("修改某个key的内容，逻辑相对复杂，但下一次该key的访问仍会cache hit")])]),s._v(" "),t("p",[s._v("可以看到，差异仅仅在于一次cache miss")]),s._v(" "),t("h3",{attrs:{id:"缓存中的value数据一般是怎么修改的-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#缓存中的value数据一般是怎么修改的-2"}},[s._v("#")]),s._v(" 缓存中的value数据一般是怎么修改的？")]),s._v(" "),t("ul",[t("li",[s._v("（1）朴素类型的数据，直接set修改后的值即可")]),s._v(" "),t("li",[s._v("（2）序列化后的对象：一般需要先get数据，反序列化成对象，修改其中的成员，再序列化为binary，再set数据")]),s._v(" "),t("li",[s._v("（3）json或者html数据：一般也需要先get文本，parse成doom树对象，修改相关元素，序列化为文本，再set数据")])])])}),[],!1,null,null,null);e.default=i.exports}}]);