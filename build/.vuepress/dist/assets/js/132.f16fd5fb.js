(window.webpackJsonp=window.webpackJsonp||[]).push([[132],{512:function(e,t,v){"use strict";v.r(t);var s=v(13),a=Object(s.a)({},(function(){var e=this,t=e.$createElement,v=e._self._c||t;return v("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[v("h2",{attrs:{id:"基础"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#基础"}},[e._v("#")]),e._v(" 基础")]),e._v(" "),v("h3",{attrs:{id:"_1、mysql选择b-树的原因"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_1、mysql选择b-树的原因"}},[e._v("#")]),e._v(" 1、mysql选择B+树的原因")]),e._v(" "),v("p",[e._v("1、那么Mysql如何衡量查询效率呢？磁盘IO次数，B-树（B类树）的特定就是每层节点数目非常多，层数很少，目的就是为了就少磁盘IO次数，当查询数据的时候，最好的情况就是很快找到目标索引，然后读取数据，使用B+树就能很好的完成这个目的，但是B-树的每个节点都有data域（指针），这无疑增大了节点大小，说白了增加了磁盘IO次数（磁盘IO一次读出的数据量大小是固定的，单个数据变大，每次读出的就少，IO次数增多，一次IO多耗时啊！），而B+树除了叶子节点其它节点并不存储数据，节点小，磁盘IO次数就少。这是优点之一。\n索引的数据大的话，会增加IO的次数，好费时间，索引通过B树能够最快的找到相关的索引。")]),e._v(" "),v("p",[e._v("2、B+树所有的Data域在叶子节点，一般来说都会进行一个优化，就是将所有的叶子节点用指针串起来。这样遍历叶子节点就能获得全部数据，这样就能进行区间访问啦。i")]),e._v(" "),v("h3",{attrs:{id:"_2、explain各个字段的涵义"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_2、explain各个字段的涵义"}},[e._v("#")]),e._v(" 2、explain各个字段的涵义")]),e._v(" "),v("p",[e._v("mysql> explain select * from servers;\n+----+-------------+---------+------+---------------+------+---------+------+------+-------+\n| id | select_type | table   | type | possible_keys | key  | key_len | ref  | rows | Extra |\n+----+-------------+---------+------+---------------+------+---------+------+------+-------+\n|  1 | SIMPLE      | servers | ALL  | NULL          | NULL | NULL    | NULL |    1 | NULL  |\n+----+-------------+---------+------+---------------+------+---------+------+------+-------+\nrow in set (0.03 sec)")]),e._v(" "),v("p",[e._v("expain出来的信息有10列，分别是id、select_type、table、type、possible_keys、key、key_len、ref、rows、Extra,下面对这些字段出现的可能进行解释：")]),e._v(" "),v("p",[e._v("一、 id  我的理解是SQL执行的顺序的标识,SQL从大到小的执行")]),e._v(" "),v("ol",[v("li",[e._v("id相同时，执行顺序由上至下")]),e._v(" "),v("li",[e._v("如果是子查询，id的序号会递增，id值越大优先级越高，越先被执行\n3.id如果相同，可以认为是一组，从上往下顺序执行；在所有组中，id值越大，优先级越高，越先执行")])]),e._v(" "),v("p",[e._v("二、select_type 表示查询中每个select子句的类型\n(1) SIMPLE(简单SELECT,不使用UNION或子查询等)\n(2) PRIMARY(查询中若包含任何复杂的子部分,最外层的select被标记为PRIMARY)\n(3) UNION(UNION中的第二个或后面的SELECT语句)\n(4) DEPENDENT UNION(UNION中的第二个或后面的SELECT语句，取决于外面的查询)\n(5) UNION RESULT(UNION的结果)\n(6) SUBQUERY(子查询中的第一个SELECT)\n(7) DEPENDENT SUBQUERY(子查询中的第一个SELECT，取决于外面的查询)\n(8) DERIVED(派生表的SELECT, FROM子句的子查询)\n(9) UNCACHEABLE SUBQUERY(一个子查询的结果不能被缓存，必须重新评估外链接的第一行)")]),e._v(" "),v("p",[e._v("三、table：显示这一行的数据是关于哪张表的，有时不是真实的表名字,看到的是derivedx(x是个数字,我的理解是第几步执行的结果)\nmysql> explain select * from (select * from ( select * from t1 where id=2602) a) b;\n+----+-------------+------------+--------+-------------------+---------+---------+------+------+-------+\n| id | select_type | table      | type   | possible_keys     | key     | key_len | ref  | rows | Extra |\n+----+-------------+------------+--------+-------------------+---------+---------+------+------+-------+\n|  1 | PRIMARY     | "),v("derived2",[e._v(" | system | NULL              | NULL    | NULL    | NULL |    1 |       |\n|  2 | DERIVED     | "),v("derived3",[e._v(" | system | NULL              | NULL    | NULL    | NULL |    1 |       |\n|  3 | DERIVED     | t1         | const  | PRIMARY,idx_t1_id | PRIMARY | 4       |      |    1 |       |\n+----+-------------+------------+--------+-------------------+---------+---------+------+------+-------+")])],1)],1),e._v(" "),v("p",[e._v("四、type：表示MySQL在表中找到所需行的方式，又称“访问类型”。")]),e._v(" "),v("p",[e._v("常用的类型有： ALL, index,  range, ref, eq_ref, const, system, NULL（从左到右，性能从差到好）\n1、ALL：Full Table Scan， MySQL将遍历全表以找到匹配的行\n2、index: Full Index Scan，index与ALL区别为index类型只遍历索引树\n3、range:只检索给定范围的行，使用一个索引来选择行\n4、ref: 表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值\n5、eq_ref: 类似ref，区别就在使用的索引是唯一索引，对于每个索引键值，表中只有一条记录匹配，简单来说，就是多表连接中使用primary key或者 unique key作为关联条件\n6、const、system: 当MySQL对查询某部分进行优化，并转换为一个常量时，使用这些类型访问。如将主键置于where列表中，MySQL就能将该查询转换为一个常量,system是const类型的特例，当查询的表只有一行的情况下，使用system\n6、NULL: MySQL在优化过程中分解语句，执行时甚至不用访问表或索引，例如从一个索引列里选取最小值可以通过单独索引查找完成。")]),e._v(" "),v("p",[e._v("五、possible_keys：指出MySQL能使用哪个索引在表中找到记录，查询涉及到的字段上若存在索引，则该索引将被列出，但不一定被查询使用。\n该列完全独立于EXPLAIN输出所示的表的次序。这意味着在possible_keys中的某些键实际上不能按生成的表次序使用。如果该列是NULL，则没有相关的索引。在这种情况下，可以通过检查WHERE子句看是否它引用某些列或适合索引的列来提高你的查询性能。如果是这样，创造一个适当的索引并且再次用EXPLAIN检查查询")]),e._v(" "),v("p",[e._v("六、Key：key列显示MySQL实际决定使用的键（索引）\n如果没有选择索引，键是NULL。要想强制MySQL使用或忽视possible_keys列中的索引，在查询中使用FORCE INDEX、USE INDEX或者IGNORE INDEX。")]),e._v(" "),v("p",[e._v("七、key_len：表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度（key_len显示的值为索引字段的最大可能长度，并非实际使用长度，即key_len是根据表定义计算而得，不是通过表内检索出的）不损失精确性的情况下，长度越短越好")]),e._v(" "),v("p",[e._v("八、ref：表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值")]),e._v(" "),v("p",[e._v("九、rows：表示MySQL根据表统计信息及索引选用情况，估算的找到所需的记录所需要读取的行数")]),e._v(" "),v("h3",{attrs:{id:"_3、怎么截取一部分作为索引"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_3、怎么截取一部分作为索引"}},[e._v("#")]),e._v(" 3、怎么截取一部分作为索引：")]),e._v(" "),v("p",[e._v("下边的就是在创建表的时候指定，name的前10个字段\nCREATE TABLE person_info(\nname VARCHAR(100) NOT NULL,\nbirthday DATE NOT NULL,\nphone_number CHAR(11) NOT NULL,\ncountry varchar(100) NOT NULL,\nKEY idx_name_age_birthday (name(10), birthday, phone_number)\n);")]),e._v(" "),v("p",[e._v("下边是其他字段的情况说明\nCREATE TABLE "),v("code",[e._v("hc_project_vote")]),e._v(" (\n"),v("code",[e._v("rcd_id")]),e._v(" INT (11) NOT NULL AUTO_INCREMENT COMMENT 'id',\n"),v("code",[e._v("create_time")]),e._v(" datetime COMMENT '创建时间',\n"),v("code",[e._v("update_time")]),e._v(" datetime COMMENT '更新时间',\n"),v("code",[e._v("sn")]),e._v(" VARCHAR (30) DEFAULT '' COMMENT 'sn',\n"),v("code",[e._v("project_sn")]),e._v(" VARCHAR (30) DEFAULT '' COMMENT '项目sn',\n"),v("code",[e._v("user_sn")]),e._v(" VARCHAR (30) DEFAULT '' COMMENT '投票者sn',\n"),v("code",[e._v("vote_time")]),e._v(" datetime COMMENT '投票时间',\n"),v("code",[e._v("visit_ip")]),e._v(" VARCHAR (15) DEFAULT '' COMMENT '投票者ip',\nPRIMARY KEY ("),v("code",[e._v("rcd_id")]),e._v("),\nKEY "),v("code",[e._v("idx_hc_vote_project_sn")]),e._v(" ("),v("code",[e._v("project_sn")]),e._v(") USING BTREE,\nKEY "),v("code",[e._v("idx_hc_vote_user_sn")]),e._v(" ("),v("code",[e._v("user_sn")]),e._v(") USING BTREE\n)ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT '项目投票记录表';")]),e._v(" "),v("p",[e._v("UNIQUE是可选参数，表示索引为唯一性索引；FULLTEXT是可选参数，表示索引为全文索引；SPATIAL也是可选参数，表示索引为空间索引；INDEX和KEY参数用来指定字段为索引的，两者选择其中之一就可以了，作用是一样的；")]),e._v(" "),v("h3",{attrs:{id:"_4、联合索引的数据结构"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_4、联合索引的数据结构"}},[e._v("#")]),e._v(" 4、联合索引的数据结构")]),e._v(" "),v("p",[e._v("极好的文章：https://m.jb51.net/article/99940.htm\nMyisaM叶子节点存储的是位置的索引")]),e._v(" "),v("p",[e._v("MyISAM的索引方式也叫做“非聚集”的，之所以这么称呼是为了与InnoDB的聚集索引区分。")]),e._v(" "),v("p",[e._v("而在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。")]),e._v(" "),v("p",[e._v("聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。\n第二个与MyISAM索引的不同是InnoDB的辅助索引data域存储相应记录主键的值而不是地址。换句话说，InnoDB的所有辅助索引都引用主键作为data域。")]),e._v(" "),v("p",[e._v("知道了InnoDB的索引实现后，就很容易明白为什么不建议使用过长的字段作为主键，因为所有辅助索引都引用主索引，过长的主索引会令辅助索引变得过大。再例如，用非单调的字段作为主键在InnoDB中不是个好主意，因为InnoDB数据文件本身是一颗B+Tree，非单调的主键会造成在插入新记录时数据文件为了维持B+Tree的特性而频繁的分裂调整，十分低效，而使用自增字段作为主键则是一个很好的选择。")]),e._v(" "),v("h3",{attrs:{id:"_5、b-的特点"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_5、b-的特点"}},[e._v("#")]),e._v(" 5、B+的特点")]),e._v(" "),v("p",[e._v("与B-Tree相比，B+Tree有以下不同点：")]),e._v(" "),v("ol",[v("li",[e._v("每个节点的指针上限为2d而不是2d+1。")]),e._v(" "),v("li",[e._v("内节点不存储data，只存储key；叶子节点不存储指针。")])]),e._v(" "),v("p",[e._v("在B+Tree的每个叶子节点增加一个指向相邻叶子节点的指针，就形成了带有顺序访问指针的B+Tree。做这个优化的目的是为了提高区间访问的性能，例如图4中如果要查询key为从18到49的所有数据记录，当找到18后，只需顺着节点和指针顺序遍历就可以一次性访问到所有数据节点，极大提到了区间查询效率。")]),e._v(" "),v("h3",{attrs:{id:"_5、磁盘存取原理"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_5、磁盘存取原理"}},[e._v("#")]),e._v(" 5、磁盘存取原理")]),e._v(" "),v("p",[e._v("当需要从磁盘读取数据时，系统会将数据逻辑地址传给磁盘，磁盘的控制电路按照寻址逻辑将逻辑地址翻译成物理地址，即确定要读的数据在哪个磁道，哪个扇区。为了读取这个扇区的数据，需要将磁头放到这个扇区上方，为了实现这一点，磁头需要移动对准相应磁道，这个过程叫做寻道，所耗费时间叫做寻道时间，然后磁盘旋转将目标扇区旋转到磁头下，这个过程耗费的时间叫做旋转时间。")]),e._v(" "),v("p",[e._v("由于存储介质的特性，磁盘本身存取就比主存慢很多，再加上机械运动耗费，磁盘的存取速度往往是主存的几百分分之一，因此为了提高效率，要尽量减少磁盘I/O。为了达到这个目的，磁盘往往不是严格按需读取，而是每次都会预读，即使只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存。这样做的理论依据是计算机科学中著名的局部性原理：当一个数据被用到时，其附近的数据也通常会马上被使用。")]),e._v(" "),v("p",[e._v("上文说过，索引一般以文件形式存储在磁盘上，索引检索需要磁盘I/O操作。与主存不同，磁盘I/O存在机械运动耗费，因此磁盘I/O的时间消耗是巨大的。")]),e._v(" "),v("h3",{attrs:{id:"_6、一张表-里面有id自增主键-当insert了17条记录之后-删除了第15-16-17条记录-再把mysql重启-再insert一条记录-这条记录的id是18还是15"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_6、一张表-里面有id自增主键-当insert了17条记录之后-删除了第15-16-17条记录-再把mysql重启-再insert一条记录-这条记录的id是18还是15"}},[e._v("#")]),e._v(" 6、一张表，里面有ID自增主键，当insert了17条记录之后，删除了第15,16,17条记录，再把Mysql重启，再insert一条记录，这条记录的ID是18还是15 ？")]),e._v(" "),v("p",[e._v("1、一般情况下，我们创建的表的类型是InnoDB，如果新增一条记录（不重启mysql的情况下），这条记录的id是18；但是如果重启（文中提到的）MySQL的话，这条记录的ID是15。因为InnoDB表只把自增主键的最大ID记录到内存中，所以重启数据库或者对表OPTIMIZE操作，都会使最大ID丢失\n2、但是，如果我们使用表的类型是MylSAM，那么这条记录的ID就是18。因为MylSAM表会把自增主键的最大ID记录到数据文件里面，重启MYSQL后，自增主键的最大ID也不会丢失。")]),e._v(" "),v("h3",{attrs:{id:"_7、什么时候会用行级锁"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_7、什么时候会用行级锁"}},[e._v("#")]),e._v(" 7、什么时候会用行级锁？")]),e._v(" "),v("p",[e._v("1、MyISM采用表级锁，对Myism表读不会阻塞读，会阻塞同表写，对Myism写则会阻塞读和写，即一个线程获得1个表的写锁后，只有持有锁的线程可以对表更新操作，其他线程的读和写都会等待。")]),e._v(" "),v("p",[e._v("2、InnoDB，采用行级锁，支持事务，例如只对a列加索引，如果update ...where a=1 and b=2其实也会锁整个表， select 使用共享锁，update insert delete采用排它锁，commit会把锁取消，当然select by id for update也可以制定排它锁。")]),e._v(" "),v("h3",{attrs:{id:"_8、最左前缀匹配原则"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_8、最左前缀匹配原则"}},[e._v("#")]),e._v(" 8、最左前缀匹配原则")]),e._v(" "),v("p",[e._v("https://segmentfault.com/a/1190000015416513\nhttps://tech.meituan.com/2014/06/30/mysql-index.html")]),e._v(" "),v("h3",{attrs:{id:"mysql-5-7-19版本的索引长度上限是多少-以及为什么"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#mysql-5-7-19版本的索引长度上限是多少-以及为什么"}},[e._v("#")]),e._v(" mysql 5.7.19版本的索引长度上限是多少?以及为什么")]),e._v(" "),v("p",[e._v("原文地址")]),e._v(" "),v("p",[e._v("https://blog.csdn.net/qsc0624/article/details/51335632")]),e._v(" "),v("ul",[v("li",[v("p",[e._v("所有存储引擎支持每个表至少16个索引，一个索引最大可以包含16个列。")])]),e._v(" "),v("li",[v("p",[e._v("innodb 767字节；mya 1000字节；InnoDB单列索引长度不能超过767bytes，联合索引还有一个限制是长度不能超过3072。")])]),e._v(" "),v("li",[v("p",[e._v("不同的字符集，latin1编码一个字符一个字节，gbk编码的为一个字符2个字节，utf8编码的一个字符3个字节。（257个字符）")])])]),e._v(" "),v("p",[e._v("我们在设计数据库时，最好不要在一个可能包含很长字符串的列上创建索引，尤其是当这个列中的字符串都很长时。如果在这类列上创建了索引，那么在创建索引时以及根据索引查询时，都会浪费很多时间在计算和存储上。有经验的设计人员应该不会这样设计数据库。")]),e._v(" "),v("p",[e._v("为什么3072，我们知道InnoDB一个page的默认大小是16k。由于是Btree组织，要求叶子节点上一个page至少要包含两条记录（否则就退化链表了）。** 所以一个记录最多不能超过8k。** 又由于InnoDB的聚簇索引结构，一个二级索引要包含主键索引，因此每个单个索引不能超过4k （极端情况，pk和某个二级索引都达到这个限制）。由于需要预留和辅助空间，扣掉后不能超过3500，取个“整数”就是(1024*3)。 至于为什么字符长度限制在 256 内，我猜是为提高索引效率，应为varchar类型需要额外的字节保留其长度信息，256 就将其限定在一个字节了")]),e._v(" "),v("h3",{attrs:{id:"b树和b-树的区别"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#b树和b-树的区别"}},[e._v("#")]),e._v(" b树和B+树的区别")]),e._v(" "),v("p",[e._v("B树事实上是一种平衡的多叉查找树，也就是说最多可以开m个叉（m>=2），我们称之为m阶b树；B树的查询过程和二叉排序树比较类似，从根节点依次比较每个结点，因为每个节点中的关键字和左右子树都是有序的，所以只要比较节点中的关键字，或者沿着指针就能很快地找到指定的关键字，如果查找失败，则会返回叶子节点，即空指针。")]),e._v(" "),v("p",[e._v("作为B树的加强版，B+树与B树的差异在于")]),e._v(" "),v("ul",[v("li",[e._v("有n棵子树的节点含有n个关键字（也有认为是n-1个关键字）。")]),e._v(" "),v("li",[e._v("所有的关键字全部存储在叶子节点上，且叶子节点本身根据关键字自小而大顺序连接。")]),e._v(" "),v("li",[e._v("非叶子节点可以看成索引部分，节点中仅含有其子树（根节点）中的最大（或最小）关键字。")])]),e._v(" "),v("p",[e._v("另外一种说法：")]),e._v(" "),v("ul",[v("li",[e._v("B+树中只有叶子节点会带有指向记录的指针（ROWID），而B树则所有节点都带有，在内部节点出现的索引项不会再出现在叶子节点中。（数据有没有在叶子中）")]),e._v(" "),v("li",[e._v("B+树中所有叶子节点都是通过指针连接在一起，而B树不会。")]),e._v(" "),v("li",[e._v("层级更低，IO 次数更少")])]),e._v(" "),v("h3",{attrs:{id:"索引设计原则"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#索引设计原则"}},[e._v("#")]),e._v(" 索引设计原则")]),e._v(" "),v("p",[e._v("原文地址：")]),e._v(" "),v("p",[e._v("https://segmentfault.com/a/1190000012612232")]),e._v(" "),v("ul",[v("li",[e._v("索引并非越多越好，一个表中如有大量的索引，不仅占用磁盘空间，而且会影响INSERT、DELETE、UPDATE等语句的性能，因为当表中的数据更改的同时，索引也会进行调整和更新")]),e._v(" "),v("li",[e._v("避免对经常更新的表设计过多的索引，并且索引中的列尽可能要少，而对经常用于查询的字段应该创建索引，但要避免添加不必要的字段")]),e._v(" "),v("li",[e._v("数据量小的表最好不要使用索引，由于数据较少，查询花费的时间可能比遍历索引时间还要短，索引可能不会产生优化效果")]),e._v(" "),v("li",[e._v("在条件表达式中经常用到的不同值较多的列上建立索引，在不同值较少的列上不要建立索引，比如性别字段只有男和女，就没必要建立索引。如果建立索引不但不会提高查询效率，反而会严重降低更新速度")]),e._v(" "),v("li",[e._v("当唯一性是某种数据本身的特征时，指定唯一索引。使用唯一索引需能确保定义的列的数据完整性，以提高查询速度")]),e._v(" "),v("li",[e._v("在频繁排序或分组（即group by或order by操作）的列上建立索引，如果待排序的列有多个，可以在这些列上建立组合索引")]),e._v(" "),v("li",[e._v("创建联合索引时，值差异化大的列放在前面，而不是那些取值种类很少的列。")]),e._v(" "),v("li",[e._v("索引不是定义的越多越好，对于查询条件比较多的情况，避免为每个字段创建索引，只需要创建一个联合索引即可。创建联合索引时，把可能存在单列查询的那一列放前面。")]),e._v(" "),v("li",[e._v("可以认为Mysql在执行SQL语句时，一个表只可能使用一个索引（开启了Index Merge的情况除外）。新人在建表的时候总是会忽略这个事实，从而为很多列单独建立了索引，认为这样会更快。")])]),e._v(" "),v("h3",{attrs:{id:"myisam和innodb区别"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#myisam和innodb区别"}},[e._v("#")]),e._v(" MyISAM和Innodb区别")]),e._v(" "),v("p",[e._v("原文地址：https://www.tbwork.org/2017/05/31/mysql-index-mechanism/")]),e._v(" "),v("ul",[v("li",[e._v("MyISAM不支持事务，而Innodb支持。")]),e._v(" "),v("li",[e._v("MyISAM是非聚集索引，而Innodb则是聚集索引。")]),e._v(" "),v("li",[e._v("MyISAM索引和数据的存储是分开的（不同的文件），索引中最终检索到的是数据的物理地址偏移量。而InnoDB中，索引段和数据段在同一个文件中的不同段，查到索引后可以直接取出数据。")])]),e._v(" "),v("h3",{attrs:{id:"什么时候会全表扫描"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#什么时候会全表扫描"}},[e._v("#")]),e._v(" 什么时候会全表扫描")]),e._v(" "),v("ul",[v("li",[e._v("1.目标数据表太小了，再去查找索引（key lookup）太麻烦了（有点杀鸡焉用牛刀的即视感）。这通常发生在10行都不到的数据表，并且每行很短的情况。（注： 10这个数字不可靠，这里只是感性的说了个数字，可能小几十行的数据仍然会触发全表扫描。）")]),e._v(" "),v("li",[e._v("2.查询条件中的字段（WHERE后）没有匹配到索引的情况。（也不是说匹配不到就一定会全表扫描，见下文默认索引选择算法）")]),e._v(" "),v("li",[e._v("3.查询条件中的字段与某个常量比较时（就比如where age > 8)，并且使用这个常量值与对应索引筛选出的记录数占了总数的大部分。优化器认为扫这么大的数据还不如扫全表了，所以选择了扫描全表。大部分怎么定义恐怕只有Mysql开发者才知道，官网也并没有给出具体数值。")]),e._v(" "),v("li",[e._v("4.查询语句匹配到的索引对应的基数太小（对应SHOW INDEX FROM table_name结果中的Cardinality )，并且此时又有其他列上的查询条件（比如:select * from user where user_status > 0 and username =’tommy’）。所谓基数就是表中某列所有值的取值种数，比如一张表有5行，某一列对应的值分别为：1,2,3,3,2。那么该列基数就是3，因为一共有三种取值：1,2,3。 基数小，意味着该索引中每个索引值对应的目标记录数很大，在这个索引值对应的记录数中再去一个个的检查其他列上的条件是否满足，整个过程总体的查找速度还未必有全表扫描来得快。")])]),e._v(" "),v("h3",{attrs:{id:"b-树中所有叶子节点都是通过指针连接在一起的好处"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#b-树中所有叶子节点都是通过指针连接在一起的好处"}},[e._v("#")]),e._v(" B+树中所有叶子节点都是通过指针连接在一起的好处")]),e._v(" "),v("p",[e._v("在经典B+Tree的基础上进行了优化，增加了顺序访问指针。在B+Tree的每个叶子节点增加一个指向相邻叶子节点的指针，就形成了带有顺序访问指针的B+Tree。这样就提高了区间访问性能：如果要查询key为从18到49的所有数据记录，当找到18后，只需顺着节点和指针顺序遍历就可以一次性访问到所有数据节点，极大提到了区间查询效率(无需返回上层父节点重复遍历查找减少IO操作)。")]),e._v(" "),v("h3",{attrs:{id:"b-树的插入过程"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#b-树的插入过程"}},[e._v("#")]),e._v(" B+树的插入过程")]),e._v(" "),v("p",[e._v("https://www.cnblogs.com/nullzx/p/8729425.html")]),e._v(" "),v("p",[e._v("https://kyle.ai/blog/6439.html")]),e._v(" "),v("p",[e._v("B+树的分裂：当一个结点满时，分配一个新的结点，并将原结点中1/2的数据复制到新结点，最后在父结点中增加新结点的指针；B+树的分裂只影响原结点和父结点，而不会影响兄弟结点，所以它不需要指向兄弟节点的指针")]),e._v(" "),v("p",[e._v("B树的分裂，下图的红色值即为每次新插入的节点。每当一个节点满后，就需要发生分裂（分裂是一个递归过程，参考下面7的插入导致了两层分裂），由于B树的非叶子节点同样保存了键值，所以已满节点分裂后的值将分布在三个地方：1原节点，2原节点的父节点，3原节点的新建兄弟节点（参考5，7的插入过程）。分裂有可能导致树的高度增加（参考3，7的插入过程），也可能不影响树的高度（参考5，6的插入过程）。")]),e._v(" "),v("p",[e._v("a）在空树中插入39：此时根结点就一个key，此时根结点也是叶子结点")]),e._v(" "),v("p",[e._v("b）继续插入22，97和41：根结点此时有4个key")]),e._v(" "),v("p",[e._v("c）继续插入53：插入后超过了最大允许的关键字个数4，所以以key值为41为中心进行分裂，结果如下图所示，分裂后当前结点指针指向父结点，满足B树条件，插入操作结束。当阶数m为偶数时，需要分裂时就不存在排序恰好在中间的key，那么我们选择中间位置的前一个key或中间位置的后一个key为中心进行分裂即可。")]),e._v(" "),v("p",[e._v("d）依次插入13，21，40，同样会造成分裂，结果如下图所示。")]),e._v(" "),v("p",[e._v("e）依次插入30，27, 33 ；36，35，34 ；24，29，结果如下图所示。")]),e._v(" "),v("p",[e._v("f）插入key值为26的记录，插入后的结果如下图所示。当前结点需要以27为中心分裂，并向父结点进位27，然后当前结点指向父结点，结果如下图所示。进位后导致当前结点（即根结点）也需要分裂，分裂的结果如下图所示。分裂后当前结点指向新的根，此时无需调整。")]),e._v(" "),v("h3",{attrs:{id:"索引原理"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#索引原理"}},[e._v("#")]),e._v(" 索引原理")]),e._v(" "),v("p",[e._v("https://kyle.ai/blog/6439.html")]),e._v(" "),v("p",[e._v("https://icell.io/how-mysql-index-works/")]),e._v(" "),v("p",[e._v("具体怎么存储的,这个表中我们有 (name, age, gender) 这个联合索引，这个索引的结构大概如下图所示：")]),e._v(" "),v("p",[v("img",{attrs:{src:"https://txxs.github.io/pic/tofutureinterview/1-2.png",alt:"1"}})]),e._v(" "),v("p",[e._v("这个是连起来的，在上面的叶子节点下，假设有多个名为 BX 和 iCell 的员工，他们的年龄都不太一样，是先按照 name 排序，再按照 age 进行排序。")]),e._v(" "),v("div",{staticClass:"language- line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("SELECT * FROM employees WHERE name='BX' AND age=19 AND gender=0;\n")])]),e._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[e._v("1")]),v("br")])]),v("p",[e._v("上述这种查询，根据 (name, age, gender) 这个索引树来查找，找到 id 为 2 的索引数据符合条件，然后通过相邻的节点链接继续查找，发现下一个数据不符合条件，最终命中索引的就是 id 为 2 的这一条数据，因为是要查找行的所有数据，所以再根据 id 为 2 去主键索引树中继续回表查找，得到结果数据。")]),e._v(" "),v("h3",{attrs:{id:"主索引和辅助索引"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#主索引和辅助索引"}},[e._v("#")]),e._v(" 主索引和辅助索引")]),e._v(" "),v("ul",[v("li",[v("p",[e._v("主索引：包含记录的文件按照某个 key 制定的顺序排序，这个 key 就是主索引，也就是主键，也被称为聚簇索引。因为无法同时把数据行存放在两个不同的地方，所以一个表只能有一个聚集索引。在 InnoDB 中，主索引的叶子节点存的是整行数据，这也意味着 InnoDB 中的表一定要有一个主索引；")])]),e._v(" "),v("li",[v("p",[e._v("辅助索引：某个 key 指定的顺序与文件记录的物理顺序不同，这个 key 就是辅助索引。InnoDB 中的辅助索引在叶子节点中并不存储实际的数据，只会包含主索引的值 。这就意味着如果使用辅助索引进行数据的查找，只能查到主索引，然后根据这个主索引再次扫描以下主索引的树，进行一次回表操作；")])])]),e._v(" "),v("h3",{attrs:{id:"页分裂"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#页分裂"}},[e._v("#")]),e._v(" 页分裂")]),e._v(" "),v("p",[e._v("原文地址：https://icell.io/how-mysql-index-works/")]),e._v(" "),v("p",[e._v("前面说到，InnoDB 中数据是存储在数据页中的，而数据是按照索引的顺序插入到数据页中的，所以数据是紧凑排序的，但如果随机对数据进行插入，就有可能导致数据页分裂的问题。")]),e._v(" "),v("p",[e._v("假设一个数据页只能存储 3 条数据，且已经有 3 条数据（100， 200， 300）了，这时候想插入一条 150 的数据，就会再申请一个新的数据页，100，150 两条数据存放在原来的数据页中，200 和 300 存放在新的数据页中，这样可能会存在数据页利用率不高的问题。")]),e._v(" "),v("p",[e._v("不仅仅是插入数据会导致上述问题，删除数据也会。这里要注意，如果删除掉了一个数据页中的某条数据，这条数据所留下的位置并不会缩小而是等待复用，如果是一整个页的数据被删除了，那这个页也是出于被复用状态。如果相邻的两个数据页的利用率很小，系统会把这两个页的数据合到其中一个页上，另一个页就处于可被复用的状态。所以通过 delete 删除数据并不会回收表空间。")]),e._v(" "),v("p",[e._v("为了解决频繁删除数据导致的没有回收表空间的问题，可以通过重建表来解决，比如以下命令：")]),e._v(" "),v("div",{staticClass:"language- line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("alter table table_name engin=InnoDB;\n")])]),e._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[e._v("1")]),v("br")])]),v("p",[e._v("这个命令的流程基本上是：")]),e._v(" "),v("ul",[v("li",[e._v("新建一个临时表，结果同原表相同；")]),e._v(" "),v("li",[e._v("按照主键 id 递增的顺序将数据从原表读出插入到新表中；")]),e._v(" "),v("li",[e._v("用新的表替换旧表，删除旧表；\n所以我们使用 AUTO INCREMENT 主键的插入数据模式，正符合了递增插入的场景。每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。")])]),e._v(" "),v("h3",{attrs:{id:"b-树和hash索引区别"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#b-树和hash索引区别"}},[e._v("#")]),e._v(" B-树和Hash索引区别")]),e._v(" "),v("p",[e._v("原文地址：https://blog.csdn.net/maybe3is3u5/article/details/52426401")]),e._v(" "),v("p",[e._v("MySQL中，只有HEAP/MEMORY引擎才显示支持哈希索引。而常用的InnoDB引擎中默认使用的是B+树索引，它会实时监控表上索引的使用情况，如果认为建立哈希索引可以提高查询效率，则自动在内存中的“自适应哈希索引缓冲区”建立哈希索引（在InnoDB中默认开启自适应哈希索引），通过观察搜索模式，MySQL会利用index key的前缀建立哈希索引，如果一个表几乎大部分都在缓冲池中，那么建立一个哈希索引能够加快等值查询。")]),e._v(" "),v("p",[e._v("hash是key,value形式，通过一个散列函数，能够根据key快速找到value")]),e._v(" "),v("p",[e._v('1. Hash索引仅仅能满足"=","IN"和"<=>"查询，不能使用范围查询。因为经过相应的Hash算法处理之后的Hash值的大小关系，并不能保证和Hash运算前完全一样；')]),e._v(" "),v("p",[e._v("2. Hash索引无法被用来避免数据的排序操作。因为Hash值的大小关系并不一定和Hash运算前的键值完全一样；")]),e._v(" "),v("p",[e._v("3. Hash索引不能利用部分索引键查询。对于组合索引，Hash索引在计算Hash值的时候是组合索引键合并后再一起计算Hash值，而不是单独计算Hash值，所以通过组合索引的前面一个或几个索引键进行查询的时候，Hash索引也无法被利用；")]),e._v(" "),v("p",[e._v("4. Hash索引在任何时候都不能避免表扫描。由于不同索引键存在相同Hash值，所以即使取满足某个Hash键值的数据的记录条数，也无法从Hash索引中直接完成查询，还是要回表查询数据；")]),e._v(" "),v("p",[e._v("5. Hash索引遇到大量Hash值相等的情况后性能并不一定就会比B+树索引高。")]),e._v(" "),v("p",[e._v("哈希索引的优势：")]),e._v(" "),v("p",[e._v("（1）等值查询。哈希索引具有绝对优势（前提是：没有大量重复键值，如果大量重复键值时，哈希索引的效率很低，因为存在所谓的哈希碰撞问题。）")]),e._v(" "),v("p",[e._v("哈希索引不适用的场景：")]),e._v(" "),v("p",[e._v("（1）不支持范围查询")]),e._v(" "),v("p",[e._v("（2）不支持索引完成排序")]),e._v(" "),v("p",[e._v("（3）不支持联合索引的最左前缀匹配规则")]),e._v(" "),v("h3",{attrs:{id:"大于等于-走不走索引-最左前缀"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#大于等于-走不走索引-最左前缀"}},[e._v("#")]),e._v(" 大于等于,走不走索引,最左前缀")]),e._v(" "),v("p",[e._v("< 小于 > 大于 <= >= 这个根据实际查询数据来判断，如果全盘扫描速度比索引速度要快则不走索引。大于或小于操作符一般情况下是不用调整的，因为它有索引就会采用索引查找，但有的情况下可以对它进行优化，如一个表有100万记录，一个数值型字段 A，30万记录的A=0，30万记录的A=1，39万记录的A=2，1万记录的A=3。那么执行A>2与A>=3的效果就有很大的区别了，因为A>2时ORACLE会先找出为2的记录索引再进行比较，而A>=3时ORACLE则直接找到=3的记录索引。")]),e._v(" "),v("p",[e._v("因为本来就走的比较，大于等于也是比较，二叉树的比较")]),e._v(" "),v("h3",{attrs:{id:"sql中索引未使用的情况"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#sql中索引未使用的情况"}},[e._v("#")]),e._v(" SQL中索引未使用的情况")]),e._v(" "),v("p",[e._v("原文地址：https://www.douban.com/group/topic/94157455/")]),e._v(" "),v("ol",[v("li",[e._v("查询谓词没有使用索引的主要边界,换句话说就是select *，可能会导致不走索引")])]),e._v(" "),v("p",[e._v("比如，你查询的是SELECT * FROM T WHERE Y=XXX;假如你的T表上有一个包含Y值的组合索引，但是优化器会认为需要一行行的扫描会更有效，这个时候，优化器可能会选择TABLE ACCESS FULL。但是如果换成了SELECT Y FROM T WHERE Y = XXX，优化器会直接去索引中找到Y的值，因为从B树中就可以找到相应的值。")]),e._v(" "),v("ol",{attrs:{start:"2"}},[v("li",[e._v("单键值的b树索引列上存在null值，导致COUNT(*)不能走索引")])]),e._v(" "),v("p",[e._v("如果在B树索引中有一个空值，那么查询诸如SELECT COUNT("),v("em",[e._v(") FROM T 的时候，因为HASHSET中不能存储空值的，所以优化器不会走索引。有两种方式可以让索引有效，一种是SELECT COUNT(")]),e._v(") FROM T WHERE XXX IS NOT NULL，或者把这个列的属性改为not null （不能为空）。")]),e._v(" "),v("ol",{attrs:{start:"3"}},[v("li",[e._v("索引列上有函数运算，导致不走索引")])]),e._v(" "),v("p",[e._v("如果在T表上有一个索引Y，但是你的查询语句是这样子：SELECT * FROM T WHERE FUN(Y) = XXX，这个时候索引也不会被用到。因为你要查询的列中所有的行都需要被计算一遍，因此，如果要让这种SQL语句的效率提高的话，在这个表上建立一个基于函数的索引，比如CREATE INDEX IDX FUNT ON T(FUN(Y))，这种方式，等于Oracle会建立一个存储所有函数计算结果的值，再进行查询的时候就不需要进行计算了。因为很多函数存在不同返回值，因此必须标明这个函数是有固定返回值的。")]),e._v(" "),v("ol",{attrs:{start:"4"}},[v("li",[e._v("隐式转换导致不走索引")])]),e._v(" "),v("p",[e._v("索引不适用于隐式转换的情况。比如你的SELECT * FROM T WHERE Y = 5 在Y上面有一个索引，但是Y列是VARCHAR2的，那么Oracle会将上面的5进行一个隐式的转换，SELECT * FROM T WHERE TO_NUMBER(Y) = 5，这个时候也是有可能用不到索引的。")]),e._v(" "),v("ol",{attrs:{start:"5"}},[v("li",[e._v("表的数据库小或者需要选择大部分数据，不走索引")])]),e._v(" "),v("p",[e._v("在Oracle的初始化参数中，有一个参数是一次读取的数据块的数目，比如你的表只有几个数据块大小，而且可以被Oracle一次性抓取，那么就没有使用索引的必要了。因为抓取索引还需要根据rowid从数据块中获取相应的元素值，因此在表特别小的情况下，索引没有用到是情理当中的事情。")]),e._v(" "),v("ol",{attrs:{start:"6"}},[v("li",[e._v("cbo优化器下统计信息不准确，导致不走索引")])]),e._v(" "),v("p",[e._v("当很长时间没有做表分析，或者重新收集表状态信息时，在数据字典中，表的统计信息是不准确的。这个情况下，可能会使用错误的索引，这个效率可能也是比较低的。")]),e._v(" "),v("ol",{attrs:{start:"7"}},[v("li",[e._v("！=或者<>(不等于），可能导致不走索引，也可能走INDEX FAST FULL SCAN")])]),e._v(" "),v("p",[e._v("例如select id from test where id<>100。")]),e._v(" "),v("ol",{attrs:{start:"8"}},[v("li",[e._v("表字段的属性导致不走索引，字符型的索引列会导致优化器认为需要扫描索引大部分数据且聚簇因子很大，最终导致弃用索引扫描而改用全表扫描方式")])]),e._v(" "),v("p",[e._v("由于字符型和数值型的在insert的时候排序不同，字符类型导致了聚簇因子很大，原因是插入顺序与排序顺序不同。详细点说，就是按照数字类型插入（1..3200000），按字符类型（'1'...'32000000'）t排序，在对字符类型使用大于运算符时，会导致优化器认为需要扫描索引大部分数据且聚簇因子很大，最终导致弃用索引扫描而改用全表扫描方式。")]),e._v(" "),v("p",[e._v("将SQL语句由开放区间扫描（>=），修改为封闭区间（between xxx and max_value），使得数据在索引局部顺序是“对的”。如果采用这种方式仍然不走索引扫描，还可以进一步细化分段或者采用“逐条提取+批绑定”的方法。")]),e._v(" "),v("ol",{attrs:{start:"9"}},[v("li",[e._v("建立组合索引，但查询谓词并未使用组合索引的第一列")])]),e._v(" "),v("p",[e._v("此处有一个INDEX SKIP SCAN概念。")]),e._v(" "),v("ol",{attrs:{start:"10"}},[v("li",[e._v("like '%liu'")])]),e._v(" "),v("p",[e._v("百分号在前请输入标题。")]),e._v(" "),v("ol",{attrs:{start:"11"}},[v("li",[e._v("not in ,not exist")])]),e._v(" "),v("p",[e._v("可以尝试把not in或者not exist改成左连接的方式（前提是有子查询，并且子查询有where条件）。")]),e._v(" "),v("h3",{attrs:{id:"意向锁的使用"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#意向锁的使用"}},[e._v("#")]),e._v(" 意向锁的使用")]),e._v(" "),v("p",[e._v("原文地址：https://www.itcodemonkey.com/article/8000.html")]),e._v(" "),v("p",[e._v("https://www.zhihu.com/question/51513268")]),e._v(" "),v("p",[e._v("在InnoDB里当实现了标准的行级锁(row-level locking)，共享/排它锁：\n(1)事务拿到某一行记录的共享S锁，才可以读取这一行；")]),e._v(" "),v("p",[e._v("(2)事务拿到某一行记录的排它X锁，才可以修改或者删除这一行")]),e._v(" "),v("p",[e._v("可以理解为：\n(1)多个事务可以拿到一把S锁，读读可以并行；")]),e._v(" "),v("p",[e._v("(2)而只有一个事务可以拿到X锁，写写/读写必须互斥；")]),e._v(" "),v("p",[e._v("共享/排它锁的潜在问题是，不能充分的并行，解决思路是数据多版本（MVVC）")]),e._v(" "),v("p",[e._v("意向锁(Intention Locks)：InnoDB支持多粒度锁(multiple granularity locking)它允许行级锁与表级锁共存，实际应用中，InnoDB使用的是意向锁。意向锁是指，未来的某个时刻，事务可能要加共享/排它锁了，先提前声明一个意向。")]),e._v(" "),v("p",[e._v("(1)首先，意向锁，是一个表级别的锁(table-level locking)；")]),e._v(" "),v("p",[e._v("(2)意向锁分为：")]),e._v(" "),v("ul",[v("li",[e._v("意向共享锁(intention shared lock, IS)，它预示着，事务有意向对表中的某些行加共享S锁")]),e._v(" "),v("li",[e._v("意向排它锁(intention exclusive lock, IX)，它预示着，事务有意向对表中的某些行加排它X锁")])]),e._v(" "),v("p",[e._v("举个例子：")]),e._v(" "),v("ul",[v("li",[e._v("select ... lock in share mode，要设置IS锁；")]),e._v(" "),v("li",[e._v("select ... for update，要设置IX锁；")])]),e._v(" "),v("p",[e._v("(3)意向锁协议(intention locking protocol)并不复杂：")]),e._v(" "),v("ul",[v("li",[e._v("事务要获得某些行的S锁，必须先获得表的IS锁")]),e._v(" "),v("li",[e._v("事务要获得某些行的X锁，必须先获得表的IX锁")])]),e._v(" "),v("h4",{attrs:{id:"知乎上的解释结合去看"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#知乎上的解释结合去看"}},[e._v("#")]),e._v(" 知乎上的解释结合去看：")]),e._v(" "),v("p",[e._v("①在mysql中有表锁，")]),e._v(" "),v("p",[e._v("LOCK TABLE my_tabl_name READ; 用读锁锁表，会阻塞其他事务修改表数据。")]),e._v(" "),v("p",[e._v("LOCK TABLE my_table_name WRITe; 用写锁锁表，会阻塞其他事务读和写。")]),e._v(" "),v("p",[e._v("②Innodb引擎又支持行锁，行锁分为")]),e._v(" "),v("p",[e._v("共享锁，一个事务对一行的共享只读锁。")]),e._v(" "),v("p",[e._v("排它锁，一个事务对一行的排他读写锁。")]),e._v(" "),v("p",[e._v("③这两中类型的锁共存的问题")]),e._v(" "),v("p",[e._v("考虑这个例子：")]),e._v(" "),v("p",[e._v("事务A锁住了表中的一行，让这一行只能读，不能写。之后，事务B申请整个表的写锁。如果事务B申请成功，那么理论上它就能修改表中的任意一行，这与A持有的行锁是冲突的。数据库需要避免这种冲突，就是说要让B的申请被阻塞，直到A释放了行锁。数据库要怎么判断这个冲突呢？")]),e._v(" "),v("p",[e._v("step1：判断表是否已被其他事务用表锁锁表")]),e._v(" "),v("p",[e._v("step2：判断表中的每一行是否已被行锁锁住。")]),e._v(" "),v("p",[e._v("注意step2，这样的判断方法效率实在不高，因为需要遍历整个表。于是就有了意向锁。在意向锁存在的情况下，事务A必须先申请表的意向共享锁，成功后再申请一行的行锁。在意向锁存在的情况下，上面的判断可以改成")]),e._v(" "),v("p",[e._v("step1：不变")]),e._v(" "),v("p",[e._v("step2：发现表上有意向共享锁，说明表中有些行被共享行锁锁住了，因此，事务B申请表的写锁会被阻塞。")]),e._v(" "),v("h3",{attrs:{id:"mysql怎么提高读写并发"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#mysql怎么提高读写并发"}},[e._v("#")]),e._v(" MYSQL怎么提高读写并发")]),e._v(" "),v("p",[e._v("(1)InnoDB使用共享锁和MVVC，可以提高读读并发；")]),e._v(" "),v("p",[e._v("(2)为了保证数据强一致，InnoDB使用强互斥锁，保证同一行记录修改与删除的串行性；")]),e._v(" "),v("p",[e._v("(3)InnoDB使用插入意向锁，可以提高插入并发；")]),e._v(" "),v("h3",{attrs:{id:"技术上-通常如何进行并发控制"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#技术上-通常如何进行并发控制"}},[e._v("#")]),e._v(" 技术上，通常如何进行并发控制")]),e._v(" "),v("p",[e._v("原文地址：https://www.itcodemonkey.com/article/7644.html")]),e._v(" "),v("p",[e._v("通过并发控制保证数据一致性的常见手段有：")]),e._v(" "),v("ol",[v("li",[e._v("锁（Locking）")])]),e._v(" "),v("ul",[v("li",[e._v("普通锁，本质是串行执行")]),e._v(" "),v("li",[e._v("读写锁，可以实现读读并发")])]),e._v(" "),v("ol",{attrs:{start:"2"}},[v("li",[e._v("数据多版本（Multi Versioning）")])]),e._v(" "),v("ul",[v("li",[e._v("数据多版本，可以实现读写并发")])]),e._v(" "),v("p",[e._v("InnoDB是高并发互联网场景最为推荐的存储引擎，根本原因，就是其多版本并发控制（Multi Version Concurrency Control, MVCC）。行锁，并发，事务回滚等多种特性都和MVCC相关。InnoDB是基于MVCC的存储引擎，它利用了存储在回滚段里的undo日志，即数据的旧版本，提高并发；InnoDB之所以并发高，快照读不加锁；InnoDB所有普通select都是快照读；MVCC就是通过“读取旧版本数据”来降低并发事务的锁冲突，提高任务的并发度。快照读（Snapshot Read），这种一致性不加锁的读（Consistent Nonlocking Read），就是InnoDB并发如此之高的核心原因之一。这里的一致性是指，事务读取到的数据，要么是事务开始前就已经存在的数据（当然，是其他已提交事务产生的），要么是事务自身插入或者修改的数据。什么样的select是快照读？")]),e._v(" "),v("p",[e._v("除非显示加锁，普通的select语句都是快照读，例如：")]),e._v(" "),v("div",{staticClass:"language- line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("select * from t where id>2;\n")])]),e._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[e._v("1")]),v("br")])]),v("p",[e._v("这里的显示加锁，非快照读是指：")]),e._v(" "),v("div",{staticClass:"language- line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("select * from t where id>2 lock in share mode;\nselect * from t where id>2 for update;\n")])]),e._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[e._v("1")]),v("br"),v("span",{staticClass:"line-number"},[e._v("2")]),v("br")])]),v("p",[e._v("数据多版本是一种能够进一步提高并发的方法，它的核心原理是：")]),e._v(" "),v("p",[e._v("（1）写任务发生时，将数据克隆一份，以版本号区分；")]),e._v(" "),v("p",[e._v("（2）写任务操作新克隆的数据，直至提交；")]),e._v(" "),v("p",[e._v("（3）并发读任务可以继续读取旧版本的数据，不至于阻塞；")]),e._v(" "),v("p",[e._v("例如：")]),e._v(" "),v("p",[e._v("T1时刻发起了一个写任务，这是把数据clone了一份，进行修改，版本变为V1，但任务还未完成；")]),e._v(" "),v("p",[e._v("T2时刻并发了一个读任务，依然可以读V0版本的数据；")]),e._v(" "),v("p",[e._v("T3时刻又并发了一个读任务，依然不会阻塞；")]),e._v(" "),v("h3",{attrs:{id:"mysql一个索引最多有多少个列"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#mysql一个索引最多有多少个列"}},[e._v("#")]),e._v(" MySQL一个索引最多有多少个列")]),e._v(" "),v("p",[e._v("16列")]),e._v(" "),v("h3",{attrs:{id:"innodb-5项最佳实践-知其所以然"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#innodb-5项最佳实践-知其所以然"}},[e._v("#")]),e._v(" InnoDB，5项最佳实践，知其所以然")]),e._v(" "),v("p",[e._v("原文地址：58沈剑的公众号：https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651961428&idx=1&sn=31a9eb967941d888fbd4bb2112e9602b&chksm=bd2d0d888a5a849e7ebaa7756a8bc1b3d4e2f493f3a76383fc80f7e9ce7657e4ed2f6c01777d&scene=21#wechat_redirect")]),e._v(" "),v("ol",[v("li",[v("p",[e._v("关于count("),v("em",[e._v(")\n知识点：MyISAM会直接存储总行数，InnoDB则不会，需要按行扫描。潜台词是，对于select count(")]),e._v(") from t;如果数据量大，MyISAM会瞬间返回，而InnoDB则会一行行扫描。实践：数据量大的表，InnoDB不要轻易select count(*)，性能消耗极大。常见坑：只有查询全表的总行数，MyISAM才会直接返回结果，当加了where条件后，两种存储引擎的处理方式类似。")])]),e._v(" "),v("li",[v("p",[e._v("关于全文索引\n知识点：MyISAM支持全文索引，InnoDB5.6之前不支持全文索引。实践：不管哪种存储引擎，在数据量大并发量大的情况下，都不应该使用数据库自带的全文索引，会导致小量请求占用大量数据库资源，而要使用《索引外置》的架构设计方法。启示：大数据量+高并发量的业务场景，全文索引，MyISAM也不是最优之选。")])]),e._v(" "),v("li",[v("p",[e._v("关于事务\n知识点：MyISAM不支持事务，InnoDB支持事务。实践：事务是选择InnoDB非常诱人的原因之一，它提供了commit，rollback，崩溃修复等能力。在系统异常崩溃时，MyISAM有一定几率造成文件损坏，这是非常烦的。但是，事务也非常耗性能，会影响吞吐量，建议只对一致性要求较高的业务使用复杂事务。")])]),e._v(" "),v("li",[v("p",[e._v("关于外键\n知识点：MyISAM不支持外键，InnoDB支持外键。实践：不管哪种存储引擎，在数据量大并发量大的情况下，都不应该使用外键，而建议由应用程序保证完整性。")])]),e._v(" "),v("li",[v("p",[e._v("关于行锁与表锁\n知识点：MyISAM只支持表锁，InnoDB可以支持行锁。分析：")])])]),e._v(" "),v("ul",[v("li",[e._v("MyISAM：执行读写SQL语句时，会对表加锁，所以数据量大，并发量高时，性能会急剧下降。")]),e._v(" "),v("li",[e._v("InnoDB：细粒度行锁，在数据量大，并发量高时，性能比较优异。")])]),e._v(" "),v("p",[e._v("实践：网上常常说，select+insert的业务用MyISAM，因为MyISAM在文件尾部顺序增加记录速度极快。楼主的建议是，绝大部分业务是混合读写，只要数据量和并发量较大，一律使用InnoDB。常见坑：** InnoDB的行锁是实现在索引上的，而不是锁在物理行记录上。潜台词是，如果访问没有命中索引，也无法使用行锁，将要退化为表锁。 **")]),e._v(" "),v("h3",{attrs:{id:"like会用索引吗"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#like会用索引吗"}},[e._v("#")]),e._v(" like会用索引吗")]),e._v(" "),v("p",[e._v("原文地址：https://www.itcodemonkey.com/article/10209.html")]),e._v(" "),v("p",[e._v("like语句要使索引生效，like后不能以%开始，也就是说 :（like %字段名%）  、（like %字段名）这类语句会使索引失效，（like 字段名）、（like 字段名%）这类语句索引是可以正常使用。")]),e._v(" "),v("h3",{attrs:{id:"记一次mysql主从复制延迟的坑"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#记一次mysql主从复制延迟的坑"}},[e._v("#")]),e._v(" 记一次MySQL主从复制延迟的坑")]),e._v(" "),v("div",{staticClass:"language- line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("$intStatus = $arrInput[‘status’];\n$this->objActTmp->updateInfoByAId($intActId, $intStatus);\n// 更新后，马上查\n$arrActContent = $this->objActTmp->getActByStatus($intStatus);\n")])]),e._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[e._v("1")]),v("br"),v("span",{staticClass:"line-number"},[e._v("2")]),v("br"),v("span",{staticClass:"line-number"},[e._v("3")]),v("br"),v("span",{staticClass:"line-number"},[e._v("4")]),v("br")])]),v("p",[e._v("这就是主从延迟出现的地方，update后，马上get，这是主从复制架构上开发的一个大忌。这类问题的解决方案有两种：")]),e._v(" "),v("ul",[v("li",[e._v("修改代码逻辑")]),e._v(" "),v("li",[e._v("修改系统架构")])]),e._v(" "),v("p",[e._v("对于修改代码逻辑，鄙人有两点见解：")]),e._v(" "),v("ul",[v("li",[e._v("如果第二步获取的数据不需要第一步更新的status字段，那就先读，然后再更新")]),e._v(" "),v("li",[e._v("如果第二步获取的数据需要依赖第一步的status字段，那就在读出来的时候先判断是否为空，如果是空的，报错，下一次重试。")])]),e._v(" "),v("h3",{attrs:{id:"大规模数据库的性能和伸缩性优化"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#大规模数据库的性能和伸缩性优化"}},[e._v("#")]),e._v(" 大规模数据库的性能和伸缩性优化")]),e._v(" "),v("p",[e._v("原文地址：https://www.itcodemonkey.com/article/412.html")]),e._v(" "),v("ol",[v("li",[v("p",[e._v("MySQL 的内存分配：在为 MySQL 分配足够的内存之前，请考虑不同领域对 MySQL 的内存需求。要考虑的关键领域是：并发连接 —— 对于大量并发连接，排序和临时表将需要大量内存。在撰写本文时，对于处理 3000+ 并发连接的数据库，16GB 到 32GB的 RAM 是足够的。内存碎片可以消耗大约 10％ 或更多的内存。像 innodb_buffer_pool_size、key_buffer_size、query_cache_size 等缓存和缓冲区要消耗大约 80％ 的已分配内存。")])]),e._v(" "),v("li",[v("p",[e._v("优化 InnoDB 磁盘 I/O：增加 InnoDB 缓冲池大小可以让查询从缓冲池访问而不是通过磁盘 I/O 访问。通过调整系统变量 innodb_flush_method 来调整清除缓冲的指标使其达到最佳水平。")])]),e._v(" "),v("li",[v("p",[e._v("优化存储结构：对于大型的表，或者包含大量重复文本或数值数据的表，应该考虑使用 COMPRESSED(压缩的) 行格式。这样只需要较少的 I/O 就可以把数据取到缓冲池，或执行全表扫描。一旦你的数据达到稳定的大小，或者增长的表增加了几十或几百兆字节，就应该考虑使用 OPTIMIZE TABLE 语句重新组织表并压缩浪费的空间。对重新组织后的表进行全表扫描所需要的 I/O 会更少。")])]),e._v(" "),v("li",[v("p",[e._v("SQL 语句优化")])])]),e._v(" "),v("ul",[v("li",[e._v("为了提升查询的速度，可以为 WHERE 字句中使用的列添加索引。此外，不要将主键索引用于太多或太长的列，因为这些列值在辅助索引进行复制的时候会增加读取所需要的 I/O 资源并占用缓存。")]),e._v(" "),v("li",[e._v("如果索引包含了不必要的数据，通过 I/O 读取这些数据并进行缓存就会减弱服务器的性能和伸缩性。也不要为不必要的列使用唯一键索引，因为它会禁用 change buffering。应该使用常规索引代替。")]),e._v(" "),v("li",[e._v("减少和隔离需要耗费大量时间的函数调用。")]),e._v(" "),v("li",[e._v("尽可能的减少查询中的全表扫描次数。")])]),e._v(" "),v("ol",{attrs:{start:"5"}},[v("li",[v("p",[e._v("使用批量数据导入：在主键上使用已排序的数据源进行批量数据的导入可加快数据插入的过程。否则，可能需要在其他行之间插入行以维护排序，这会导致磁盘 I/O 变高，进而影响性能，增加页的拆分。关闭自动提交的模式也是有好处的，因为它会为每个插入执行日志刷新到磁盘。在批量插入期间临时转移唯一键和外键检查也可显著降低磁盘 I/O。对于新建的表，最好的做法是在批量导入后创建外键/唯一键约束。")])]),e._v(" "),v("li",[v("p",[e._v("InnoDB 页面压缩：InnoDB 支持对表进行页面级的压缩。当写入数据页的时候，会有特定的压缩算法对其进行压缩。压缩后的数据会写入磁盘，其打孔机制会释放页面末尾的空块。如果压缩失败，数据会按原样写入。表和索引都会被压缩，因为索引通常是数据库总大小中占比很大的一部分，压缩可以显著节约内存，I/O 或处理时间，这样就达到了提高性能和伸缩性的目的。它还可以减少内存和磁盘之间传输的数据量。MySQL5.1及更高版本支持该功能。注意，页面压缩并不能支持共享表空间中的表。共享表空间包括系统表空间、临时表空间和常规表空间。")])]),e._v(" "),v("li",[v("p",[e._v("InnoDB 的 Change Buffering 特性：InnoDB 提供了 change buffering 的配置，可减少维护辅助索引所需的磁盘 I/O。大规模的数据库可能会遇到大量的表操作和大量的 I/O，以保证辅助索引保持最新。当相关页面不在缓冲池里面时，InnoDB 的 change buffer 将会更改缓存到辅助索引条目，从而避免因不能立即从磁盘读取页面而导致耗时的 I/O 操作。当页面被加载到缓冲池时，缓冲的更改将被合并，更新的页面之后会刷新到磁盘。这样做可提高性能，适用于 MySQL 5.5 及更高版本。")])])]),e._v(" "),v("h3",{attrs:{id:"change-buffering-再了解"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#change-buffering-再了解"}},[e._v("#")]),e._v(" change buffering(再了解)")]),e._v(" "),v("h3",{attrs:{id:"为什么要做主从复制"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#为什么要做主从复制"}},[e._v("#")]),e._v(" 为什么要做主从复制？")]),e._v(" "),v("ol",[v("li",[v("p",[e._v("在业务复杂的系统中，有这么一个情景，有一句sql语句需要锁表，导致暂时不能使用读的服务，那么就很影响运行中的业务，使用主从复制，让主库负责写，从库负责读，这样，即使主库出现了锁表的情景，通过读从库也可以保证业务的正常运作。")])]),e._v(" "),v("li",[v("p",[e._v("做数据的热备")])]),e._v(" "),v("li",[v("p",[e._v("架构的扩展。业务量越来越大，I/O访问频率过高，单机无法满足，此时做多库的存储，降低磁盘I/O访问的频率，提高单个机器的I/O性能。")])])]),e._v(" "),v("h3",{attrs:{id:"mysql主从复制的流程"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#mysql主从复制的流程"}},[e._v("#")]),e._v(" MYSQL主从复制的流程")]),e._v(" "),v("ul",[v("li",[e._v("步骤一：主库db的更新事件(update、insert、delete)被写到binlog")]),e._v(" "),v("li",[e._v("步骤二：从库发起连接，连接到主库")]),e._v(" "),v("li",[e._v("步骤三：此时主库创建一个binlog dump thread，把binlog的内容发送到从库")]),e._v(" "),v("li",[e._v("步骤四：从库启动之后，创建一个I/O线程，读取主库传过来的binlog内容并写入到relay log")]),e._v(" "),v("li",[e._v("步骤五：还会创建一个SQL线程，从relay log里面读取内容，从Exec_Master_Log_Pos位置开始执行读取到的更新事件，将更新内容写入到slave的db")])]),e._v(" "),v("h3",{attrs:{id:"mysql磁盘io的基本常识"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#mysql磁盘io的基本常识"}},[e._v("#")]),e._v(" MYSQL磁盘IO的基本常识")]),e._v(" "),v("p",[e._v("原文地址：https://www.itcodemonkey.com/article/699.html")]),e._v(" "),v("p",[e._v("一个数据库必须保证其中存储的所有数据都是可以随时读写的，同时因为MySQL中所有的数据其实都是以文件的形式存储在磁盘上的，而从磁盘上"),v("strong",[e._v("随机访问")]),e._v("对应的数据非常耗时，所以数据库程序和操作系统提供了缓冲池和内存以提高数据的访问速度。")]),e._v(" "),v("p",[e._v("除此之外，我们还需要知道数据库对数据的读取并不是以行为单位进行的，无论是读取一行还是多行，都会将该行或者多行所在的页全部加载进来，然后再读取对应的数据记录；也就是说，读取所耗费的时间与行数无关，只与页数有关。")]),e._v(" "),v("p",[e._v("随机读取：在 MySQL 中，页的大小一般为 16KB，不过也可能是8KB、32KB或者其他值，这跟MySQL的存储引擎对数据的存储方式有很大的关系，文中不会展开介绍，"),v("strong",[e._v("不过索引或行记录是否在缓存池中极大的影响了访问索引或者数据的成本")]),e._v("。数据库等待一个页从磁盘读取到缓存池的所需要的成本巨大的，无论我们是想要读取一个页面上的多条数据还是一条数据，都需要消耗约 10ms 左右的时间：")]),e._v(" "),v("p",[e._v("内存读取：如果在数据库的缓存池中没有找到对应的数据页，那么会去内存中寻找对应的页面，当对应的页面存在于内存时，数据库程序就会使用内存中的页，这能够将数据的读取时间降低一个数量级，将10ms降低到1ms；MySQL在执行读操作时，会先从数据库的缓冲区中读取，如果不存在与缓冲区中就会尝试从内存中加载页面，如果前面的两个步骤都失败了，最后就只能执行随机 IO 从磁盘中获取对应的数据页。")]),e._v(" "),v("p",[e._v("顺序读取：从磁盘读取数据并不是都要付出很大的代价，当数据库管理程序一次性从磁盘中顺序读取大量的数据时，读取的速度会异常的快，大概在 40MB/s 左右。如果一个页面的大小为 4KB，那么 1s 的时间就可以读取10000个页，读取一个页面所花费的平均时间就是0.1ms，相比随机读取的10ms已经降低了两个数量级，甚至比内存中读取数据还要快。数据页面的顺序读取有两个非常重要的优势：")]),e._v(" "),v("ul",[v("li",[e._v("同时读取多个界面意味着总时间的消耗会大幅度减少，磁盘的吞吐量可以达到 40MB/s；")]),e._v(" "),v("li",[e._v("数据库管理程序会对一些即将使用的界面进行预读，以减少查询请求的等待和响应时间；")]),e._v(" "),v("li",[e._v("最快是顺序读取，然后是内存，最后是随机")])]),e._v(" "),v("p",[e._v("数据库查询操作的时间大都消耗在从磁盘或者内存中读取数据的过程，由于随机IO的代价巨大，如何在一次数据库查询中减少随机IO的次数往往能够大幅度的降低查询所耗费的时间提高磁盘的吞吐量。")]),e._v(" "),v("h3",{attrs:{id:"key-len"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#key-len"}},[e._v("#")]),e._v(" key_len")]),e._v(" "),v("p",[e._v("EXPLAIN执行计划中有一列 key_len 用于表示本次查询中，所选择的索引长度有多少字节，通常我们可借此判断联合索引有多少列被选择了。在这里 key_len 大小的计算规则是：")]),e._v(" "),v("ul",[v("li",[e._v("一般地，key_len 等于索引列类型字节长度，例如int类型为4 bytes，bigint为8 bytes；")]),e._v(" "),v("li",[e._v("如果是字符串类型，还需要同时考虑字符集因素，例如：CHAR(30) UTF8则key_len至少是90 bytes；")]),e._v(" "),v("li",[e._v("若该列类型定义时允许NULL，其key_len还需要再加 1 bytes；")]),e._v(" "),v("li",[e._v("若该列类型为变长类型，例如 VARCHAR（TEXT\\BLOB不允许整列创建索引，如果创建部分索引也被视为动态列类型），其key_len还需要再加 2 bytes;")])]),e._v(" "),v("h3",{attrs:{id:"、-等的匹配"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#、-等的匹配"}},[e._v("#")]),e._v(" =、>=等的匹配")]),e._v(" "),v("p",[e._v("Index Key是用来确定MySQL的一个扫描范围，分为上边界和下边界。如果比较符号中包含'='号，'>='也是包含'='，那么该索引键是可以被利用的，可以继续匹配后面的索引键值；如果不存在'='，也就是'>','<'，这两个，后面的索引键值就无法匹配了。同时，上下边界是不可以混用的，哪个边界能利用索引的的键值多，就是最终能够利用索引键值的个数。例如：")]),e._v(" "),v("div",{staticClass:"language- line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("exp:\nidx_c1_c2_c3(c1,c2,c3)\nwhere c1>=1 and c2>2 and c3=1\n--\x3e  first key (c1,c2)\n--\x3e c1为 '>=' ，加入下边界界定，继续匹配下一个\n--\x3ec2 为 '>'，加入下边界界定，停止匹配\n\n\nexp:\nidx_c1_c2_c3(c1,c2,c3)\nwhere c1<=1 and c2=2 and c3<3\n--\x3e first key (c1,c2,c3)\n--\x3e c1为 '<='，加入上边界界定，继续匹配下一个\n--\x3e c2为 '='加入上边界界定，继续匹配下一个\n--\x3e c3 为 '<'，加入上边界界定，停止匹配\n")])]),e._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[e._v("1")]),v("br"),v("span",{staticClass:"line-number"},[e._v("2")]),v("br"),v("span",{staticClass:"line-number"},[e._v("3")]),v("br"),v("span",{staticClass:"line-number"},[e._v("4")]),v("br"),v("span",{staticClass:"line-number"},[e._v("5")]),v("br"),v("span",{staticClass:"line-number"},[e._v("6")]),v("br"),v("span",{staticClass:"line-number"},[e._v("7")]),v("br"),v("span",{staticClass:"line-number"},[e._v("8")]),v("br"),v("span",{staticClass:"line-number"},[e._v("9")]),v("br"),v("span",{staticClass:"line-number"},[e._v("10")]),v("br"),v("span",{staticClass:"line-number"},[e._v("11")]),v("br"),v("span",{staticClass:"line-number"},[e._v("12")]),v("br"),v("span",{staticClass:"line-number"},[e._v("13")]),v("br"),v("span",{staticClass:"line-number"},[e._v("14")]),v("br"),v("span",{staticClass:"line-number"},[e._v("15")]),v("br")])]),v("h3",{attrs:{id:"between-和like-的处理"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#between-和like-的处理"}},[e._v("#")]),e._v(" Between 和Like 的处理")]),e._v(" "),v("p",[e._v("那么如果查询中存在between 和like，MySQL是如何进行处理的呢？")]),e._v(" "),v("p",[v("code",[e._v("where c1 between 'a' and 'b' 等价于 where c1>='a' and c1 <='b'")]),e._v("，所以进行相应的替换，然后带入上层模型，确定上下边界即可。\n首先需要确认的是%不能是最在最左侧，where c1 like '%a' 这样的查询是无法利用索引的，因为索引的匹配需要符合最左前缀原则"),v("code",[e._v("where c1 like 'a%' 其实等价于 where c1>='a' and c1<'b'")]),e._v(" 大家可以仔细思考下。")]),e._v(" "),v("h3",{attrs:{id:"给我一个不用-null-的理由"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#给我一个不用-null-的理由"}},[e._v("#")]),e._v(" 给我一个不用 Null 的理由")]),e._v(" "),v("ul",[v("li",[e._v("（1）所有使用NULL值的情况，都可以通过一个有意义的值的表示，这样有利于代码的可读性和可维护性，并能从约束上增强业务数据的规范性。")]),e._v(" "),v("li",[e._v("（2）NULL值到非NULL的更新无法做到原地更新，更容易发生索引分裂，从而影响性能。注意：但把NULL列改为NOTNULL带来的性能提示很小，除非确定它带来了问题，否则不要把它当成优先的优化措施，最重要的是使用的列的类型的适当性。")]),e._v(" "),v("li",[e._v("（3）NULL值在timestamp类型下容易出问题，特别是没有启用参数explicit_defaults_for_timestamp")]),e._v(" "),v("li",[e._v("（4）NOT IN、!= 等负向条件查询在有 NULL 值的情况下返回永远为空结果，查询容易出错")]),e._v(" "),v("li",[e._v("key_len 的计算规则和三个因素有关：数据类型、字符编码、是否为 NULL：")])]),e._v(" "),v("div",{staticClass:"language- line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("key_len 62 == 20*3（utf8 3字节） + 2 （存储 varchar 变长字符长度 2字节，定长字段无需额外的字节）\nkey_len 83 == 20*4（utf8mb4 4字节） +  1 (是否为 Null 的标识) + 2 （存储 varchar 变长字符长度 2字节，定长字段无需额外的字节）\n")])]),e._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[e._v("1")]),v("br"),v("span",{staticClass:"line-number"},[e._v("2")]),v("br")])]),v("p",[e._v("所以说索引字段最好不要为NULL，因为NULL会使索引、索引统计和值更加复杂，并且需要额外一个字节的存储空间。")]),e._v(" "),v("h3",{attrs:{id:"索引分裂"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#索引分裂"}},[e._v("#")]),e._v(" 索引分裂")]),e._v(" "),v("p",[e._v("原文地址：https://www.cnblogs.com/myf008/p/6689427.html")]),e._v(" "),v("p",[e._v("“索引分裂”就是索引块的分裂，当一次DML事务操作修改了索引块上的数据，但是旧有的索引块没有足够的空间来容纳新修改的数据，那么将分裂出一个新索引块，旧有块的部分数据放到新开辟的索引块上去，这个过程就称为索引块的分裂（INDEX BLOCK SPLIT）。")]),e._v(" "),v("p",[e._v("当有新值插入到L4叶节点块的时候，此时L4叶节点块是“充满”状态，已经没有足够的空间来存储新值了，此时会在B2分支节点下，分裂出一个新的叶节点L5来存储新值。如果分支节点B2也是“充满”了呢？那就要进行分支节点的分裂，即在ROOT根节点下，分裂出一个新的分支节点出来。依此类推，如果根节点也“充满”了，则需要进行根节点的分裂。如果发生了根节点的分裂，也意味着B树的高度（BTREE LEVEL）增加了一个层次。对真正意义上的树来说，这种生长是好事，但对B树索引来说，这就不是什么好事情了，B树索引的高度需要严格控制的。")]),e._v(" "),v("h3",{attrs:{id:"你不知道的8条sql技巧"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#你不知道的8条sql技巧"}},[e._v("#")]),e._v(" 你不知道的8条SQL技巧")]),e._v(" "),v("p",[e._v("原文地址：https://www.itcodemonkey.com/article/1404.html")]),e._v(" "),v("p",[e._v("（1）负向条件查询不能使用索引")]),e._v(" "),v("div",{staticClass:"language- line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("select * from order where status!=0 and stauts!=1\n")])]),e._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[e._v("1")]),v("br")])]),v("p",[e._v("not in/not exists都不是好习惯，可以优化为in查询（可以使用索引）：")]),e._v(" "),v("div",{staticClass:"language- line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("select * from order where status in(2,3)\n")])]),e._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[e._v("1")]),v("br")])]),v("p",[e._v("（2）前导模糊查询不能使用索引")]),e._v(" "),v("div",{staticClass:"language- line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("select * from order where desc like '%XX'\n")])]),e._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[e._v("1")]),v("br")])]),v("p",[e._v("而非前导模糊查询则可以：")]),e._v(" "),v("div",{staticClass:"language- line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("select * from order where desc like 'XX%'\n")])]),e._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[e._v("1")]),v("br")])]),v("p",[e._v("（3）数据区分度不大的字段不宜使用索引")]),e._v(" "),v("div",{staticClass:"language- line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("select * from user where sex=1\n")])]),e._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[e._v("1")]),v("br")])]),v("p",[e._v("原因：性别只有男，女，每次过滤掉的数据很少，不宜使用索引。经验上，能过滤80%数据时就可以使用索引。对于订单状态，如果状态值很少，不宜使用索引，如果状态值很多，能够过滤大量数据，则应该建立索引。\n（4）在属性上进行计算不能命中索引")]),e._v(" "),v("div",{staticClass:"language- line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("select * from order where YEAR(date) < = '2017'\n")])]),e._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[e._v("1")]),v("br")])]),v("p",[e._v("即使date上建立了索引，也会全表扫描，可优化为值计算：")]),e._v(" "),v("div",{staticClass:"language- line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("select * from order where date < = CURDATE()\n")])]),e._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[e._v("1")]),v("br")])]),v("p",[e._v("5）如果业务大部分是单条查询，使用Hash索引性能更好，例如用户中心")]),e._v(" "),v("div",{staticClass:"language- line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("select * from user where uid=?\nselect * from user where login_name=?\n")])]),e._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[e._v("1")]),v("br"),v("span",{staticClass:"line-number"},[e._v("2")]),v("br")])]),v("p",[e._v("原因(Innodb的存在hash索引)：")]),e._v(" "),v("ul",[v("li",[e._v("B-Tree索引的时间复杂度是O(log(n))")]),e._v(" "),v("li",[e._v("Hash索引的时间复杂度是O(1)")])]),e._v(" "),v("p",[e._v("（6）允许为null的列，查询有潜在大坑")]),e._v(" "),v("p",[v("code",[e._v("单列索引不存null值，复合索引不存全为null的值")]),e._v("，如果列允许为null，可能会得到“不符合预期”的结果集")]),e._v(" "),v("div",{staticClass:"language- line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("select * from user where name != 'shenjian'\n")])]),e._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[e._v("1")]),v("br")])]),v("p",[e._v("如果name允许为null，索引不存储null值，结果集中不会包含这些记录。所以，请使用not null约束以及默认值。")]),e._v(" "),v("p",[e._v("（7）如果明确知道只有一条结果返回，limit 1能够提高效率")]),e._v(" "),v("div",{staticClass:"language- line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("select * from user where login_name=?\n")])]),e._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[e._v("1")]),v("br")])]),v("p",[e._v("可以优化为：")]),e._v(" "),v("div",{staticClass:"language- line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("select * from user where login_name=? limit 1\n")])]),e._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[e._v("1")]),v("br")])]),v("p",[e._v("原因：你知道只有一条结果，但数据库并不知道，明确告诉它，让它主动停止游标移动")]),e._v(" "),v("p",[e._v("（8）强制类型转换会全表扫描")]),e._v(" "),v("div",{staticClass:"language- line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("select * from user where phone=13800001234\n")])]),e._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[e._v("1")]),v("br")])]),v("p",[e._v("你以为会命中phone索引么？大错特错了，这个语句究竟要怎么改？末了，再加一条，不要使用select *（潜台词，文章的SQL都不合格 =_=），只返回需要的列，能够大大的节省数据传输量，与数据库的内存使用量哟。思路比结论重要。")]),e._v(" "),v("h3",{attrs:{id:"建立索引其他的原则"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#建立索引其他的原则"}},[e._v("#")]),e._v(" 建立索引其他的原则")]),e._v(" "),v("p",[e._v("1、在建表时就应该考虑添加索引,如: 外键字段,等等。")]),e._v(" "),v("p",[e._v("2、在写完SQL后,一定要查看执行计划。尽量避免全表扫描。")]),e._v(" "),v("p",[e._v("3、如果是已有表中添加索引,一定要先计算该字段的区分度。")]),e._v(" "),v("p",[e._v("4、联合索引,将区分度大放在前面。")]),e._v(" "),v("p",[e._v("5、遵从MySQL左列前缀优先原则")]),e._v(" "),v("h3",{attrs:{id:"分布式之缓存击穿的三种解决方案"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#分布式之缓存击穿的三种解决方案"}},[e._v("#")]),e._v(" 分布式之缓存击穿的三种解决方案")]),e._v(" "),v("p",[e._v("原文地址：https://www.itcodemonkey.com/article/3739.html")]),e._v(" "),v("ol",[v("li",[e._v("使用互斥锁：该方法是比较普遍的做法，即，在根据key获得的value值为空时，先锁上，再从数据库加载，加载完毕，释放锁。若其他线程发现获取锁失败，则睡眠50ms后重试。至于锁的类型，单机环境用并发包的Lock类型就行，集群环境则使用分布式锁( redis的setnx)")])]),e._v(" "),v("div",{staticClass:"language- line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v('String get(String key) {  \n   String value = redis.get(key);  \n   if (value  == null) {  \n    if (redis.setnx(key_mutex, "1")) {  \n        // 3 min timeout to avoid mutex holder crash  \n        redis.expire(key_mutex, 3 * 60)  \n        value = db.get(key);  \n        redis.set(key, value);  \n        redis.delete(key_mutex);  \n    } else {  \n        //其他线程休息50毫秒后重试  \n        Thread.sleep(50);  \n        get(key);  \n    }  \n  }  \n}  \n')])]),e._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[e._v("1")]),v("br"),v("span",{staticClass:"line-number"},[e._v("2")]),v("br"),v("span",{staticClass:"line-number"},[e._v("3")]),v("br"),v("span",{staticClass:"line-number"},[e._v("4")]),v("br"),v("span",{staticClass:"line-number"},[e._v("5")]),v("br"),v("span",{staticClass:"line-number"},[e._v("6")]),v("br"),v("span",{staticClass:"line-number"},[e._v("7")]),v("br"),v("span",{staticClass:"line-number"},[e._v("8")]),v("br"),v("span",{staticClass:"line-number"},[e._v("9")]),v("br"),v("span",{staticClass:"line-number"},[e._v("10")]),v("br"),v("span",{staticClass:"line-number"},[e._v("11")]),v("br"),v("span",{staticClass:"line-number"},[e._v("12")]),v("br"),v("span",{staticClass:"line-number"},[e._v("13")]),v("br"),v("span",{staticClass:"line-number"},[e._v("14")]),v("br"),v("span",{staticClass:"line-number"},[e._v("15")]),v("br"),v("span",{staticClass:"line-number"},[e._v("16")]),v("br")])]),v("p",[e._v("缺点:")]),e._v(" "),v("ul",[v("li",[e._v("代码复杂度增大")]),e._v(" "),v("li",[e._v("存在死锁的风险")])]),e._v(" "),v("ol",{attrs:{start:"2"}},[v("li",[e._v("异步构建缓存:在这种方案下，构建缓存采取异步策略，会从线程池中取线程来异步构建缓存，从而不会让所有的请求直接怼到数据库上。该方案redis自己维护一个timeout，当timeout小于System.currentTimeMillis()时，则进行缓存更新，否则直接返回value值。\n集群环境的redis代码如下所示:")])]),e._v(" "),v("div",{staticClass:"language- line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v('String get(final String key) {  \n        V v = redis.get(key);  \n        String value = v.getValue();  \n        long timeout = v.getTimeout();  \n        if (v.timeout <= System.currentTimeMillis()) {  \n            // 异步更新后台异常执行  \n            threadPool.execute(new Runnable() {  \n                public void run() {  \n                    String keyMutex = "mutex:" + key;  \n                    if (redis.setnx(keyMutex, "1")) {  \n                        // 3 min timeout to avoid mutex holder crash  \n                        redis.expire(keyMutex, 3 * 60);  \n                        String dbValue = db.get(key);  \n                        redis.set(key, dbValue);  \n                        redis.delete(keyMutex);  \n                    }  \n                }  \n            });  \n        }  \n        return value;  \n    }\n')])]),e._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[e._v("1")]),v("br"),v("span",{staticClass:"line-number"},[e._v("2")]),v("br"),v("span",{staticClass:"line-number"},[e._v("3")]),v("br"),v("span",{staticClass:"line-number"},[e._v("4")]),v("br"),v("span",{staticClass:"line-number"},[e._v("5")]),v("br"),v("span",{staticClass:"line-number"},[e._v("6")]),v("br"),v("span",{staticClass:"line-number"},[e._v("7")]),v("br"),v("span",{staticClass:"line-number"},[e._v("8")]),v("br"),v("span",{staticClass:"line-number"},[e._v("9")]),v("br"),v("span",{staticClass:"line-number"},[e._v("10")]),v("br"),v("span",{staticClass:"line-number"},[e._v("11")]),v("br"),v("span",{staticClass:"line-number"},[e._v("12")]),v("br"),v("span",{staticClass:"line-number"},[e._v("13")]),v("br"),v("span",{staticClass:"line-number"},[e._v("14")]),v("br"),v("span",{staticClass:"line-number"},[e._v("15")]),v("br"),v("span",{staticClass:"line-number"},[e._v("16")]),v("br"),v("span",{staticClass:"line-number"},[e._v("17")]),v("br"),v("span",{staticClass:"line-number"},[e._v("18")]),v("br"),v("span",{staticClass:"line-number"},[e._v("19")]),v("br"),v("span",{staticClass:"line-number"},[e._v("20")]),v("br"),v("span",{staticClass:"line-number"},[e._v("21")]),v("br")])]),v("p",[e._v("缺点:无法保证缓存一致性")]),e._v(" "),v("ol",{attrs:{start:"3"}},[v("li",[e._v("布隆过滤器:本质上布隆过滤器是一种数据结构，比较巧妙的概率型数据结构（probabilistic data structure），特点是高效地插入和查询，可以用来告诉你 “某样东西一定不存在或者可能存在”。相比于传统的 List、Set、Map 等数据结构，它更高效、占用空间更少，但是缺点是其返回的结果是概率性的，而不是确切的。"),v("strong",[e._v("布隆过滤器是一个bit向量或者说bit数组")]),e._v("，长这样：如果我们要映射一个值到布隆过滤器中，我们需要使用多个不同的哈希函数生成多个哈希值，并对每个生成的哈希值指向的 bit 位置 1，例如针对值 “baidu” 和三个不同的哈希函数分别生成了哈希值 1、4、7，则上图转变为：Ok，我们现在再存一个值 “tencent”，如果哈希函数返回 3、4、8 的话，图继续变为：")])]),e._v(" "),v("p",[e._v("值得注意的是，4 这个 bit 位由于两个值的哈希函数都返回了这个 bit 位，因此它被覆盖了。现在我们如果想查询 “dianping” 这个值是否存在，哈希函数返回了 1、5、8三个值，结果我们发现 5 这个 bit 位上的值为 0，说明没有任何一个值映射到这个 bit 位上，因此我们可以很确定地说 “dianping” 这个值不存在。而当我们需要查询 “baidu” 这个值是否存在的话，那么哈希函数必然会返回 1、4、7，然后我们检查发现这三个 bit 位上的值均为 1，那么我们可以说 “baidu” 存在了么？答案是不可以，只能是 “baidu” 这个值可能存在。")]),e._v(" "),v("p",[e._v("既然你使用布隆过滤器来加速查找和判断是否存在，那么性能很低的哈希函数不是个好选择，推荐 MurmurHash、Fnv 这些。")]),e._v(" "),v("p",[e._v("总结：核心就是判断"),v("strong",[e._v("元素存不存在")]),e._v("，redis或者其他也是这个原理")]),e._v(" "),v("p",[e._v("缺点")]),e._v(" "),v("ul",[v("li",[e._v("代码复杂度增大")]),e._v(" "),v("li",[e._v("需要另外维护一个集合来存放缓存的Key")]),e._v(" "),v("li",[e._v("布隆过滤器不支持删值操作")])]),e._v(" "),v("p",[v("strong",[e._v("查询缓存日志发现没有key说明缓存穿透了，现象是使用了redis但是仍然还有大量连接")])]),e._v(" "),v("p",[e._v("原文地址：https://www.jianshu.com/p/2104d11ee0a2")]),e._v(" "),v("h3",{attrs:{id:"优化再实践"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#优化再实践"}},[e._v("#")]),e._v(" 优化再实践")]),e._v(" "),v("ol",[v("li",[v("p",[e._v("把IP地址存成 UNSIGNED INT：很多程序员都会创建一个 VARCHAR(15) 字段来存放字符串形式的IP而不是整形的IP。如果你用整形来存放，只需要4个字节，并且你可以有定长的字段。而且，这会为你带来查询上的优势，尤其是当你需要使用这样的WHERE条件：IP between ip1 and ip2。")])]),e._v(" "),v("li",[v("p",[e._v("固定长度的表会更快：如果表中的所有字段都是“固定长度”的，整个表会被认为是“static”或“fixed-length”。例如，表中没有如下类型的字段：VARCHAR，TEXT，BLOB。只要你包括了其中一个这些字段，那么这个表就不是“固定长度静态表”了，这样，MySQL 引擎会用另一种方法来处理。固定长度的表会提高性能，因为MySQL搜寻得会更快一些，因为这些固定的长度是很容易计算下一个数据的偏移量的，所以读取的自然也会很快。而如果字段不是定长的，那么，每一次要找下一条的话，需要程序找到主键。")])]),e._v(" "),v("li",[v("p",[e._v("垂直分割：“垂直分割”是一种把数据库中的表按列变成几张表的方法，这样可以降低表的复杂度和字段的数目，从而达到优化的目的。（以前，在银行做过项目，见过一张表有100多个字段，很恐怖）")])]),e._v(" "),v("li",[v("p",[e._v("拆分大的 DELETE 或 INSERT 语句：如果你需要在一个在线的网站上去执行一个大的DELETE或INSERT查询，你需要非常小心，要避免你的操作让你的整个网站停止相应。因为这两个操作是会锁表的，表一锁住了，别的操作都进不来了。（确保条件使用索引）")])]),e._v(" "),v("li",[v("p",[e._v("18、越小的列会越快：对于大多数的数据库引擎来说，硬盘操作可能是最重大的瓶颈。所以，把你的数据变得紧凑会对这种情况非常有帮助，因为这减少了对硬盘的访问。参看 MySQL 的文档 Storage Requirements 查看所有的数据类型。如果一个表只会有几列罢了（比如说字典表，配置表），那么，我们就没有理由使用 INT 来做主键，使用 MEDIUMINT, SMALLINT 或是更小的 TINYINT 会更经济一些。如果你不需要记录时间，使用 DATE 要比 DATETIME 好得多。")])])]),e._v(" "),v("h3",{attrs:{id:"分库分表后面临的问题"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#分库分表后面临的问题"}},[e._v("#")]),e._v(" 分库分表后面临的问题")]),e._v(" "),v("ul",[v("li",[v("p",[e._v("事务支持：分库分表后，就成了分布式事务了。如果依赖数据库本身的分布式事务管理功能去执行事务，将付出高昂的性能代价； 如果由应用程序去协助控制，形成程序逻辑上的事务，又会造成编程方面的负担。")])]),e._v(" "),v("li",[v("p",[e._v("多库结果集合并（group by，order by）")])])]),e._v(" "),v("h3",{attrs:{id:"与b-tree相比-b-tree有以下不同点"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#与b-tree相比-b-tree有以下不同点"}},[e._v("#")]),e._v(" 与B-Tree相比，B+Tree有以下不同点")]),e._v(" "),v("ol",[v("li",[v("p",[e._v("每个节点的指针上限为2d而不是2d+1。")])]),e._v(" "),v("li",[v("p",[e._v("内节点不存储data，只存储key；叶子节点不存储指针。")])]),e._v(" "),v("li",[v("p",[e._v("叶子结点串联，增加了顺序访问指针")])])]),e._v(" "),v("h3",{attrs:{id:"主存的存取过程如下"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#主存的存取过程如下"}},[e._v("#")]),e._v(" 主存的存取过程如下")]),e._v(" "),v("p",[e._v("原文地址：https://www.itcodemonkey.com/article/4034.html")]),e._v(" "),v("p",[e._v("当系统需要读取主存时，则将地址信号放到地址总线上传给主存，主存读到地址信号后，解析信号并定位到指定存储单元，然后将此存储单元数据放到数据总线上，供其它部件读取。写主存的过程类似，系统将要写入单元地址和数据分别放在地址总线和数据总线上，主存读取两个总线的内容，做相应的写操作。这里可以看出，主存存取的时间仅与存取次数呈线性关系，因为不存在机械操作，两次存取的数据的“距离”不会对时间有任何影响，例如，先取A0再取A1和先取A0再取D3的时间消耗是一样的。")]),e._v(" "),v("h3",{attrs:{id:"innodb索引实现"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#innodb索引实现"}},[e._v("#")]),e._v(" InnoDB索引实现")]),e._v(" "),v("p",[e._v("原文地址：https://www.itcodemonkey.com/article/4034.html")]),e._v(" "),v("p",[e._v("第一个重大区别是InnoDB的数据文件本身就是索引文件。从上文知道，MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。而在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。")]),e._v(" "),v("p",[e._v("第二个与MyISAM索引的不同是InnoDB的辅助索引data域存储相应记录主键的值而不是地址。换句话说，InnoDB的所有辅助索引都引用主键作为data域。")]),e._v(" "),v("p",[e._v("聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。")]),e._v(" "),v("h3",{attrs:{id:"mysql数据库开发的36条军规"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#mysql数据库开发的36条军规"}},[e._v("#")]),e._v(" MySQL数据库开发的36条军规")]),e._v(" "),v("h4",{attrs:{id:"核心军规"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#核心军规"}},[e._v("#")]),e._v(" 核心军规")]),e._v(" "),v("ul",[v("li",[e._v("尽量不在数据库做运算")]),e._v(" "),v("li",[e._v("控制单表数据量 纯INT不超过10M条，含Char不超过5M条")]),e._v(" "),v("li",[e._v("保持表身段苗条")]),e._v(" "),v("li",[e._v("平衡范式和冗余")]),e._v(" "),v("li",[e._v("拒绝大SQL，复杂事务，大批量任务")])]),e._v(" "),v("h4",{attrs:{id:"字段类军规"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#字段类军规"}},[e._v("#")]),e._v(" 字段类军规")]),e._v(" "),v("ul",[v("li",[e._v("用好数值字段，尽量简化字段位数")]),e._v(" "),v("li",[e._v("把字符转化为数字")]),e._v(" "),v("li",[e._v("优先使用Enum或Set")]),e._v(" "),v("li",[e._v("避免使用Null字段")]),e._v(" "),v("li",[e._v("少用并拆封Text/Blob")]),e._v(" "),v("li",[e._v("不在数据库中存图片")])]),e._v(" "),v("h4",{attrs:{id:"索引类军规"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#索引类军规"}},[e._v("#")]),e._v(" 索引类军规")]),e._v(" "),v("ul",[v("li",[e._v("谨慎合理添加索引")]),e._v(" "),v("li",[e._v("字符字段必须建立前缀索引?")]),e._v(" "),v("li",[e._v("不在索引列做运算")]),e._v(" "),v("li",[e._v("自增列或全局ID做InnoDB主键")]),e._v(" "),v("li",[e._v("尽量不用外键")])]),e._v(" "),v("h4",{attrs:{id:"sql类军规"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#sql类军规"}},[e._v("#")]),e._v(" SQL类军规")]),e._v(" "),v("ul",[v("li",[e._v("SQL尽可能简单")]),e._v(" "),v("li",[e._v("保持事务连接短小")]),e._v(" "),v("li",[e._v("尽可能避免使用SP/Trigger/Function")]),e._v(" "),v("li",[e._v("尽量不用Select *")]),e._v(" "),v("li",[e._v("改写Or为IN()")]),e._v(" "),v("li",[e._v("改写Or为Union")]),e._v(" "),v("li",[e._v("避免负向查询和%前缀模糊查询")]),e._v(" "),v("li",[e._v("Count不要使用在可Null的字段上面")]),e._v(" "),v("li",[e._v("减少Count(*)")]),e._v(" "),v("li",[e._v("Limit高效分页，SELECT * FROM message WHERE id > 9527 (or sub select) limit 10")]),e._v(" "),v("li",[e._v("使用Union ALL 而不用Union")]),e._v(" "),v("li",[e._v("分解链接，保证高并发")]),e._v(" "),v("li",[e._v("Group By 去除排序")]),e._v(" "),v("li",[e._v("同数据类型的列值比较")]),e._v(" "),v("li",[e._v("Load Data导入数据，比Insert快20倍")]),e._v(" "),v("li",[e._v("打散大批量更新，尽量凌晨操作")])]),e._v(" "),v("h3",{attrs:{id:"约定类军规"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#约定类军规"}},[e._v("#")]),e._v(" 约定类军规")]),e._v(" "),v("ul",[v("li",[e._v("隔离线上线下")]),e._v(" "),v("li",[e._v("禁止未经DBA认证的子查询")]),e._v(" "),v("li",[e._v("永远不在程序段显式加锁")]),e._v(" "),v("li",[e._v("表字符集统一使用UTF8MB4")])]),e._v(" "),v("h3",{attrs:{id:"什么情况要建立索引什么时候不用"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#什么情况要建立索引什么时候不用"}},[e._v("#")]),e._v(" 什么情况要建立索引什么时候不用")]),e._v(" "),v("p",[e._v("哪些情况需要建索引：")]),e._v(" "),v("ol",[v("li",[e._v("主键，唯一索引")]),e._v(" "),v("li",[e._v("经常用作查询条件的字段需要创建索引")]),e._v(" "),v("li",[e._v("经常需要排序、分组和统计的字段需要建立索引")]),e._v(" "),v("li",[e._v("查询中与其他表关联的字段，外键关系建立索引")])]),e._v(" "),v("p",[e._v("哪些情况不要建索引：")]),e._v(" "),v("ol",[v("li",[e._v("表的记录太少，百万级以下的数据不需要创建索引")]),e._v(" "),v("li",[e._v("经常增删改的表不需要创建索引")]),e._v(" "),v("li",[e._v("数据重复且分布平均的字段不需要创建索引，如 true,false 之类。")]),e._v(" "),v("li",[e._v("频发更新的字段不适合创建索引")]),e._v(" "),v("li",[e._v("where条件里用不到的字段不需要创建索引")])]),e._v(" "),v("h3",{attrs:{id:"mvcc-实现机制"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#mvcc-实现机制"}},[e._v("#")]),e._v(" MVCC(实现机制)")]),e._v(" "),v("p",[e._v("原文地址：https://www.itcodemonkey.com/article/7509.html")]),e._v(" "),v("p",[e._v("MySQL的通过MVCC以及(Next-Key Lock)实现了可重复读(Repeatable Read),其思想(MVCC)就是记录数据的版本变迁，通过精巧的选择不同数据的版本从而能够对用户呈现一致的结果。"),v("strong",[e._v("MVCC仅仅在纯select时有效(不包括select for update,lock in share mode等加锁操作,以及updateinsert等)")])]),e._v(" "),v("p",[e._v("事务的隔离级别就是保证两个事务在同一个自身事务中多次读取都是一致的。同一个事物中多次读取数据不一致的情况。原文中讲的很好。")]),e._v(" "),v("h3",{attrs:{id:"悲观锁和乐观锁的使用场景"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#悲观锁和乐观锁的使用场景"}},[e._v("#")]),e._v(" 悲观锁和乐观锁的使用场景")]),e._v(" "),v("p",[e._v("原文地址：https://www.itcodemonkey.com/article/5109.html")]),e._v(" "),v("p",[e._v("下面这个假设的实际场景可以比较清楚的帮助我们理解这个问题：假设当当网上用户下单买了本书，这时数据库中有条订单号为001的订单，其中有个status字段是’有效’,表示该订单是有效的；后台管理人员查询到这条001的订单，并且看到状态是有效的用户发现下单的时候下错了，于是撤销订单，假设运行这样一条SQL: update order_table set status = ‘取消’ where order_id = 001;后台管理人员由于在b这步看到状态有效的，这时，虽然用户在c这步已经撤销了订单，可是管理人员并未刷新界面，看到的订单状态还是有效的，于是点击”发货”按钮，将该订单发到物流部门，同时运行类似如下SQL，将订单状态改成已发货:update order_table set status = ‘已发货’ where order_id = 001")]),e._v(" "),v("p",[e._v("观点1："),v("strong",[e._v("只有冲突非常严重的系统才需要悲观锁")]),e._v("；“所有悲观锁的做法都适合于状态被修改的概率比较高的情况，具体是否合适则需要根据实际情况判断。”，表达的也是这个意思，不过说法不够准确；的确，之所以用悲观锁就是因为两个用户更新同一条数据的概率高，也就是冲突比较严重的情况下，所以才用悲观锁。")]),e._v(" "),v("p",[e._v("观点2：最后提交前作一次select for update检查，然后再提交update也是一种乐观锁的做法，的确，这符合传统乐观锁的做法，就是到最后再去检查。但是wiki在解释悲观锁的做法的时候，’It is not appropriate for useinwebapplicationdevelopment.’，现在已经很少有悲观锁的做法了，所以我自己将这种二次检查的做法也归为悲观锁的变种，因为这在所有乐观锁里面，做法和悲观锁是最接近的，都是先select for update，然后update")]),e._v(" "),v("p",[e._v("在实际应用中我们在更新数据的时候，更严谨的做法是带上更新前的“状态”，如")]),e._v(" "),v("div",{staticClass:"language- line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("update order_table set status = ‘取消’ where order_id = 001 and status = ‘待支付’ and ..........; \n")])]),e._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[e._v("1")]),v("br")])]),v("h3",{attrs:{id:"主从复制的几种方式"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#主从复制的几种方式"}},[e._v("#")]),e._v(" 主从复制的几种方式")]),e._v(" "),v("p",[e._v("同步复制:所谓的同步复制，意思是master的变化，必须等待slave-1,slave-2,...,slave-n完成后才能返回。这样，显然不可取，也不是MYSQL复制的默认设置。比如，在WEB前端页面上，用户增加了条记录，需要等待很长时间。")]),e._v(" "),v("p",[e._v("异步复制:如同AJAX请求一样。master只需要完成自己的数据库操作即可。至于slaves是否收到二进制日志，是否完成操作，不用关心。MYSQL的默认设置。")]),e._v(" "),v("p",[e._v("半同步复制:master只保证slaves中的一个操作成功，就返回，其他slave不管。这个功能，是由google为MYSQL引入的。")]),e._v(" "),v("h3",{attrs:{id:"当master的二进制日志每产生一个事件-都需要发往slave-如果我们有n个slave-那是发n次-还是只发一次"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#当master的二进制日志每产生一个事件-都需要发往slave-如果我们有n个slave-那是发n次-还是只发一次"}},[e._v("#")]),e._v(" 当master的二进制日志每产生一个事件，都需要发往slave，如果我们有N个slave,那是发N次，还是只发一次")]),e._v(" "),v("p",[e._v("如果只发一次，发给了slave-1，那slave-2,slave-3,...它们怎么办？")]),e._v(" "),v("p",[e._v("显然，应该发N次。实际上，在MYSQL master内部，维护N个线程，每一个线程负责将二进制日志文件发往对应的slave。master既要负责写操作，还的维护N个线程，负担会很重。可以这样，slave-1是master的从，slave-1又是slave-2,slave-3,...的主，同时slave-1不再负责select。slave-1将master的复制线程的负担，转移到自己的身上。这就是所谓的多级复制的概念。")]),e._v(" "),v("h3",{attrs:{id:"主从复制中有master-slave1-slave2-等等这么多mysql数据库-那比如一个java-web应用到底应该连接哪个数据库"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#主从复制中有master-slave1-slave2-等等这么多mysql数据库-那比如一个java-web应用到底应该连接哪个数据库"}},[e._v("#")]),e._v(" 主从复制中有master,slave1,slave2,...等等这么多MYSQL数据库，那比如一个JAVA WEB应用到底应该连接哪个数据库?")]),e._v(" "),v("p",[e._v("当然，我们在应用程序中可以这样，insert/delete/update这些更新数据库的操作，用connection(for master)进行操作，select用connection(for slaves)进行操作。那我们的应用程序还要完成怎么从slaves选择一个来执行select，例如简单的轮循算法。")]),e._v(" "),v("p",[e._v("这样的话，相当于应用程序完成了SQL语句的路由，而且与MYSQL的主从复制架构非常关联，一旦master挂了，某些slave挂了，那么应用程序就要修改了。能不能让应用程序与MYSQL的主从复制架构没有什么太多关系呢？找一个组件，application program只需要与它打交道，用它来完成MYSQL的代理，实现SQL语句的路由。mysql proxy并不负责，怎么从众多的slaves挑一个？可以交给另一个组件(比如haproxy)来完成。这就是所谓的MYSQL READ WRITE SPLITE，MYSQL的读写分离。")]),e._v(" "),v("h3",{attrs:{id:"主从复制中-可以有n个slave-可是这些slave又不能进行写操作-要他们干嘛"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#主从复制中-可以有n个slave-可是这些slave又不能进行写操作-要他们干嘛"}},[e._v("#")]),e._v(" 主从复制中，可以有N个slave,可是这些slave又不能进行写操作，要他们干嘛？")]),e._v(" "),v("ol",[v("li",[e._v("可以实现数据备份。类似于高可用的功能，一旦master挂了，可以让slave顶上去，同时slave提升为master。")]),e._v(" "),v("li",[e._v("异地容灾，比如master在北京，地震挂了，那么在上海的slave还可以继续。主要用于实现scale out,分担负载,可以将读的任务分散到slaves上。")]),e._v(" "),v("li",[e._v("很可能的情况是，一个系统的读操作远远多于写操作，因此写操作发向master，读操作发向slaves进行操作】")])]),e._v(" "),v("h3",{attrs:{id:"master的写操作-slaves被动的进行一样的操作-保持数据一致性-那么slave是否可以主动的进行写操作"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#master的写操作-slaves被动的进行一样的操作-保持数据一致性-那么slave是否可以主动的进行写操作"}},[e._v("#")]),e._v(" master的写操作，slaves被动的进行一样的操作，保持数据一致性，那么slave是否可以主动的进行写操作？")]),e._v(" "),v("p",[e._v("假设slave可以主动的进行写操作，slave又无法通知master，这样就导致了master和slave数据不一致了。因此slave不应该进行写操作，至少是slave上涉及到复制的数据库不可以写。实际上，这里已经揭示了读写分离的概念。")]),e._v(" "),v("h3",{attrs:{id:"为什么使用数据索引能提高效率"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#为什么使用数据索引能提高效率"}},[e._v("#")]),e._v(" 为什么使用数据索引能提高效率")]),e._v(" "),v("ol",[v("li",[e._v("数据索引的存储是有序的")]),e._v(" "),v("li",[e._v("在有序的情况下，通过索引查询一个数据是无需遍历索引记录的")]),e._v(" "),v("li",[e._v("极端情况下，数据索引的查询效率为二分法查询效率，趋近于 log2(N)")])]),e._v(" "),v("h3",{attrs:{id:"b-树索引和哈希索引的区别"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#b-树索引和哈希索引的区别"}},[e._v("#")]),e._v(" B+树索引和哈希索引的区别")]),e._v(" "),v("p",[e._v("原文地址：https://www.itcodemonkey.com/article/6470.html")]),e._v(" "),v("p",[e._v("B+树是一个平衡的多叉树，从根节点到每个叶子节点的高度差值不超过1，而且同层级的节点间有指针相互链接，是有序的.")]),e._v(" "),v("p",[e._v("哈希索引就是采用一定的哈希算法，把键值换算成新的哈希值，检索时不需要类似B+树那样从根节点到叶子节点逐级查找，只需一次哈希算法即可,是无序的")]),e._v(" "),v("p",[e._v("哈希索引的优势：等值查询。哈希索引具有绝对优势（前提是：没有大量重复键值，如果大量重复键值时，哈希索引的效率很低，因为存在所谓的哈希碰撞问题。）")]),e._v(" "),v("p",[e._v("哈希索引不适用的场景：")]),e._v(" "),v("ol",[v("li",[e._v("不支持范围查询")]),e._v(" "),v("li",[e._v("不支持索引完成排序")]),e._v(" "),v("li",[e._v("不支持联合索引的最左前缀匹配规则")])]),e._v(" "),v("h3",{attrs:{id:"b树和b-树的区别-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#b树和b-树的区别-2"}},[e._v("#")]),e._v(" B树和B+树的区别")]),e._v(" "),v("p",[e._v("B树，每个节点都存储key和data，所有节点组成这棵树，并且叶子节点指针为nul，叶子结点不包含任何关键字信息。")]),e._v(" "),v("p",[e._v("B+树，所有的叶子结点中包含了全部关键字的信息，及指向含有这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大的顺序链接，所有的非终端结点可以看成是索引部分，结点中仅含有其子树根结点中最大（或最小）关键字。 (而B 树的非终节点也包含需要查找的有效信息)")]),e._v(" "),v("h3",{attrs:{id:"为什么说b-比b树更适合实际应用中操作系统的文件索引和数据库索引"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#为什么说b-比b树更适合实际应用中操作系统的文件索引和数据库索引"}},[e._v("#")]),e._v(" 为什么说B+比B树更适合实际应用中操作系统的文件索引和数据库索引？")]),e._v(" "),v("p",[e._v("B+的磁盘读写代价更低 B+的内部结点并没有指向关键字具体信息的指针。因此其内部结点相对B树更小。如果把所有同一内部结点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多。一次性读入内存中的需要查找的关键字也就越多。相对来说IO读写次数也就降低了。")]),e._v(" "),v("p",[e._v("B+-tree的查询效率更加稳定 由于非终结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。")]),e._v(" "),v("h3",{attrs:{id:"mysql联合索引"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#mysql联合索引"}},[e._v("#")]),e._v(" MySQL联合索引")]),e._v(" "),v("ol",[v("li",[v("p",[e._v("联合索引是两个或更多个列上的索引。对于联合索引:Mysql从左到右的使用索引中的字段，一个查询可以只使用索引中的一部份，但只能是最左侧部分。例如索引是key index (a,b,c). 可以支持a   、    a,b   、  a,b,c 3种组合进行查找，但不支持 b,c进行查找 .当最左侧字段是常量引用时，索引就十分有效。")])]),e._v(" "),v("li",[v("p",[e._v("利用索引中的附加列，您可以缩小搜索的范围，但使用一个具有两列的索引 不同于使用两个单独的索引。复合索引的结构与电话簿类似，人名由姓和名构成，电话簿首先按姓氏对进行排序，然后按名字对有相同姓氏的人进行排序。如果您知 道姓，电话簿将非常有用；如果您知道姓和名，电话簿则更为有用，但如果您只知道名不姓，电话簿将没有用处。")])])]),e._v(" "),v("h3",{attrs:{id:"什么情况下应不建或少建索引"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#什么情况下应不建或少建索引"}},[e._v("#")]),e._v(" 什么情况下应不建或少建索引")]),e._v(" "),v("ol",[v("li",[e._v("表记录太少")]),e._v(" "),v("li",[e._v("经常插入、删除、修改的表")]),e._v(" "),v("li",[e._v("数据重复且分布平均的表字段，假如一个表有10万行记录，有一个字段A只有T和F两种值，且每个值的分布概率大约为50%，那么对这种表A字段建索引一般不会提高数据库的查询速度。")]),e._v(" "),v("li",[e._v("经常和主字段一块查询但主字段索引值比较多的表字段")])]),e._v(" "),v("h3",{attrs:{id:"mvcc最大的好处"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#mvcc最大的好处"}},[e._v("#")]),e._v(" MVCC最大的好处")]),e._v(" "),v("p",[e._v("读不加锁，读写不冲突。MVCC：Multi-Version Concurrency Control，基于多版本的并发控制协议。纯粹基于锁的并发机制并发量低，MVCC是在基于锁的并发控制上的改进，主要是在读操作上提高了并发量。")]),e._v(" "),v("p",[e._v("在MVCC并发控制中，读操作可以分成两类：")]),e._v(" "),v("ol",[v("li",[e._v("快照读 (snapshot read)：读取的是记录的可见版本 (有可能是历史版本)，不用加锁（共享读锁s锁也不加，所以不会阻塞其他事务的写）。")]),e._v(" "),v("li",[e._v("当前读 (current read)：读取的是记录的最新版本，并且，当前读返回的记录，都会加上锁，保证其他事务不会再并发修改这条记录。")])]),e._v(" "),v("h3",{attrs:{id:"mysql优化"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#mysql优化"}},[e._v("#")]),e._v(" MySQL优化")]),e._v(" "),v("ol",[v("li",[e._v("开启查询缓存，优化查询")]),e._v(" "),v("li",[e._v("explain你的select查询，这可以帮你分析你的查询语句或是表结构的性能瓶颈。EXPLAIN 的查询结果还会告诉你你的索引主键被如何利用的，你的数据表是如何被搜索和排序的")]),e._v(" "),v("li",[e._v("当只要一行数据时使用limit 1，MySQL数据库引擎会在找到一条数据后停止搜索，而不是继续往后查少下一条符合记录的数据")]),e._v(" "),v("li",[e._v("为搜索字段建索引")]),e._v(" "),v("li",[e._v("使用 ENUM 而不是 VARCHAR，如果你有一个字段，比如“性别”，“国家”，“民族”，“状态”或“部门”，你知道这些字段的取值是有限而且固定的，那么，你应该使用 ENUM 而不是VARCHAR。")]),e._v(" "),v("li",[e._v("Prepared Statements Prepared Statements很像存储过程，是一种运行在后台的SQL语句集合，我们可以从使用 prepared statements 获得很多好处，无论是性能问题还是安全问题。Prepared Statements 可以检查一些你绑定好的变量，这样可以保护你的程序不会受到“SQL注入式”攻击")]),e._v(" "),v("li",[e._v("垂直分表")]),e._v(" "),v("li",[e._v("选择正确的存储引擎")])]),e._v(" "),v("h3",{attrs:{id:"mysql-中-myisam-和-innodb-的区别有哪些"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#mysql-中-myisam-和-innodb-的区别有哪些"}},[e._v("#")]),e._v(" Mysql 中 MyISAM 和 InnoDB 的区别有哪些？")]),e._v(" "),v("ol",[v("li",[e._v("InnoDB支持事务，MyISAM不支持，对于InnoDB每一条SQL语言都默认封装成事务，自动提交，这样会影响速度，所以最好把多条SQL语言放在begin和commit之间，组成一个事务；")]),e._v(" "),v("li",[e._v("InnoDB支持外键，而MyISAM不支持。对一个包含外键的InnoDB表转为MYISAM会失败；")]),e._v(" "),v("li",[e._v("InnoDB是聚集索引，数据文件是和索引绑在一起的，必须要有主键，通过主键索引效率很高。但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大。而MyISAM是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。")]),e._v(" "),v("li",[e._v("InnoDB不保存表的具体行数，执行select count(*) from table时需要全表扫描。而MyISAM用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快；")]),e._v(" "),v("li",[e._v("Innodb不支持全文索引，而MyISAM支持全文索引，查询效率上MyISAM要高；")])]),e._v(" "),v("h3",{attrs:{id:"缓存与数据库不一致-咋办"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#缓存与数据库不一致-咋办"}},[e._v("#")]),e._v(" 缓存与数据库不一致，咋办")]),e._v(" "),v("p",[e._v("数据库主从不一致，发生的场景是，写后立刻读：")]),e._v(" "),v("p",[e._v("（1）主库一个写请求（主从没同步完成）")]),e._v(" "),v("p",[e._v("（2）从库接着一个读请求，读到了旧数据")]),e._v(" "),v("p",[e._v("（3）最后，主从同步完成")]),e._v(" "),v("p",[e._v("导致的结果是：主动同步完成之前，会读取到旧数据。可以看到，这里提到的缓存与数据库数据不一致，根本上是由数据库主从不一致引起的。当主库上发生写操作之后，从库binlog同步的时间间隔内，读请求，可能导致有旧数据入缓存。假如主从不一致没法彻底解决，引入缓存之后，binlog同步时间间隔内，也无法避免读旧数据。但是，有没有办法做到，即使引入缓存，不一致不会比“不引入缓存”更糟呢？这是更为实际的优化目标。思路转化为：在从库同步完成之后，如果有旧数据入缓存，应该及时把这个旧数据淘汰掉。")]),e._v(" "),v("p",[e._v("（6）主从同步")]),e._v(" "),v("p",[e._v("（7）通过工具订阅从库的binlog，这里能够最准确的知道，从库数据同步完成的时间")]),e._v(" "),v("p",[e._v("（8）从库执行完写操作，向缓存再次发起删除，淘汰这段时间内可能写入缓存的旧数据")]),e._v(" "),v("h3",{attrs:{id:"数据库主库和从库不一致-常见有这么几种优化方案"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#数据库主库和从库不一致-常见有这么几种优化方案"}},[e._v("#")]),e._v(" 数据库主库和从库不一致，常见有这么几种优化方案：")]),e._v(" "),v("p",[e._v("（1）业务可以接受，系统不优化")]),e._v(" "),v("p",[e._v("（2）强制读主，高可用主库，用缓存提高读性能")]),e._v(" "),v("p",[e._v("（3）在cache里记录哪些记录发生过写请求，来路由读主还是读从")]),e._v(" "),v("h3",{attrs:{id:"分布式事务讲的不错"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#分布式事务讲的不错"}},[e._v("#")]),e._v(" 分布式事务讲的不错")]),e._v(" "),v("p",[e._v("https://www.itcodemonkey.com/article/6875.html")]),e._v(" "),v("h3",{attrs:{id:"innodb共有七种类型的锁"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#innodb共有七种类型的锁"}},[e._v("#")]),e._v(" InnoDB共有七种类型的锁")]),e._v(" "),v("p",[e._v("(1)共享/排它锁(Shared and Exclusive Locks)")]),e._v(" "),v("p",[e._v("(2)意向锁(Intention Locks)")]),e._v(" "),v("p",[e._v("(3)记录锁(Record Locks)")]),e._v(" "),v("p",[e._v("(4)间隙锁(Gap Locks)")]),e._v(" "),v("p",[e._v("(5)临键锁(Next-key Locks)")]),e._v(" "),v("p",[e._v("(6)插入意向锁(Insert Intention Locks)")]),e._v(" "),v("p",[e._v("(7)自增锁(Auto-inc Locks)")]),e._v(" "),v("h3",{attrs:{id:"插入innodb自增列-居然是表锁"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#插入innodb自增列-居然是表锁"}},[e._v("#")]),e._v(" 插入InnoDB自增列，居然是表锁")]),e._v(" "),v("p",[e._v("自增锁是一种特殊的表级别锁（table-level lock），专门针对事务插入AUTO_INCREMENT类型的列。最简单的情况，如果一个事务正在往表中插入记录，所有其他事务的插入必须等待，以便第一个事务插入的行，是连续的主键值。")]),e._v(" "),v("p",[e._v("官网是这么说的")]),e._v(" "),v("p",[e._v("An AUTO-INC lock is a special table-level lock taken by transactions inserting into tables with AUTO_INCREMENT columns. In the simplest case, if one transaction is inserting values into the table, any other transactions must wait to do their own inserts into that table, so that rows inserted by the first transaction receive consecutive primary key values.")]),e._v(" "),v("p",[e._v("与此同时，InnoDB提供了innodb_autoinc_lock_mode配置，可以调节与改变该锁的模式与行为。")]),e._v(" "),v("h3",{attrs:{id:"innodb并发插入-居然使用意向锁"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#innodb并发插入-居然使用意向锁"}},[e._v("#")]),e._v(" InnoDB并发插入，居然使用意向锁？")]),e._v(" "),v("h3",{attrs:{id:"索引结构为什么要设计成树型"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#索引结构为什么要设计成树型"}},[e._v("#")]),e._v(" 索引结构为什么要设计成树型")]),e._v(" "),v("p",[e._v("(1)哈希，例如HashMap，查询/插入/修改/删除的平均时间复杂度都是O(1)；")]),e._v(" "),v("p",[e._v("(2)树，例如平衡二叉搜索树，查询/插入/修改/删除的平均时间复杂度都是O(lg(n))；")]),e._v(" "),v("p",[e._v("可以看到，不管是读请求，还是写请求，哈希类型的索引，都要比树型的索引更快一些，那为什么，索引结构要设计成树型呢？索引设计成树形，和SQL的需求相关。")]),e._v(" "),v("p",[e._v("对于这样一个单行查询的SQL需求：")]),e._v(" "),v("div",{staticClass:"language- line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("select * from t where name=”shenjian”;\n")])]),e._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[e._v("1")]),v("br")])]),v("p",[e._v("确实是哈希索引更快，因为每次都只查询一条记录。所以，如果业务需求都是单行访问，例如passport，确实可以使用哈希索引。但是对于排序查询的SQL需求：")]),e._v(" "),v("p",[e._v("分组：group by")]),e._v(" "),v("p",[e._v("排序：order by")]),e._v(" "),v("p",[e._v("比较：<、>")]),e._v(" "),v("p",[e._v("哈希型的索引，时间复杂度会退化为O(n)，而树型的“有序”特性，依然能够保持O(log(n)) 的高效率。"),v("strong",[e._v("InnoDB并不支持哈希索引")])]),e._v(" "),v("h3",{attrs:{id:"什么是局部性原理"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#什么是局部性原理"}},[e._v("#")]),e._v(" 什么是局部性原理")]),e._v(" "),v("p",[e._v("局部性原理的逻辑是这样的：")]),e._v(" "),v("p",[e._v("(1)内存读写块，磁盘读写慢，而且慢很多；")]),e._v(" "),v("p",[e._v("(2)磁盘预读：磁盘读写并不是按需读取，而是按页预读，一次会读一页的数据，每次加载更多的数据，如果未来要读取的数据就在这一页中，可以避免未来的磁盘IO，提高效率；画外音：通常，一页数据是4K。")]),e._v(" "),v("p",[e._v("(3)局部性原理：软件设计要尽量遵循“数据读取集中”与“使用到一个数据，大概率会使用其附近的数据”，这样磁盘预读能充分提高磁盘IO；")]),e._v(" "),v("h3",{attrs:{id:"数据库优化的几个阶段"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#数据库优化的几个阶段"}},[e._v("#")]),e._v(" 数据库优化的几个阶段")]),e._v(" "),v("p",[e._v("原文地址：https://www.itcodemonkey.com/article/8216.html")]),e._v(" "),v("ol",[v("li",[e._v("第一阶段 优化sql和索引:因为这一步成本最低啊，不需要加什么中间件。你没经过索引优化和SQL优化，就来什么水平拆分，这不是坑人么。")])]),e._v(" "),v("p",[e._v("(1)用慢查询日志定位执行效率低的SQL语句")]),e._v(" "),v("p",[e._v("(2)用explain分析SQL的执行计划")]),e._v(" "),v("p",[e._v("(3)确定问题，采取相应的优化措施，建立索引啊，等")]),e._v(" "),v("ol",{attrs:{start:"2"}},[v("li",[e._v("第二阶段 搭建缓存：在优化sql无法解决问题的情况下，才考虑搭建缓存。毕竟你使用缓存的目的，就是将复杂的、耗时的、不常变的执行结果缓存起来，降低数据库的资源消耗。这里需要注意的是:搭建缓存后，系统的复杂性增加了。你需要考虑很多问题，比如:")])]),e._v(" "),v("p",[e._v("缓存和数据库一致性问题？(比如是更缓存，还是删缓存),这点可以看我的一篇文章《数据库和缓存双写一致性方案解析》。")]),e._v(" "),v("p",[e._v("缓存击穿、缓存穿透、缓存雪崩问题如何解决？是否有做缓存预热的必要。不过我猜，大部分中小公司应该都没考虑。")]),e._v(" "),v("ol",{attrs:{start:"3"}},[v("li",[e._v("第三阶段 读写分离")])]),e._v(" "),v("p",[e._v("缓存也搞不定的情况下，搞主从复制，上读写分离。在应用层，区分读写请求。或者利用现成的中间件mycat或者altas等做读写分离。")]),e._v(" "),v("p",[e._v("(1)主从的好处？：回答:实现数据库备份，实现数据库负载均衡，提高数据库可用性")]),e._v(" "),v("p",[e._v("(2)主从的原理?：主库有一个log dump线程，将binlog传给从库，从库有两个线程，一个I/O线程，一个SQL线程，I/O线程读取主库传过来的binlog内容并写入到relay log,SQL线程从relay log里面读取内容，写入从库的数据库。")]),e._v(" "),v("p",[e._v("(3)如何解决主从一致性?回答:这个问题，我不建议在数据库层面解决该问题。根据CAP定理，主从架构本来就是一种高可用架构，是无法满足一致性的。哪怕你采用同步复制模式或者半同步复制模式，都是弱一致性，并不是强一致性。所以，推荐还是利用缓存，来解决该问题。")]),e._v(" "),v("p",[e._v("步骤如下:")]),e._v(" "),v("p",[e._v("1、自己通过测试，计算主从延迟时间，建议mysql版本为5.7以后，因为mysql自5.7开始，多线程复制功能比较完善，一般能保证延迟在1s内。不过话说回来，mysql现在都出到8.x了，还有人用5.x的版本么。")]),e._v(" "),v("p",[e._v("2、数据库的写操作，先写数据库，再写cache，但是有效期很短，就比主从延时的时间稍微长一点。")]),e._v(" "),v("p",[e._v("3、读请求的时候，先读缓存，缓存存在则直接返回。如果缓存不存在(这时主从同步已经完成)，再读数据库。")]),e._v(" "),v("ol",{attrs:{start:"4"}},[v("li",[e._v("第四阶段 垂直拆分：上面四个阶段都没搞定，就来垂直拆分了。垂直拆分的复杂度还是比水平拆分小的。将你的表，按模块拆分为不同的小表。大家应该都看过《大型网站架构演变之路》，这种类型的文章或者书籍，基本都有提到这一阶段。")])]),e._v(" "),v("p",[e._v("如果你有幸能够在什么运营商、银行等公司上班，你会发现他们一个表，几百个字段都是很常见的事情。所以，应该要进行拆分，拆分原则一般是如下三点:")]),e._v(" "),v("p",[e._v("(1)把不常用的字段单独放在一张表。")]),e._v(" "),v("p",[e._v("(2)把常用的字段单独放一张表")]),e._v(" "),v("p",[e._v("(3)经常组合查询的列放在一张表中（联合索引）。")]),e._v(" "),v("ol",{attrs:{start:"5"}},[v("li",[e._v("第五阶段 水平拆分：OK,水平拆分是最麻烦的一个阶段，拆分后会有很多的问题，我再强调一次，水平拆分一定是最最最最后的选择。从某种意义上，我觉得还不如垂直拆分。因为你用垂直拆分，分成不同模块后，发现单模块的压力过大，你完全可以给该模块单独做优化，例如提高该模块的机器配置等。如果是水平拆分，拆成两张表，代码需要变动，然后发现两张表还不行，再变代码，再拆成三张表的？水平拆分后，各模块间耦合性太强，成本太大，慎重。")])]),e._v(" "),v("h3",{attrs:{id:"乐观锁实现方式"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#乐观锁实现方式"}},[e._v("#")]),e._v(" 乐观锁实现方式")]),e._v(" "),v("ol",[v("li",[e._v("如果数据是单向的，要么增加要么减少数据本身就可以做乐观锁，如果数据不是单向的就是造成ABA的问题")]),e._v(" "),v("li",[e._v("要么就是增加字段了，时间或者版本号都可以")])]),e._v(" "),v("h3",{attrs:{id:"repeatable-read-可重复读-实现原理"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#repeatable-read-可重复读-实现原理"}},[e._v("#")]),e._v(" REPEATABLE READ(可重复读)实现原理")]),e._v(" "),v("p",[e._v("原文地址：https://www.itcodemonkey.com/article/9274.html")]),e._v(" "),v("p",[e._v("Mysql的RR是由“行排它锁+MVCC”一起实现的。大多数数据库系统的默认隔离级别都是READ COMMTTED（但MySQL不是，Mysql的默认隔离级别是REPEATABLE READ）。")]),e._v(" "),v("h3",{attrs:{id:"mysql主从延时这么长-要怎么优化"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#mysql主从延时这么长-要怎么优化"}},[e._v("#")]),e._v(" MySQL主从延时这么长，要怎么优化？")]),e._v(" "),v("p",[e._v("原文地址：https://www.itcodemonkey.com/article/10396.html")]),e._v(" "),v("p",[e._v("原因是MySQL使用单线程重放RelayLog。那么多线程并行重放RelayLog可以缩短时间解决这个问题，需要考虑如何分割RelayLog，才能够让多个数据库实例，多个线程并行重放RelayLog，不会出现不一致。相同库上的写操作，用相同的线程来重放RelayLog；不同库上的写操作，可以并发用多个线程并发来重放RelayLog。")]),e._v(" "),v("p",[e._v("具体到MySQL主从同步延时：")]),e._v(" "),v("ul",[v("li",[e._v("mysql5.5：不支持并行复制，大伙快升级MySQL版本；")]),e._v(" "),v("li",[e._v("mysql5.6：按照库并行复制，建议使用“多库”架构；")]),e._v(" "),v("li",[e._v("mysql5.7：按照GTID并行复制；")])]),e._v(" "),v("h3",{attrs:{id:"建立索引的原则"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#建立索引的原则"}},[e._v("#")]),e._v(" 建立索引的原则")]),e._v(" "),v("p",[e._v("建立索引不是建的越多越好，原则是：")]),e._v(" "),v("p",[e._v("第一：一个表的索引不是越多越好，也没有一个具体的数字，根据以往的经验，一个表的索引最多不能超过6个，因为索引越多，对update和insert操作也会有性能的影响，涉及到索引的新建和重建操作。")]),e._v(" "),v("p",[e._v("第二：建立索引的方法论为：")]),e._v(" "),v("ol",[v("li",[e._v("多数查询经常使用的列；")]),e._v(" "),v("li",[e._v("很少进行修改操作的列；")]),e._v(" "),v("li",[e._v("索引需要建立在数据差异化大的列上")])]),e._v(" "),v("h3",{attrs:{id:"innodb中的行锁与表锁"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#innodb中的行锁与表锁"}},[e._v("#")]),e._v(" Innodb中的行锁与表锁")]),e._v(" "),v("p",[e._v("InnoDB行锁是通过给索引上的索引项加锁来实现的，这一点MySQL与Oracle不同，后者是通过在数据块中对相应数据行加锁来实现的。InnoDB这种行锁实现特点意味着：只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁！")]),e._v(" "),v("p",[e._v("在实际应用中，要特别注意InnoDB行锁的这一特性，不然的话，可能导致大量的锁冲突，从而影响并发性能。")]),e._v(" "),v("ul",[v("li",[e._v("在不通过索引条件查询的时候,InnoDB 确实使用的是表锁,而不是行锁。")]),e._v(" "),v("li",[e._v("由于 MySQL 的行锁是针对索引加的锁,不是针对记录加的锁,所以虽然是访问不同行的记录,但是如果是使用相同的索引键,是会出现锁冲突的。应用设计的时候要注意这一点。")]),e._v(" "),v("li",[e._v("当表有多个索引的时候,不同的事务可以使用不同的索引锁定不同的行,另外,不论 是使用主键索引、唯一索引或普通索引,InnoDB 都会使用行锁来对数据加锁。")]),e._v(" "),v("li",[e._v("即便在条件中使用了索引字段,但是否使用索引来检索数据是由 MySQL 通过判断不同 执行计划的代价来决定的,如果 MySQL 认为全表扫效率更高,比如对一些很小的表,它就不会使用索引,这种情况下 InnoDB 将使用表锁,而不是行锁。因此,在分析锁冲突时, 别忘了检查 SQL 的执行计划,以确认是否真正使用了索引。")])]),e._v(" "),v("h3",{attrs:{id:"行级锁与死锁"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#行级锁与死锁"}},[e._v("#")]),e._v(" 行级锁与死锁")]),e._v(" "),v("p",[e._v("MyISAM中是不会产生死锁的，因为MyISAM总是一次性获得所需的全部锁，要么全部满足，要么全部等待。而在InnoDB中，锁是逐步获得的，就造成了死锁的可能。在MySQL中，行级锁并不是直接锁记录，而是锁索引。索引分为主键索引和非主键索引两种，如果一条sql语句操作了主键索引，MySQL就会锁定这条主键索引；如果一条语句操作了非主键索引，MySQL会先锁定该非主键索引，再锁定相关的主键索引。 在UPDATE、DELETE操作时，MySQL不仅锁定WHERE条件扫描过的所有索引记录，而且会锁定相邻的键值，即所谓的next-key locking。")]),e._v(" "),v("p",[e._v("当两个事务同时执行，一个锁住了主键索引，在等待其他相关索引。另一个锁定了非主键索引，在等待主键索引。这样就会发生死锁。发生死锁后，InnoDB一般都可以检测到，并使一个事务释放锁回退，另一个获取锁完成事务。")]),e._v(" "),v("p",[e._v("有多种方法可以避免死锁，这里只介绍常见的三种")]),e._v(" "),v("ol",[v("li",[e._v("如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表，可以大大降低死锁机会。")]),e._v(" "),v("li",[e._v("在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁产生概率；")]),e._v(" "),v("li",[e._v("对于非常容易产生死锁的业务部分，可以尝试使用升级锁定颗粒度，通过表级锁定来减少死锁产生的概率；")])]),e._v(" "),v("h3",{attrs:{id:"一条sql语句执行得很慢的原因有哪些"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#一条sql语句执行得很慢的原因有哪些"}},[e._v("#")]),e._v(" 一条SQL语句执行得很慢的原因有哪些")]),e._v(" "),v("p",[e._v("一个 SQL 执行的很慢，我们要分两种情况讨论：")]),e._v(" "),v("ol",[v("li",[e._v("大多数情况下很正常，偶尔很慢，则有如下原因")])]),e._v(" "),v("p",[e._v("(1)、数据库在刷新脏页，例如 redo log 写满了需要同步到磁盘。")]),e._v(" "),v("p",[e._v("(2)、执行的时候，遇到锁，如表锁、行锁。")]),e._v(" "),v("ol",{attrs:{start:"2"}},[v("li",[e._v("这条 SQL 语句一直执行的很慢，则有如下原因。")])]),e._v(" "),v("p",[e._v("(1)、没有用上索引：例如该字段没有索引；由于对字段进行运算、函数操作导致无法用索引。")]),e._v(" "),v("p",[e._v("(2)、数据库选错了索引。")]),e._v(" "),v("h3",{attrs:{id:"mysql是怎么解决cpu和硬盘速度不一致问题么"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#mysql是怎么解决cpu和硬盘速度不一致问题么"}},[e._v("#")]),e._v(" MYSQL是怎么解决CPU和硬盘速度不一致问题么")]),e._v(" "),v("p",[e._v("mysql先把数据页加载到内存里，然后读内存中的数据啊")]),e._v(" "),v("h3",{attrs:{id:"说说innodb中lru怎么做的"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#说说innodb中lru怎么做的"}},[e._v("#")]),e._v(" 说说Innodb中LRU怎么做的")]),e._v(" "),v("p",[e._v("原文地址：https://www.itcodemonkey.com/article/14417.html")]),e._v(" "),v("p",[e._v("Innodb为了解决磁盘上磁盘速度和CPU速度不一致的问题，在操作磁盘上的数据时，先将数据加载至内存中，在内存中对数据页进行操作。Mysql在启动的时候，会向内存申请一块连续的空间，这块空间名为Bufffer Pool，也就是缓冲池，默认情况下Buffer Pool只有128M。")]),e._v(" "),v("p",[e._v("有三部分组成:")]),e._v(" "),v("ul",[v("li",[e._v("ctl: 俗称控制体，里头有一个指针指向缓存页，还有一个成员变量存储着所谓的一些所谓的控制信息，例如该页所属的表空间编号、页号")]),e._v(" "),v("li",[e._v("page:缓存页，就是磁盘上的页加载进Bufffer Pool后的结构体")]),e._v(" "),v("li",[e._v("碎片：每个控制体都有一个缓存页。最后内存中会有一点点的空间不足以容纳一对控制体和缓存页，于是碎片就诞生的！")])]),e._v(" "),v("p",[e._v("Innodb将这个链表分为两个部分，也就是所谓的old区和young区。天啦噜，这两个区干嘛用的？")]),e._v(" "),v("ul",[v("li",[e._v("young区在链表的头部，存放经常被访问的数据页，可以理解为热数据！")]),e._v(" "),v("li",[e._v("old区在链表的尾部，存放不经常被访问的数据页，可以理解为冷数据！")])]),e._v(" "),v("p",[e._v("数据何时在old区，何时进入young区？好，数据页第一次被加载进BufferPool时在old区头部。当这个数据页在old区，再次被访问到，会做如下判断")]),e._v(" "),v("ul",[v("li",[e._v("如果这个数据页在LRU链表中old区存在的时间超过了1秒，就把它移动到young区")]),e._v(" "),v("li",[e._v("这个存在时间由innodb_old_blocks_time控制")])]),e._v(" "),v("h3",{attrs:{id:"count-1-、count-与-count-列名-的执行区别"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#count-1-、count-与-count-列名-的执行区别"}},[e._v("#")]),e._v(" count(1)、count(*) 与 count (列名) 的执行区别")]),e._v(" "),v("p",[e._v("执行效果上：")]),e._v(" "),v("ul",[v("li",[e._v("count(*)包括了所有的列，相当于行数，在统计结果的时候，不会忽略列值为NULL")]),e._v(" "),v("li",[e._v("count(1)包括了忽略所有列，用1代表代码行，在统计结果的时候，不会忽略列值为NULL")]),e._v(" "),v("li",[e._v("count(列名)只包括列名那一列，在统计结果的时候，会忽略列值为空（这里的空不是只空字符串或者0，而是表示null）的计数，即某个字段值为NULL时，不统计。")])]),e._v(" "),v("p",[e._v("执行效率上：")]),e._v(" "),v("ul",[v("li",[e._v("列名为主键，count(列名)会比count(1)快")]),e._v(" "),v("li",[e._v("列名不为主键，count(1)会比count(列名)快")]),e._v(" "),v("li",[e._v("如果表多个列并且没有主键，则 count（1） 的执行效率优于 count（*）")]),e._v(" "),v("li",[e._v("如果有主键，则 select count（主键）的执行效率是最优的")]),e._v(" "),v("li",[e._v("如果表只有一个字段，则 select count（*）最优。")])]),e._v(" "),v("h3",{attrs:{id:"mysql复合索引的底层数据结构"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#mysql复合索引的底层数据结构"}},[e._v("#")]),e._v(" mysql复合索引的底层数据结构")]),e._v(" "),v("p",[e._v("原文地址：https://blog.csdn.net/klchht/article/details/78146443")]),e._v(" "),v("p",[e._v("https://segmentfault.com/q/1010000017579884/")]),e._v(" "),v("p",[e._v("首先可以肯定的是，肯定只有一棵树，又因为 最左原则的存在，那么带着这个想法自己试着画了下：")]),e._v(" "),v("p",[v("img",{attrs:{src:"https://txxs.github.io/pic/tofutureinterview/1-16.png",alt:"1"}})]),e._v(" "),v("p",[e._v("联合索引在查找的时候，比如要找 Alice，34 这条记录 WHERE COL3 = 'Alice' AND COL2 = 34先根据col3 查找 Alice ，找到了2条记录，在根据col2 查找 34，然后获取到主键 15 ，在根据主键去查找 主索引。如果 是 WHERE COL2 = 34，由于只有联合索引 (col3, col2)，没有col2 的单列索引。那么查找的时候，就没法根据上面的这棵树来查找 ，只能全表扫描。所以为什么会有最左原则，就是因为 B+树 是根据最左边的字段构建的")]),e._v(" "),v("p",[e._v("下边这种数据结构更合理")]),e._v(" "),v("div",{staticClass:"language- line-numbers-mode"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("create table t1 (a int primary key, b int, c int, d int, e varchar(20));\n\ncreate index idx_t1_bcd on t1(b, c, d);\n\ninsert into t1 values (4,3,1,1,’d’);\ninsert into t1 values (1,1,1,1,’a’);\ninsert into t1 values (8,8,8,8,’h’):\ninsert into t1 values (2,2,2,2,’b’);\ninsert into t1 values (5,2,3,5,’e’);\ninsert into t1 values (3,3,2,2,’c’);\ninsert into t1 values (7,4,5,5,’g’);\ninsert into t1 values (6,6,4,4,’f’);\n")])]),e._v(" "),v("div",{staticClass:"line-numbers-wrapper"},[v("span",{staticClass:"line-number"},[e._v("1")]),v("br"),v("span",{staticClass:"line-number"},[e._v("2")]),v("br"),v("span",{staticClass:"line-number"},[e._v("3")]),v("br"),v("span",{staticClass:"line-number"},[e._v("4")]),v("br"),v("span",{staticClass:"line-number"},[e._v("5")]),v("br"),v("span",{staticClass:"line-number"},[e._v("6")]),v("br"),v("span",{staticClass:"line-number"},[e._v("7")]),v("br"),v("span",{staticClass:"line-number"},[e._v("8")]),v("br"),v("span",{staticClass:"line-number"},[e._v("9")]),v("br"),v("span",{staticClass:"line-number"},[e._v("10")]),v("br"),v("span",{staticClass:"line-number"},[e._v("11")]),v("br"),v("span",{staticClass:"line-number"},[e._v("12")]),v("br")])]),v("p",[v("img",{attrs:{src:"https://txxs.github.io/pic/tofutureinterview/1-17.png",alt:"1"}})]),e._v(" "),v("h3",{attrs:{id:"数据库主从不一致-怎么解"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#数据库主从不一致-怎么解"}},[e._v("#")]),e._v(" 数据库主从不一致，怎么解")]),e._v(" "),v("p",[e._v("原文地址：https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651961330&idx=1&sn=4bdbada3b26d4fc2fc505f7a0f2ad7c4&chksm=bd2d022e8a5a8b38e59f0dfffba7ca407fe8711644b3794832572dd822c665205bb820cdddf7&scene=21#wechat_redirect")]),e._v(" "),v("p",[e._v("方案一：忽略:任何脱离业务的架构设计都是耍流氓，绝大部分业务，例如：百度搜索，淘宝订单，QQ消息，58帖子都允许短时间不一致。画外音：如果业务能接受，最推崇此法。")]),e._v(" "),v("p",[e._v("方案二：强制读主:")]),e._v(" "),v("p",[e._v("（1）使用一个高可用主库提供数据库服务")]),e._v(" "),v("p",[e._v("（2）读和写都落到主库上")]),e._v(" "),v("p",[e._v("（3）采用缓存来提升系统读性能")]),e._v(" "),v("p",[e._v("这是很常见的微服务架构，可以避免数据库主从一致性问题。")]),e._v(" "),v("p",[e._v("方案三：选择性读主")]),e._v(" "),v("p",[e._v("强制读主过于粗暴，毕竟只有少量写请求，很短时间，可能读取到脏数据。当写请求发生时：")]),e._v(" "),v("p",[e._v("（1）写主库")]),e._v(" "),v("p",[e._v("（2）将哪个库，哪个表，哪个主键三个信息拼装一个key设置到cache里，这条记录的超时时间，设置为“主从同步时延”")]),e._v(" "),v("p",[e._v("画外音：key的格式为“db:table:PK”，假设主从延时为1s，这个key的cache超时时间也为1s。")]),e._v(" "),v("p",[e._v("当读请求发生时：")]),e._v(" "),v("p",[e._v("这是要读哪个库，哪个表，哪个主键的数据呢，也将这三个信息拼装一个key，到cache里去查询，如果，")]),e._v(" "),v("p",[e._v("（1）cache里有这个key，说明1s内刚发生过写请求，数据库主从同步可能还没有完成，此时就应该去主库查询")]),e._v(" "),v("p",[e._v("（2）cache里没有这个key，说明最近没有发生过写请求，此时就可以去从库查询")]),e._v(" "),v("p",[e._v("以此，保证读到的一定不是不一致的脏数据。")]),e._v(" "),v("p",[e._v("总结")]),e._v(" "),v("p",[e._v("数据库主库和从库不一致，常见有这么几种优化方案：")]),e._v(" "),v("p",[e._v("（1）业务可以接受，系统不优化")]),e._v(" "),v("p",[e._v("（2）强制读主，高可用主库，用缓存提高读性能")]),e._v(" "),v("p",[e._v("（3）在cache里记录哪些记录发生过写请求，来路由读主还是读从")])])}),[],!1,null,null,null);t.default=a.exports}}]);