(window.webpackJsonp=window.webpackJsonp||[]).push([[231],{614:function(e,s,i){"use strict";i.r(s);var v=i(13),l=Object(v.a)({},(function(){var e=this,s=e.$createElement,i=e._self._c||s;return i("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[i("ol",{attrs:{start:"0"}},[i("li",[e._v("redis基础")])]),e._v(" "),i("p",[e._v("0.1. Redis的使用场景")]),e._v(" "),i("ul",[i("li",[e._v("String：缓存、计数器、分布式锁等。")]),e._v(" "),i("li",[e._v("List：链表、队列、微博关注人时间轴列表等。")]),e._v(" "),i("li",[e._v("Hash：用户信息、Hash 表等。")]),e._v(" "),i("li",[e._v("Set：去重、赞、踩、共同好友等。")]),e._v(" "),i("li",[e._v("Zset：访问量排行榜、点击量排行榜等")])]),e._v(" "),i("p",[e._v("0.2. 那你能说说这些数据类型的使用指令吗？")]),e._v(" "),i("ul",[i("li",[e._v("String: 就是基本的 SET、GET、MSET、MGET、INCR、DECR")]),e._v(" "),i("li",[e._v("List: LPUSH、RPUSH、LRANGE、LINDEX")]),e._v(" "),i("li",[e._v("Hash: HSET、HMSET、HSETNX、HKEYS、HVALS")]),e._v(" "),i("li",[e._v("Set: SADD、SCARD、SDIFF、SREM")]),e._v(" "),i("li",[e._v("SortSet: ZADD、ZCARD、ZCOUNT、ZRANGE")])]),e._v(" "),i("p",[e._v("0.3 redis的数据结构")]),e._v(" "),i("p",[e._v("redisObject：即redis对象，redis数据库是以Key-Value形式存在，当新建一个Key-Value对时，至少会创建两个对象，一个用于作为Key对象，一个用于作为Value对象，每个对象都由一个redisObject的结构表示。Redis 5种基础数据类型分别是字符串(string)、列表(list)、哈希(hash)、集合(set)、有序集合(zset)。 Redis底层的数据结构包括：简单动态数组SDS、链表、字典、跳跃链表、整数集合、压缩列表、对象。")]),e._v(" "),i("p",[e._v("简单动态数组SDS")]),e._v(" "),i("ul",[i("li",[e._v("增加len表示当前字符串的长度：这样就可以直接获取长度了，复杂度 O(1)；因为 C 不保存数组的长度，每次都需要遍历一遍整个数组；")]),e._v(" "),i("li",[e._v("自动扩展空间：当 SDS 需要对字符串进行修改时，首先借助于 len 和 alloc 检查空间是否满足修改所需的要求，如果空间不够的话，SDS 会自动扩展空间，避免了像 C 字符串操作中的覆盖情况；")]),e._v(" "),i("li",[e._v("有效降低内存分配次数：C字符串在涉及增加或者清除操作时会改变底层数组的大小造成重新分配，SDS使用了空间预分配和惰性空间释放机制，简单理解就是每次在扩展时是成倍的多分配的，在缩容是也是先留着并不正式归还给 OS；")]),e._v(" "),i("li",[e._v("二进制安全：C 语言字符串只能保存 ascii 码，对于图片、音频等信息无法保存，SDS 是二进制安全的，写入什么读取就是什么，不做任何过滤和限制；C语言出现的'\\0'可能会被判定为提前结束的字符串而识别不了；")])]),e._v(" "),i("p",[e._v("链表：")]),e._v(" "),i("ul",[i("li",[e._v("Redis 的列表相当于 Java 语言里面的 LinkedList，注意它是链表而不是数组。这意味着 list 的插入和删除操作非常快，时间复杂度为 O(1)，但是索引定位很慢，时间复杂度为 O(n)。")]),e._v(" "),i("li",[e._v("双端： 链表节点带有 prev 和 next 指针， 获取某个节点的前置节点和后置节点的复杂度都是 O(1) 。\n无环： 表头节点的 prev 指针和表尾节点的 next 指针都指向 NULL ， 对链表的访问以 NULL 为终点。\n带表头指针和表尾指针： 通过 list 结构的 head 指针和 tail 指针， 程序获取链表的表头节点和表尾节点的复杂度为 O(1) 。\n带链表长度计数器： 程序使用 list 结构的 len 属性来对 list 持有的链表节点进行计数， 程序获取链表中节点数量的复杂度为 O(1) 。")])]),e._v(" "),i("p",[e._v("字典")]),e._v(" "),i("ul",[i("li",[e._v("Redis 中的字典相当于 Java 中的 HashMap，内部实现也差不多类似，都是通过 “数组 + 链表” 的 链地址法 来解决部分哈希冲突，同时这样的结构也吸收了两种不同数据结构的优点。")]),e._v(" "),i("li",[e._v("字典结构内部包含 两个 hashtable，通常情况下只有一个 hashtable 有值，但是在字典扩容缩容时，需要分配新的 hashtable，然后进行 渐进式搬迁 (rehash)，这时候两个 hashtable 分别存储旧的和新的 hashtable，待搬迁结束后，旧的将被删除，新的 hashtable 取而代之。")]),e._v(" "),i("li",[e._v("正常情况下，当 hash 表中 元素的个数等于第一维数组的长度时，就会开始扩容，扩容的新数组是 原数组大小的 2 倍。不过如果 Redis 正在做 bgsave(持久化命令)，为了减少内存也得过多分离，Redis 尽量不去扩容，但是如果 hash 表非常满了，达到了第一维数组长度的 5 倍了，这个时候就会 强制扩容。当 hash 表因为元素逐渐被删除变得越来越稀疏时，Redis 会对 hash 表进行缩容来减少 hash 表的第一维数组空间占用。所用的条件是 元素个数低于数组长度的 10%，缩容不会考虑 Redis 是否在做 bgsave。")])]),e._v(" "),i("p",[e._v("跳跃链表（Zset）")]),e._v(" "),i("ul",[i("li",[e._v("Zset类似于 Java 的 SortedSet 和 HashMap 的结合体，一方面它是一个 set，保证了内部 value 的唯一性，另一方面它可以给每个 value 赋予一个 score，代表这个 value 的排序权重。它的内部实现用的是一种叫做「跳跃列表」的数据结构。Redis 正是通过 score 来为集合中的成员进行从小到大的排序。Zset 的成员是唯一的，但 score 却可以重复。")]),e._v(" "),i("li",[e._v("跳跃表主要由以下部分构成：表头（head）：负责维护跳跃表的节点指针；跳跃表节点：保存着元素值，以及多个层；层：保存着指向其他元素的指针。高层的指针越过的元素数量大于等于低层的指针，为了提高查找的效率，程序总是从高层先开始访问，然后随着元素值范围的缩小，慢慢降低层次；表尾：全部由 NULL 组成，表示跳跃表的末尾。")]),e._v(" "),i("li",[e._v("Redis 的跳跃表实现由 zskiplist 和 zskiplistNode 两个结构组成， 其中 zskiplist 用于保存跳跃表信息（比如表头节点、表尾节点、长度）， 而 zskiplistNode 则用于表示跳跃表节点；每个跳跃表节点的层高都是 1 至 32 之间的随机数；在同一个跳跃表中， 多个节点可以包含相同的分值， 但每个节点的成员对象必须是唯一的；跳跃表中的节点按照分值大小进行排序， 当分值相同时， 节点按照成员对象的大小进行排序。")])]),e._v(" "),i("p",[e._v("为啥 redis 使用跳表(skiplist)而不是使用 red-black？")]),e._v(" "),i("ul",[i("li",[e._v("skiplist的复杂度和红黑树一样，而且实现起来更简单。")]),e._v(" "),i("li",[e._v("在并发环境下skiplist有另外一个优势，红黑树在插入和删除的时候可能需要做一些rebalance的操作，这样的操作可能会涉及到整个树的其他部分，而skiplist的操作显然更加局部性一些，锁需要盯住的节点更少，因此在这样的情况下性能好一些。")]),e._v(" "),i("li",[e._v("就是在server端，对并发和性能有要求的情况下，如何选择合适的数据结构（这里是跳跃表和红黑树）。如果单纯比较性能，跳跃表和红黑树可以说相差不大，但是加上并发的环境就不一样了，如果要更新数据，跳跃表需要更新的部分就比较少，锁的东西也就比较少，所以不同线程争锁的代价就相对少了，而红黑树有个平衡的过程，牵涉到大量的节点，争锁的代价也就相对较高了。性能也就不如前者了。不过这些对redis这个单进程单线程server来说都是浮云。")])]),e._v(" "),i("p",[e._v("压缩列表：")]),e._v(" "),i("ul",[i("li",[e._v("这是 Redis 为了节约内存 而使用的一种数据结构，zset 和 hash 容器对象会在元素个数较少的时候，采用压缩列表（ziplist）进行存储。压缩列表是 一块连续的内存空间，元素之间紧挨着存储，没有任何冗余空隙。")]),e._v(" "),i("li",[e._v("zlbytes：记录整个压缩列表占用的内存字节数：在对压缩列表进行内存重分配， 或者计算 zlend 的位置时使用；zltail：记录压缩列表表尾节点距离压缩列表的起始地址有多少字节： 通过这个偏移量，程序无须遍历整个压缩列表就可以确定表尾节点的地址；zllen：记录了压缩列表包含的节点数量： 当这个属性的值小于 UINT16_MAX （65535）时， 这个属性的值就是压缩列表包含节点的数量；当这个值等于UINT16_MAX时，节点的真实数量需要遍历整个压缩列表才能计算得出；entryX：压缩列表包含的各个节点，节点的长度由节点保存的内容决定；zlend：特殊值 0xFF （十进制 255 ），用于标记压缩列表的末端。")])]),e._v(" "),i("p",[e._v("0.4 编码维度")]),e._v(" "),i("p",[e._v("字符串对象的编码可以是int、raw或者embstr。")]),e._v(" "),i("ul",[i("li",[e._v("如果一个字符串对象保存的是整数值， 并且这个整数值可以用long类型来表示， 那么字符串对象会将整数值保存在字符串对象结构的ptr属性里面（将 void* 转换成 long ），并将字符串对象的编码设置为int。")]),e._v(" "),i("li",[e._v("如果字符串对象保存的是一个字符串值， 并且这个字符串值的长度大于39字节， 那么字符串对象将使用一个简单动态字符串（SDS）来保存这个字符串值， 并将对象的编码设置为raw。")]),e._v(" "),i("li",[e._v("如果字符串对象保存的是一个字符串值， 并且这个字符串值的长度小于等于39字节， 那么字符串对象将使用 embstr 编码的方式来保存这个字符串值。")]),e._v(" "),i("li",[e._v("embstr编码是专门用于保存短字符串的一种优化编码方式， 这种编码和raw编码一样，都使用redisObject结构和sdshdr结构来表示字符串对象， 但raw编码会调用两次内存分配函数来分别创建redisObject结构和sdshdr 结构， 而embstr编码则通过调用一次内存分配函数来分配一块连续的空间， 空间中依次包含redisObject和sdshdr两个结构。")])]),e._v(" "),i("p",[e._v("列表对象")]),e._v(" "),i("ul",[i("li",[e._v("编码可以是 ziplist 或者 linkedlist，ziplist 编码的列表对象使用压缩列表作为底层实现，每个压缩列表节点（entry）保存了一个列表元素。")]),e._v(" "),i("li",[e._v("linkedlist编码的列表对象使用双端链表作为底层实现， 每个双端链表节点（node）都保存了一个字符串对象， 而每个字符串对象都保存了一个列表元素。")])]),e._v(" "),i("p",[e._v("哈希对象\n编码可以是 ziplist 或者 hashtable 。")]),e._v(" "),i("ul",[i("li",[e._v("ziplist 编码的哈希对象使用压缩列表作为底层实现， 每当有新的键值对要加入到哈希对象时， 程序会先将保存了键的压缩列表节点推入到压缩列表表尾， 然后再将保存了值的压缩列表节点推入到压缩列表表尾， 因此： 保存了同一键值对的两个节点总是紧挨在一起， 保存键的节点在前， 保存值的节点在后；\n先添加到哈希对象中的键值对会被放在压缩列表的表头方向， 而后来添加到哈希对象中的键值对会被放在压缩列表的表尾方向。")]),e._v(" "),i("li",[e._v("进行渐进式 rehash 的过程中， 字典会同时使用 ht[0] 和 ht[1] 两个哈希表， 所以在渐进式 rehash 进行期间， 字典的删除（delete）、查找（find）、更新（update）等操作会在两个哈希表上进行： 比如说， 要在字典里面查找一个键的话， 程序会先在 ht[0] 里面进行查找， 如果没找到的话， 就会继续到 ht[1] 里面进行查找， 诸如此类。 另外， 在渐进式 rehash 执行期间， 新添加到字典的键值对一律会被保存到 ht[1] 里面， 而 ht[0] 则不再进行任何添加操作： 这一措施保证了 ht[0] 包含的键值对数量会只减不增， 并随着 rehash 操作的执行而最终变成空表。")])]),e._v(" "),i("p",[e._v("集合对象")]),e._v(" "),i("ul",[i("li",[e._v("集合对象的编码可以是 intset 或者 hashtable 。intset 编码的集合对象使用整数集合作为底层实现， 集合对象包含的所有元素都被保存在整数集合里面。")])]),e._v(" "),i("p",[e._v("有序集合对象")]),e._v(" "),i("ul",[i("li",[e._v("有序集合的编码可以是 ziplist 或者 skiplist 。ziplist 编码的有序集合对象使用压缩列表作为底层实现， 每个集合元素使用两个紧挨在一起的压缩列表节点来保存， 第一个节点保存元素的成员（member）， 而第二个元素则保存元素的分值（score）。压缩列表内的集合元素按分值从小到大进行排序， 分值较小的元素被放置在靠近表头的方向， 而分值较大的元素则被放置在靠近表尾的方向。")])]),e._v(" "),i("ol",[i("li",[e._v("redis分布式锁")])]),e._v(" "),i("ul",[i("li",[e._v("SETNX 是『SET if Not eXists』(如果不存在，则 SET)的简写。返回值：设置成功，返回 1 。设置失败，返回 0 。再加上过期时间，删除锁用delete，但是这种设计有个问题就是存在redis锁并发竞争的问题，解决方案：基于zookeeper临时有序节点可以实现的分布式锁。大致思想为：每个客户端对某个方法加锁时，在zookeeper上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点。 判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。完成业务流程后，删除对应的子节点释放锁。")]),e._v(" "),i("li",[e._v("为了防止redis分布式锁单点问题（分布式锁，当我们请求一个分布式锁的时候，成功了，但是这时候slave还没有复制我们的锁，masterDown了，我们的应用继续请求锁的时候，会从继任了master的原slave上申请，也会成功。这就会导致，同一个锁被获取了不止一次。）：有另外一种锁，叫红锁，流程如下：有效的避免了获取redis发生down机或超时造成的阻塞状态，我们设置获取锁的尝试时间远远小于锁的超时时间，当reids不可用时立刻与下一个redis进行通信；对集群的每个节点进行加锁，如果大多数（N/2+1）加锁成功了，则认为获取锁成功；如果锁获取成功了，锁的超时时间就是最初的锁超时时间减去获取锁的总耗时时间；如果锁获取失败了，去尽快释放（部分）获得的锁")])]),e._v(" "),i("ol",{attrs:{start:"2"}},[i("li",[i("p",[e._v("假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来？")]),e._v(" "),i("p",[e._v("使用keys指令可以扫出指定模式的key列表。对方接着追问：如果这个redis正在给线上的业务提供服务，那使用keys指令会有什么问题？这个时候你要回答redis关键的一个特性：redis的单线程的。keys指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。这个时候可以使用scan指令，scan指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用keys指令长。")])]),e._v(" "),i("li",[i("p",[e._v("单线程那么快")]),e._v(" "),i("p",[e._v("至于为什么单线程那么快我觉得主要有以下几个原因：")])])]),e._v(" "),i("ul",[i("li",[e._v("首先，一个重要的原因是，Redis 的大部分操作都在内存中完成，并且采用了高效的数据结构，比如哈希表和跳表。")]),e._v(" "),i("li",[e._v("其次，因为是单线程模型避免了多线程之间的竞争，省去了多线程切换带来的时间和性能上的开销，而且也不会导致死锁问题。")]),e._v(" "),i("li",[e._v("最后，也是最重要的一点， Redis 采用了 I/O 多路复用机制处理大量的客户端 Socket 请求，这让 Redis 可以高效地进行网络通信，因为基于非阻塞的 I/O 模型，就意味着 I/O 的读写流程不再阻塞。")])]),e._v(" "),i("ol",{attrs:{start:"4"}},[i("li",[e._v("Redis 属于单线程还是多线程？")])]),e._v(" "),i("ul",[i("li",[e._v("Redis 是单线程的，主要是指 Redis 的网络 I/O 线程，以及键值的 SET 和 GET 等读写操作都是由一个线程来完成的。但 Redis 的持久化、集群同步等操作，则是由另外的线程来执行的。但是因为 Redis 不同版本的特殊性，所以对于 Redis 的线程模型要分版本来看。")]),e._v(" "),i("li",[e._v("Redis 4.0 版本之前，使用单线程速度快的原因就是上述的几个原因；")]),e._v(" "),i("li",[e._v("Redis 4.0 版本之后，Redis 添加了多线程的支持，但这时的多线程主要体现在大数据的异步删除功能上，例如 unlink key、flushdb async、flushall async 等。")]),e._v(" "),i("li",[e._v("Redis 6.0 版本之后，为了更好地提高 Redis 的性能，新增了多线程 I/O 的读写并发能力，但是在面试中，能把 Redis 6.0 中的多线程模型回答上来的人很少，如果你能在面试中补充 Redis 6.0 多线程的原理，势必会增加面试官对你的认可。你可以在面试中这样补充：虽然 Redis 一直是单线程模型，但是在 Redis 6.0 版本之后，也采用了多个 I/O 线程来处理网络请求，这是因为随着网络硬件的性能提升，Redis 的性能瓶颈有时会出现在网络 I/O 的处理上，所以为了提高网络请求处理的并行度，Redis 6.0 对于网络请求采用多线程来处理。但是对于读写命令，Redis 仍然使用单线程来处理。")]),e._v(" "),i("li",[e._v("Redis6.0引入了多线程的特性，这个多线程是在哪里呢？——「是对处理网络请求过程采用了多线程」。Redis6.0采用多个IO线程来处理网络请求，网络请求的解析可以由其他线程完成，然后把解析后的请求交由主线程进行实际的内存读写。提升网络请求处理的并行度，进而提升整体性能。那么多并发的线程安全问题存在吗？——当然不存在。「Redis 的多 IO 线程只是用来处理网络请求的，对于命令的执行，Redis 仍然使用单线程来处理。")])]),e._v(" "),i("ol",{attrs:{start:"4"}},[i("li",[e._v("Redis实现高可用主要有三种方式：主从复制、哨兵模式，以及Redis集群。")])]),e._v(" "),i("ul",[i("li",[i("p",[e._v("主从复制:将从前的一台 Redis 服务器，同步数据到多台从 Redis 服务器上，即一主多从的模式，这个跟MySQL主从复制的原理一样。")])]),e._v(" "),i("li",[i("p",[e._v("哨兵模式:使用 Redis 主从服务的时候，会有一个问题，就是当 Redis 的主从服务器出现故障宕机时，需要手动进行恢复，为了解决这个问题，Redis 增加了哨兵模式（因为哨兵模式做到了可以监控主从服务器，并且提供自动容灾恢复的功能）。使用哨兵模式在数据上有副本数据做保证，在可用性上又有哨兵监控，一旦master宕机会选举salve节点为master节点，这种已经满足了我们的生产环境需要，那为什么还需要使用集群模式呢？**哨兵模式归根节点还是主从模式，在主从模式下我们可以通过增加slave节点来扩展读并发能力，但是没办法扩展写能力和存储能力，存储能力只能是master节点能够承载的上限。所以为了扩展写能力和存储能力，我们就需要引入集群模式。")])]),e._v(" "),i("li",[i("p",[e._v("Redis Cluster（集群）:Redis Cluster 是一种分布式去中心化的运行模式，最大的优势是增加了redis集群的扩展性。RedisCluster采用的是类一致性哈希算法实现节点选择的，至于什么是一致性哈希算法你自己回去看看。RedisCluster将自己分成了16384个Slot（槽位），哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个哈希槽中，具体执行过程分为两大步。根据键值对的 key，按照 CRC16 算法计算一个 16 bit 的值。再用 16bit 值对 16384 取模，得到 0~16383 范围内的模数，每个模数代表一个相应编号的哈希槽。 每个Redis节点负责处理一部分槽位。假设要新增机器怎么办Redis集群不使用一致性哈希,而是不同形式的分片,这可以确保每个key都可以存入到一个我们称之为哈希槽(hash slot)中Redis集群中共有16384个哈希槽(hashslot),通过CRC16算法可以计算出一个给定的key属于哪个哈希槽中.集群中的每个节点都负责处理这16384个哈希槽的一部分.例如,在一个三个节点组成的集群中:节点A负责处理0到5500个哈希槽；节点B负责处理5501到11000个哈希槽；节点C负责处理11001到16383个哈希槽。通过这种方法我们可以很方便的向集群添加或者移除节点.例如我们想添加一个节点D到集群,只需要从节点A或B或C负责的哈希槽中转移一部分到节点D上,节点D即可以上线提供服务.又例如节点A因硬件性能问题需要退役,我们只需要将节点A负责的哈希槽转移到其他节点上,即可将A节点从集群剔除")]),e._v(" "),i("p",[e._v("哨兵的核心知识")])]),e._v(" "),i("li",[i("p",[e._v("哨兵至少需要 3 个实例，来保证自己的健壮性。")])]),e._v(" "),i("li",[i("p",[e._v("哨兵 + redis 主从的部署架构，是不保证数据零丢失的，只能保证 redis 集群的高可用性。")])]),e._v(" "),i("li",[i("p",[e._v("对于哨兵 + redis 主从这种复杂的部署架构，尽量在测试环境和生产环境，都进行充足的测试和演练。")])])]),e._v(" "),i("ol",{attrs:{start:"5"}},[i("li",[e._v("为什么Redis集群有16384个槽")])]),e._v(" "),i("ul",[i("li",[e._v("(1)如果槽位为65536，发送心跳信息的消息头达8k，发送的心跳包过于庞大。如上所述，在消息头中，最占空间的是myslots[CLUSTER_SLOTS/8]。当槽位为65536时，这块的大小是:65536÷8÷1024=8kb，因为每秒钟，redis节点需要发送一定数量的ping消息作为心跳包，如果槽位为65536，这个ping消息的消息头太大了，浪费带宽。")]),e._v(" "),i("li",[e._v("(2)redis的集群主节点数量基本不可能超过1000个。如上所述，集群节点越多，心跳包的消息体内携带的数据越多。如果节点过1000个，也会导致网络拥堵。因此redis作者，不建议redis cluster节点数量超过1000个。那么，对于节点数在1000以内的redis cluster集群，16384个槽位够用了。没有必要拓展到65536个。")]),e._v(" "),i("li",[e._v("(3)槽位越小，节点少的情况下，压缩比高。Redis主节点的配置信息中，它所负责的哈希槽是通过一张bitmap的形式来保存的，在传输过程中，会对bitmap进行压缩，但是如果bitmap的填充率slots / N很高的话(N表示节点数)，bitmap的压缩率就很低。 如果节点数很少，而哈希槽数量很多的话，bitmap的压缩率就很低。")])]),e._v(" "),i("ol",{attrs:{start:"5"}},[i("li",[e._v("那Redis是如何实现数据不丢失的呢？\nRedis数据是存储在内存中的，为了保证Redis数据不丢失，那就要把数据从内存存储到磁盘上，以便在服务器重启后还能够从磁盘中恢复原有数据，这就是Redis的数据持久化。Redis数据持久化有三种方式。")])]),e._v(" "),i("ul",[i("li",[i("p",[e._v("AOF 日志（Append Only File，文件追加方式）：记录所有的操作命令，并以文本的形式追加到文件中。")])]),e._v(" "),i("li",[i("p",[e._v("RDB 快照（Redis DataBase）：将某一个时刻的内存数据，以二进制的方式写入磁盘。Redis 提供了两个命令来生成 RDB 快照文件，分别是 save 和 bgsave。save 命令在主线程中执行，会导致阻塞。而 bgsave 命令则会创建一个子进程，用于写入 RDB 文件的操作，避免了对主线程的阻塞，这也是 Redis RDB 的默认配置。save是同步的会阻塞客户端命令，bgsave的时候是可以修改的。")])]),e._v(" "),i("li",[i("p",[e._v("混合持久化方式：Redis 4.0 新增了混合持久化的方式，集成了 RDB 和 AOF 的优点。Redis是怎么解决在bgsave做快照的时候允许数据修改呢？这里主要是利用 bgsave的子线程实现的，具体操作如下：如果主线程执行读操作，则主线程和 bgsave 子进程互相不影响；如果主线程执行写操作，则被修改的数据会复制一份副本，然后 bgsave子进程会把该副本数据写入 RDB 文件，在这个过程中，主线程仍然可以直接修改原来的数据。要注意，Redis 对 RDB 的执行频率非常重要，因为这会影响快照数据的完整性以及 Redis 的稳定性，所以在 Redis 4.0 后，增加了 AOF 和 RDB 混合的数据持久化机制： 把数据以 RDB 的方式写入文件，再将后续的操作命令以 AOF 的格式存入文件，既保证了 Redis 重启速度，又降低数据丢失风险。\nAOF和 RDB的实现原理AOF采用的是写后日志的方式，Redis先执行命令把数据写入内存，然后再记录日志到文件中。AOF日志记录的是操作命令，不是实际的数据，如果采用AOF方法做故障恢复时需要将全量日志都执行一遍。RDB采用的是内存快照的方式，它记录的是某一时刻的数据，而不是操作，所以采用RDB方法做故障恢复时只需要直接把RDB文件读入内存即可，实现快速恢复。")]),e._v(" "),i("p",[e._v("AOF整个流程分两步：")])]),e._v(" "),i("li",[i("p",[e._v("第一步是命令的实时写入，不同级别可能有1秒数据损失。命令先追加到aof_buf然后再同步到AO磁盘，如果实时写入磁盘会带来非常高的磁盘IO，影响整体性能。")])]),e._v(" "),i("li",[i("p",[e._v("第二步是对aof文件的重写，目的是为了减少AOF文件的大小，可以自动触发或者手动触发(BGREWRITEAOF)，是Fork出子进程操作，期间Redis服务仍可用。")])]),e._v(" "),i("li",[i("p",[e._v("在重写期间，由于主进程依然在响应命令，为了保证最终备份的完整性；它依然会写入旧的AOF中，如果重写失败，能够保证数据不丢失。")])]),e._v(" "),i("li",[i("p",[e._v("为了把重写期间响应的写入信息也写入到新的文件中，因此也会为子进程保留一个buf，防止新写的file丢失数据。")])])]),e._v(" "),i("ol",{attrs:{start:"5"}},[i("li",[i("p",[e._v("bgsave的原理是什么？\n你给出两个词汇就可以了，fork和cow。fork是指redis通过创建子进程来进行bgsave操作，cow指的是copy on write，子进程创建后，父子进程共享数据段，父进程继续提供读写服务，写脏的页面数据会逐渐和子进程分离开来。")])]),e._v(" "),i("li",[i("p",[e._v("Redis为什么要先执行命令，再把数据写入日志呢？")]),e._v(" "),i("p",[e._v("主要是由于Redis在写入日志之前，不对命令进行语法检查，所以只记录执行成功的命令，避免出现记录错误命令的情况，而且在命令执行后再写日志不会阻塞当前的写操作。后写日志主要有两个风险可能会发生：数据可能会丢失：如果Redis刚执行完命令，此时发生故障宕机，会导致这条命令存在丢失的风险;可能阻塞其他操作：AOF日志其实也是在主线程中执行，所以当Redis把日志文件写入磁盘的时候，还是会阻塞后续的操作无法执行。")])]),e._v(" "),i("li",[i("p",[e._v("什么是io多路复用\n假设你是一个老师，让30个学生解答一道题目，然后检查学生做的是否正确，你有下面几个选择：\n第一种选择：按顺序逐个检查，先检查A，然后是B，之后是C、D。。。这中间如果有一个学生卡主，全班都会被耽误。这种模式就好比，你用循环挨个处理socket，根本不具有并发能力。\n第二种选择，你站在讲台上等，谁解答完谁举手。这时C、D举手，表示他们解答问题完毕，你下去依次检查C、D的答案，然后继续回到讲台上等。此时E、A又举手，然后去处理E和A。\n第一种就是阻塞IO模型，第二种就是I/O复用模型，Linux下的select、poll和epoll就是干这个的。将用户socket对应的fd注册进epoll，然后epoll帮你监听哪些socket上有消息到达，这样就避免了大量的无用操作。此时的socket应该采用非阻塞模式。这样，整个过程只在调用select、poll、epoll这些调用的时候才会阻塞，收发客户消息是不会阻塞的，整个进程或者线程就被充分利用起来，这就是事件驱动，所谓的reactor模式。")])]),e._v(" "),i("li",[i("p",[e._v("Redis的事务")]),e._v(" "),i("p",[e._v("Redis的事务本质是一组命令的集合，一个事务中的命令要么全部执行，要么都不执行。事务的原理是先将属于一个事务的命令发送给Redis，存放到一个队列中，再让Redis依次执行这些命令。如果在发送EXEC命令前客户端断线了，则Redis会清空事务队列，事务中的所有命令都不会执行。而一旦客户端发送了EXEC命令，所有的命令就都会被执行，即使此后客户端断线也没关系，因为Redis中已经记录了所有要执行的命令。\n除此之外，Redis的事务还能保证一个事务内的命令依次执行而不被其他命令插入。也就是说，在事务执行期间，服务器不会中断事务而改去执行其他客户端的命令请求，即不会被其它命令插入，不许加塞，等事务中的所有命令都执行完毕才去处理其他客户端的命令请求。即一次性、顺序性、排他性的执行一系列命令。")])])]),e._v(" "),i("ul",[i("li",[e._v("WATCH：当某个事务需要按条件执行时，就要使用该命令将key设置为受监控的。如果在事务执行之前这些key被其他命令所改动，那么整个事务将会被打断。WATCH命令可用于提供CAS功能。利用watch实现incr")]),e._v(" "),i("li",[e._v("MULTI：用于标记事务块的开启。MULTI执行之后，Redis会将后续的命令逐个放到一个缓存队列中，当EXEC命令被调用时，所有队列中的命令才会被原子化执行。")]),e._v(" "),i("li",[e._v("EXEC：在一个事务中执行所有先前放入队列的命令，然后恢复正常的连接状态。当使用WATCH命令时，只有当受监控的键没有被修改时，EXEC命令才会执行事务中的命令。")])]),e._v(" "),i("ol",{attrs:{start:"9"}},[i("li",[e._v("缓存一致性")])]),e._v(" "),i("ul",[i("li",[e._v("写入（插入数据时，同时写入Redis）：队列 + 重试机制：流程如下所示1.更新数据库数据；2.缓存因为种种问题删除失败；3.将需要删除的key发送至消息队列；4.自己消费消息，获得需要删除的key；5.继续重试删除操作，直到成功；然而，该方案有一个缺点，对业务线代码造成大量的侵入。")]),e._v(" "),i("li",[e._v("读取：从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中（避免缓存击穿：数据库没有就需要命中的数据，导致Redis一直没有数据，而一直命中数据库。）；如果是更新的话，先把数据存到数据库中，成功后，再让缓存失效。")])])])}),[],!1,null,null,null);s.default=l.exports}}]);