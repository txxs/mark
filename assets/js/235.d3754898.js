(window.webpackJsonp=window.webpackJsonp||[]).push([[235],{615:function(_,v,l){"use strict";l.r(v);var e=l(13),i=Object(e.a)({},(function(){var _=this,v=_.$createElement,l=_._self._c||v;return l("ContentSlotsDistributor",{attrs:{"slot-key":_.$parent.slotKey}},[l("p",[_._v("1.0. DB数据存储")]),_._v(" "),l("ul",[l("li",[_._v("一般来说，B+Tree比B-Tree更适合实现外存储索引结构，具体原因与外存储器原理及计算机存取原理有关，红黑树等数据结构也可以用来实现索引，但是文件系统及数据库系统普遍采用B-/+Tree作为索引结构，一般来说，索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上。这样的话，索引查找过程中就要产生磁盘I/O消耗，相对于内存存取，I/O存取的消耗要高几个数量级，所以评价一个数据结构作为索引的优劣最重要的指标就是在查找过程中磁盘I/O操作次数的渐进复杂度。换句话说，索引的结构组织要尽量减少查找过程中磁盘I/O的存取次数。下面先介绍内存和磁盘存取原理，然后再结合这些原理分析B-/+Tree作为索引的效率。")]),_._v(" "),l("li",[_._v("计算机系统有主存和基于磁盘的辅存，主存通常就是我们说的RAM，也就是内存，这里不展开说它。索引文件本身很大，一般不会存在内存里，因此索引往往是以文件的形式存储在磁盘里，所以索引检索需要磁盘I/O操作。磁盘读取数据靠的是磁盘的机械运动。每次磁盘读取的时间有三部分：寻道时间、旋转延迟、传输时间。寻道时间指的是磁臂移动到指定磁道所需要的时间，主流磁盘一般在5ms以下；旋转延迟就是我们经常听说的磁盘转速，比如一个磁盘7200转，表示每分钟能转7200次，也就是说1秒钟能转120次，旋转延迟就是1/120/2=4.17ms；传输时间指的是从磁盘读出或将数据写入磁盘的时间，一般在零点几毫秒，相对于前两个时间可以忽略。那么访问一次磁盘读取数据的时间，即一次磁盘I/O操作的时间约9ms左右，这相对于主存存储时间50ns高出5个数量级。看着还不错的，但是一台500-MIPS（500百万每秒）的机器每秒可以执行5亿条指令，因为指令依靠的是电的性质，换句话说执行一次IO的时间可以执行40万条指令，数据库动辄十万百万乃至千万级数据，每次9毫秒的时间，显然是个灾难。更详细的过程阅读：http://blog.codinglabs.org/articles/theory-of-mysql-index.html。磁盘IO时间 = 寻道 + 磁盘旋转 + 数据传输时间")]),_._v(" "),l("li",[_._v("为了缩短磁盘读取的时间，计算机做了一些优化：磁盘预读。磁盘预读是基于局部性原理：当一个数据被用到时，其附近的数据也通常会马上被使用。所以磁盘I/O操作时不光把当前磁盘地址的数据，而是把相邻的数据也都读取到内存缓冲区内，因为局部性原理告诉我们，当计算机访问一个地址的数据的时候，与其相邻的数据也会很快被访问到。预读的长度一般为页（page）的整倍数。页是计算机管理存储器的逻辑块，硬件及操作系统往往将主存和磁盘存储区分割为连续的大小相等的块，每个存储块称为一页（在许多操作系统中，页得大小通常为4k），主存和磁盘以页为单位交换数据。")]),_._v(" "),l("li",[_._v("文件很大，不可能全部存储在内存中，故要存储到磁盘上。索引的结构组织要尽量减少查找过程中磁盘I/O的存取次数，因为每次磁盘I/O消耗时间都是非常多的。局部性原理与磁盘预读，预读的长度一般为页（page）的整倍数。")]),_._v(" "),l("li",[_._v("数据库系统巧妙利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入。B-树也利用这一点，每次新建节点时，直接申请一个页的空间，这样就保证一个节点物理上也存储在一个页里，加之计算机存储分配都是按页对齐的，就实现了一次磁盘I/O就读取了一页的数据。")]),_._v(" "),l("li",[_._v("InnoDB 使用页作为磁盘管理的最小单位；数据在 InnoDB 存储引擎中都是按行存储的，每个 16KB 大小的页中可以存放 2-200 行的记录。")])]),_._v(" "),l("p",[_._v("1.1. sql执行过程")]),_._v(" "),l("ul",[l("li",[_._v("查询语句的执行流程如下：权限校验（如果命中缓存）---\x3e查询缓存---\x3e分析器---\x3e优化器---\x3e权限校验---\x3e执行器---\x3e引擎")]),_._v(" "),l("li",[_._v("更新语句执行流程如下：分析器----\x3e权限校验----\x3e执行器---\x3e引擎---redo log(prepare 状态)---\x3ebinlog---\x3eredo log(commit状态)")])]),_._v(" "),l("p",[_._v("2.0. 索引分类")]),_._v(" "),l("ul",[l("li",[_._v("主键索引：树的叶子节点直接就是我们要查询的整行数据了。")]),_._v(" "),l("li",[_._v("非主键索引：树的叶子节点是主键的值，查到主键的值以后，还需要再通过主键的值再进行一次查询。主键索引查询只会查一次，而非主键索引需要回表查询多次。")]),_._v(" "),l("li",[_._v("覆盖索引：指一个查询语句的执行只用从索引中就能够取得，不必从数据表中读取。也可以称之为实现了索引覆盖。当一条查询语句符合覆盖索引条件时，MySQL只需要通过索引就可以返回查询所需要的数据，这样避免了查到索引后再返回表操作，减少I/O提高效率。")])]),_._v(" "),l("p",[_._v("2.1. 索引的本质是数据结构，可以选择的数据结构有哪些？")]),_._v(" "),l("ul",[l("li",[_._v("二叉树：二叉树在某些场景下退化成了链表，这就是mysql索引底层没有使用二叉树这种数据结构的原因之一。")]),_._v(" "),l("li",[_._v("红黑树：是一种平衡二叉树，JDK1.8的hashmap就用到了红黑树。我们只有7条记录，树的高度就达到了4层，那数百万数千万甚至上亿记录的表创建的索引它的树高得有多高？一般来说都是从根节点开始查找，假如树的高度是50，那我要进行50次查找，50次磁盘IO那得多慢啊这开销已经很大了。这就是红黑树作为索引数据结构的弊端：树的高度过高导致查询效率变慢。\nhash")]),_._v(" "),l("li",[_._v("B-Tree:也就是说在一个节点上可以存储更多的元素，k-v，key就是索引字段，data就是索引字段所在的那一行的数据或是那一行数据坐在的的磁盘文件地址、指针，再去查找元素的时候一次性不是Load一个小元素，而是把一个大的节点的数据一次性全部load到内存，然后再在内存里再去比对，在内存里操作是比较快的。如果我们要查找49这个元素，实际上是从根节点开始查找的，它一次性将根节点这个大节点一次性load到内存里，然后用要查找的元素在这里去比对，49大于15小于56，在15和56之间有一个节点存储的是下一个节点的磁盘地址指向下一个节点（这个节点的索引都是大于15小于56的），然后再将这个节点一次性load到内存去找这个元素，然后比对就找到了。这个节点的大小设置要合适，不能太大也不能太小，mysql对这个节点大小设置的是16K")])]),_._v(" "),l("p",[_._v("2.2. 索引为什么选择B树")]),_._v(" "),l("ul",[l("li",[_._v("B-Tree是为磁盘等外存储设备设计的一种平衡查找树。")]),_._v(" "),l("li",[_._v("系统从磁盘读取数据到内存时是以磁盘块（block）为基本单位的，位于同一个磁盘块中的数据会被一次性读取出来，而不是需要什么取什么。")]),_._v(" "),l("li",[_._v("InnoDB 存储引擎中有页（Page）的概念，页是其磁盘管理的最小单位。InnoDB 存储引擎中默认每个页的大小为16KB，可通过参数 innodb_page_size 将页的大小设置为 4K、8K、16K，在 MySQL 中可通过如下命令查看页的大小：show variables like 'innodb_page_size';而系统一个磁盘块的存储空间往往没有这么大，因此 InnoDB 每次申请磁盘空间时都会是若干地址连续磁盘块来达到页的大小 16KB。InnoDB 在把磁盘数据读入到磁盘时会以页为基本单位，在查询数据时如果一个页中的每条数据都能有助于定位数据记录的位置，这将会减少磁盘I/O次数，提高查询效率。")]),_._v(" "),l("li",[_._v("B-Tree 结构的数据可以让系统高效的找到数据所在的磁盘块。")])]),_._v(" "),l("p",[_._v("2.3. B树木的概念")]),_._v(" "),l("ul",[l("li",[_._v("每个节点最多有m个孩子")]),_._v(" "),l("li",[_._v("除了根节点和叶子节点外，其它每个节点至少有Ceil(m/2)个孩子。")]),_._v(" "),l("li",[_._v("若根节点不是叶子节点，则至少有2个孩子")]),_._v(" "),l("li",[_._v("所有叶子节点都在同一层，且不包含其它关键字信息")]),_._v(" "),l("li",[_._v("每个非终端节点包含n个关键字信息（P0,P1,…Pn, k1,…kn）")]),_._v(" "),l("li",[_._v("关键字的个数n满足：ceil(m/2)-1 <= n <= m-1")])]),_._v(" "),l("p",[_._v("2.4. B+Tree和B树的不同")]),_._v(" "),l("ul",[l("li",[_._v("非叶子节点只存储键值信息；")]),_._v(" "),l("li",[_._v("所有叶子节点之间都有一个链指针；")]),_._v(" "),l("li",[_._v("数据记录都存放在叶子节点中")])]),_._v(" "),l("p",[_._v("2.5. 数据库为什么使用B+树而不是B树")]),_._v(" "),l("ul",[l("li",[_._v("B树只适合随机检索，而B+树同时支持随机检索和顺序检索；")]),_._v(" "),l("li",[_._v("B+树空间利用率更高，可减少I/O次数，磁盘读写代价更低。一般来说，索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上。这样的话，索引查找过程中就要产生磁盘I/O消耗。B+树的内部结点并没有指向关键字具体信息的指针，只是作为索引使用，其内部结点比B树小，盘块能容纳的结点中关键字数量更多，一次性读入内存中可以查找的关键字也就越多，相对的，IO读写次数也就降低了。而IO读写次数是影响索引检索效率的最大因素；")]),_._v(" "),l("li",[_._v("B+树的查询效率更加稳定。B树搜索有可能会在非叶子结点结束，越靠近根节点的记录查找时间越短，只要找到关键字即可确定记录的存在，其性能等价于在关键字全集内做一次二分查找。而在B+树中，顺序检索比较明显，随机检索时，任何关键字的查找都必须走一条从根节点到叶节点的路，所有关键字的查找路径长度相同，导致每一个关键字的查询效率相当。")]),_._v(" "),l("li",[_._v("B-树在提高了磁盘IO性能的同时并没有解决元素遍历的效率低下的问题。B+树的叶子节点使用指针顺序连接在一起，只要遍历叶子节点就可以实现整棵树的遍历。而且在数据库中基于范围的查询是非常频繁的，而B树不支持这样的操作。")]),_._v(" "),l("li",[_._v("增删文件（节点）时，效率更高。因为B+树的叶子节点包含所有关键字，并以有序的链表结构存储，这样可很好提高增删效率。")])]),_._v(" "),l("p",[_._v("2.6. b+树的查找过程")]),_._v(" "),l("ul",[l("li",[_._v("假设我们用以下数字构建一个树：3、5、9、10、13、15、28、29、36、60、75、79、90、99那么首先会把磁盘块1由磁盘加载到内存，此时发生一次IO。")]),_._v(" "),l("li",[_._v("在内存中用二分查找确定29在17和35之间，锁定磁盘块1的P2指针，内存时间因为非常短（相比磁盘的IO）可以忽略不计。")]),_._v(" "),l("li",[_._v("通过磁盘块1的P2指针的磁盘地址把磁盘块3由磁盘加载到内存，发生第二次IO。")]),_._v(" "),l("li",[_._v("29在26和30之间，锁定磁盘块3的P2指针，通过指针加载磁盘块8到内存，发生第三次IO，同时内存中做二分查找找到29，结束查询，总计三次IO。")]),_._v(" "),l("li",[_._v("真实的情况是，3层的b+树可以表示上百万的数据，如果上百万的数据查找只需要三次IO，性能提高将是巨大的，如果没有索引，每个数据项都要发生一次IO，那么总共需要百万次的IO，显然成本非常非常高。")])]),_._v(" "),l("p",[_._v("2.7. 联合索引的查找过程")]),_._v(" "),l("ul",[l("li",[_._v("当b+树的数据项是复合的数据结构，比如(name,age,sex)的时候，b+数是按照从左到右的顺序来建立搜索树的，比如当(张三,20,F)这样的数据来检索的时候，b+树会优先比较name来确定下一步的所搜方向，如果name相同再依次比较age和sex，最后得到检索的数据；但当(20,F)这样的没有name的数据来的时候，b+树就不知道下一步该查哪个节点，因为建立搜索树的时候name就是第一个比较因子，必须要先根据name来搜索才能知道下一步去哪里查询。比如当(张三,F)这样的数据来检索时，b+树可以用name来指定搜索方向，但下一个字段age的缺失，所以只能把名字等于张三的数据都找到，然后再匹配性别是F的数据了， 这个是非常重要的性质，即索引的最左匹配特性。")]),_._v(" "),l("li",[_._v("总结起来就是根据联合索引的第一列先排序；在第一列相等情况下，再根据第二列排序，其他依次类推。")])]),_._v(" "),l("p",[_._v("2.8. InnoDB索引实现")]),_._v(" "),l("ul",[l("li",[_._v("逻辑存储结构从大到小依次可以分为：表空间、段、区、页、行。表空间作为存储结构的最高层，所有数据都存放在表空间中，默认情况下用一个共享表空间 ibdata1 ，如果开启了 innodb_file_per_table 则每张表的数据将存储在单独的表空间中，也就是每张表都会有一个文件，表空间由各个段构成，InnoDB存储引擎由索引组织的，而索引中的叶子节点用来记录数据，存储在数据段，而非叶子节点用来构建索引，存储在索引段，而回滚段我们在后面分析锁的时候在聊。区是由连续的页组成，任何情况下一个区都是1MB，一个区中可以有多个页，每个页默认为16KB，所以默认情况下一个区中可以包含64个连续的页，页的大小是可以通过innodb_page_size设置，页中存储的是具体的行记录。")]),_._v(" "),l("li",[_._v("数据是以行为单位存储在聚簇索引里的，根据主键查询可以直接利用聚簇索引定位到所在记录，根据普通索引查询需要先在普通索引上找到对应的主键的值，然后根据主键值去聚簇索引上查找记录，俗称回表。")]),_._v(" "),l("li",[_._v("普通索引上存储的值是主键的值，如果主键是一个很长的字符串并且建了很多普通索引，将造成普通索引占有很大的物理空间，这也是为什么建议使用自增ID来替代订单号作为主键，另一个原因是自增ID在插入的时候可以保证相邻的两条记录可能在同一个数据块，而订单号的连续性在设计上可能没有自增ID好，导致连续插入可能在多个数据块，增加了磁盘读写次数。")])]),_._v(" "),l("p",[_._v("2.9 Mysql对索引的高级优化")]),_._v(" "),l("ul",[l("li",[_._v("索引下推：explain 结果中的 extra 字段值包含 using index condition，则说明使用了索引下推。索引下推功能是从 5.6 版本开始支持的。在 5.6 版本之前，i_first_name 索引是没有使用上的，需要每次去主键索引表取完整的记录值进行比较。从 5.6 版本开始，由于索引 i_first_name 的存在，可以直接取索引的 first_name 值进行过滤，这样不符合\"first_name like 'Hi%'\"条件的记录就不再需要回表操作。")])]),_._v(" "),l("div",{staticClass:"language- line-numbers-mode"},[l("pre",{pre:!0,attrs:{class:"language-text"}},[l("code",[_._v("SELECT * from user where  name like '陈%' and age=20\n")])]),_._v(" "),l("div",{staticClass:"line-numbers-wrapper"},[l("span",{staticClass:"line-number"},[_._v("1")]),l("br")])]),l("p",[_._v("Mysql5.6之前的版本：会忽略age这个字段，直接通过name进行查询，在(name,age)这课树上查找到了两个结果，id分别为2,1，然后拿着取到的id值一次次的回表查询，因此这个过程需要回表两次。Mysql5.6及之后版本：InnoDB并没有忽略age这个字段，而是在索引内部就判断了age是否等于20，对于不等于20的记录直接跳过，因此在(name,age)这棵索引树中只匹配到了一个记录，此时拿着这个id去主键索引树中回表查询全部数据，这个过程只需要回表一次。")]),_._v(" "),l("ul",[l("li",[_._v("MRR优化：使用MRR在数据没有预热的情况下，可以很大程度的提升范围查询的性能，我们都知道mysql的索引和数据是组合在一起的就是聚族索引，辅助索引的叶子节点就是主键ID，mysql一般都是先从辅助索引中查询主键ID，在回表查询具体的行数据，如果不适用MRR优化的话，需要一个个主键无序的查询具体的数据，会导致数据的page页重复请求，会有在同一个page中的数据，因为没有连续请求可能会导致对同一个page发送多次系统IO把数据读到内存中，内存会有LRU算法淘汰page页。开启MRR优化后，会先对辅助索引查询的主键ID进行排序，就可以减少磁盘请求，因为page页已经在内存中，这种情况在mysql没有预热的情况比较明显。")])]),_._v(" "),l("p",[_._v("2.10.1. 索引平常知识：索引失效")]),_._v(" "),l("ul",[l("li",[_._v("sql层面：not in, not exist，会导致索引失效；like '%_' 百分号在前面，会导致索引失效；对索引列进行运算操作，会导致索引失效；隐式转换会导致索引失效（重点）；表字段定义为varchar类型，但在查询时把该字段作为number类型以where条件传给oracle。对索引使用内部函数回导致索引失效。where语句中索引列使用了负向查询，可能会导致索引失效。负向查询包括：NOT、!=、<>、!、NOT IN、NOT LIKE等。负向查询并不绝对会索引失效，这要看MySQL优化器的判断，全表扫描或者走索引哪个成本低了；索引字段可以为null，使用is null或is not null时，可能会导致索引失效")]),_._v(" "),l("li",[_._v("表层面：对小表进行查询")]),_._v(" "),l("li",[_._v("组合（复合）索引：使用复合索引的时候，按照最左优先原则")])]),_._v(" "),l("p",[_._v("2.10.2. 索引平常知识：哪些列可以作为查询索引哪些不可以")]),_._v(" "),l("ul",[l("li",[_._v("可以：经常作为查询条件的列；经常作为排序条件的列；经常被查询的列；")]),_._v(" "),l("li",[_._v("不可以：数据频繁被修改的列，数据被修改，索引需要做相应的修改，消耗资源；区分度不是很高的列，如性别，列值重复性太大，索引效果不是很明显；不是经常被作为查询条件、排序条件、连接条件的列。")])]),_._v(" "),l("p",[_._v("2.10.3. 索引平常知识：如何删除百万级别或以上的数据？")]),_._v(" "),l("ul",[l("li",[_._v("可以考虑先删掉表的索引，等删除数据后再重建索引。当我们在进行数据修改时，需要同时修改索引，这些额外的索引维护成本较低数据修改的效率；同时，大量的数据删除会导致索引数据页产生大量的碎片空间，此时删除数据后重建索引可以使索引树更 “紧凑”，提高磁盘空间利用率。")])]),_._v(" "),l("p",[_._v("2.10.4. 索引平常知识：is null 走索引吗")]),_._v(" "),l("ul",[l("li",[_._v("数据量小的时候：当某一列有为null值的数据时，该列的索引依然生效，1.EXPLAIN select * from j_copy where a is null;2.EXPLAIN select * from j_copy where a is not null;使用is null确实是走了索引，没有问题。")]),_._v(" "),l("li",[_._v("数据量大的时候：索引不走null的")])]),_._v(" "),l("p",[_._v("2.10.5. 索引平常知识：索引相关建议")]),_._v(" "),l("ul",[l("li",[_._v("不在更新十分频繁、离散度不高的列上建立索引，尽􏰂选择离散度比较大的字段，查询频率比更新频率高的字段")]),_._v(" "),l("li",[_._v("联合索引使用遵循最左前缀匹配原则，一直向右匹配直到遇到范围查询")]),_._v(" "),l("li",[_._v("创建联合索引区分度高的字段前置，范围查询尽􏰂后置")]),_._v(" "),l("li",[_._v("不要让索引列的默认值为 NULL，可以设置default值或者空")]),_._v(" "),l("li",[_._v("能使用唯一索引就要使用唯一索引提高查询效率")]),_._v(" "),l("li",[_._v("update / delete 操作的 where 子句必须命中索引，否则相当于锁表")]),_._v(" "),l("li",[_._v("索引不是越多越好，按实际需要进行创建，单表中索引数􏰂不超过5个(建议3个左右)")]),_._v(" "),l("li",[_._v("单个索引中的字段数不超过3个")]),_._v(" "),l("li",[_._v("单字母区分度:26 4字母区分度:26^4 = 456,976 6字母区分度:26^6 = 308,915,776")]),_._v(" "),l("li",[_._v("字符串列最好创建前缀索引，而非整列索引pinyin varchar(100) DEFAULT NULL COMMENT '', KEY idx_pinyin (pinyin(8)),整个字符串，占用空间，增加树高度")])]),_._v(" "),l("p",[_._v("2.10.6. 索引平常知识：OrderBy一定会使用索引吗？")]),_._v(" "),l("ul",[l("li",[_._v("MySQL支持二种方式的排序，FileSort和Index，后者效率高，它指MySQL扫描索引本身完成排序。FileSort方式效率较低。ORDER BY满足以下情况，会使用Index方式排序:")]),_._v(" "),l("li",[_._v("ORDER BY 语句使用索引最左前列。")]),_._v(" "),l("li",[_._v("使用Where子句与Order BY子句条件列组合满足索引最左前列。")]),_._v(" "),l("li",[_._v("强制使用索引也可以FORCE INDEX（key）")])]),_._v(" "),l("p",[_._v("2.10.7. 索引平常知识：count(0) count(1) count(索引字段） count（非索引字段）的查找效率")]),_._v(" "),l("ul",[l("li",[_._v("count（0）和count（1）相同，以count（1）举例，这种情况是取出行（不取行内数据），然后把1放入这一行，server层判断是不可能为空的，就对行数进行累加，同时也解释了为什么能取出来所有字段都为null的行")]),_._v(" "),l("li",[_._v("对于 count(主键 id) 来说，InnoDB 引擎会遍历整张表，把每一行的 id 值都取出来，返回给 server 层。server 层拿到 id 后，判断是不可能为空的，就按行累加。")]),_._v(" "),l("li",[_._v("对于 count(字段) 来说：如果这个“字段”是定义为 not null 的话，一行行地从记录里面读出这个字段，判断不能为 null，按行累加；如果这个“字段”定义允许为 null，那么执行的时候，判断到有可能是 null，还要把值取出来再判断一下，不是 null 才累加。")]),_._v(" "),l("li",[_._v("所以在统计查询的时候按照效率排序的话，count(字段)<count(主键 id)<count(1)≈count()，所以我建议你，尽量使用 count()。")])]),_._v(" "),l("p",[_._v("2.10.8. 索引平常知识：索引查询和非索引查询")]),_._v(" "),l("ul",[l("li",[_._v("如果没有索引：排序有好多种算法来实现，在 MySQL 中经常会带上一个 limit ,表示从排序后的结果集中取前 100 条，或者取第 n 条到第 m 条，要实现排序，我们需要先根据查询条件获取结果集，然后在内存中对这个结果集进行排序，如果结果集数量特别大，还需要将结果集写入到多个文件里，然后单独对每个文件里的数据进行排序，然后在文件之间进行归并，排序完成后在进行 limit 操作。没错，这个就是 MySQL 实现排序的方式，前提是排序的字段没有索引。")]),_._v(" "),l("li",[_._v("如果有索引：这样查询过程如下：根据 city,name 联合索引定位到 city 等于武汉的第一条记录，获取主键索引ID；根据 ID 去主键索引上找到对应记录，取出 city,name,age 字段作为结果集返回；继续重复以上步骤直到 city 不等于武汉，或者条数大于 1000。总结一下，我们在有排序操作的时候，最好能够让排序字段上建有索引，另外由于查询第一百万条开始的一百条记录，需要过滤掉前面一百万条记录，即使用到索引也很慢，所以可以根据ID来进行区分，分页遍历的时候每次缓存上一次查询结果最后一条记录的 id ， 下一次查询加上 id > xxxx limit 0,1000 这样可以避免前期扫描到的结果被过滤掉的情况。")])]),_._v(" "),l("p",[_._v("2.10.9. 索引平常知识：官方为什么建议采用自增id 作为主键？")]),_._v(" "),l("ul",[l("li",[_._v("自增id是连续的，插入过程也是顺序的，总是插入在最后，减少了页分裂，有效减少数据的移动。")]),_._v(" "),l("li",[_._v("所以尽量不要使用字符串（如：UUID）作为主键。")])]),_._v(" "),l("p",[_._v("2.10.10. 索引平常知识：为什么非主键索引结构叶子节点存储的是主键值？")]),_._v(" "),l("ul",[l("li",[_._v("为了一致性和节省存储空间。已经维护了一套主键索引+数据的B+Tree结构，如果再有其他的非主键索引的话，索引的叶子节点存储的是主键，这是为了节省空间，因为继续存数据的话，那就会导致一份数据存了多份，空间占用就会翻倍。另一方面也是一致性的考虑，都通过主键索引来找到最终的数据，避免维护多份数据导致不一致的情况。")])]),_._v(" "),l("p",[_._v("3.0. 锁分类")]),_._v(" "),l("ul",[l("li",[_._v("共享锁(Shared Locks)：简称S锁，在事务要读取一条记录时，需要先获取该记录的S锁。S锁可以在同一时刻被多个事务同时持有。我们可以用select ...... lock in share mode;的方式手工加上一把S锁。")]),_._v(" "),l("li",[_._v("排他锁(Exclusive Locks)：简称X锁，在事务要改动一条记录时，需要先获取该记录的X锁。X锁在同一时刻最多只能被一个事务持有。X锁的加锁方式有两种，第一种是自动加锁，在对数据进行增删改的时候，都会默认加上一个X锁。还有一种是手工加锁，我们用一个FOR UPDATE给一行数据加上一个X锁。")]),_._v(" "),l("li",[_._v("意向锁(Intention Locks)：除了共享锁(Shared Locks)和排他锁(Exclusive Locks)，Mysql还有意向锁(Intention Locks)。意向锁是由数据库自己维护的，一般来说，当我们给一行数据加上共享锁之前，数据库会自动在这张表上面加一个意向共享锁(IS锁)；当我们给一行数据加上排他锁之前，数据库会自动在这张表上面加一个意向排他锁(IX锁)。**意向锁可以认为是S锁和X锁在数据表上的标识，通过意向锁可以快速判断表中是否有记录被上锁，从而避免通过遍历的方式来查看表中有没有记录被上锁，提升加锁效率。**例如，我们要加表级别的X锁，这时候数据表里面如果存在行级别的X锁或者S锁的，加锁就会失败，此时直接根据意向锁就能知道这张表是否有行级别的X锁或者S锁。InnoDB的意向锁主要用户多粒度的锁并存的情况。比如事务A要在一个表上加S锁，如果表中的一行已被事务B加了X锁，那么该锁的申请也应被阻塞。如果表中的数据很多，逐行检查锁标志的开销将很大，系统的性能将会受到影响。为了解决这个问题，可以在表级上引入新的锁类型来表示其所属行的加锁情况，这就引出了“意向锁”的概念。举个例子，如果表中记录1亿，事务A把其中有几条记录上了行锁了，这时事务B需要给这个表加表级锁，如果没有意向锁的话，那就要去表中查找这一亿条记录是否上锁了。如果存在意向锁，那么假如事务Ａ在更新一条记录之前，先加意向锁，再加Ｘ锁，事务B先检查该表上是否存在意向锁，存在的意向锁是否与自己准备加的锁冲突，如果有冲突，则等待直到事务Ａ释放，而无须逐条记录去检测。事务Ｂ更新表时，其实无须知道到底哪一行被锁了，它只要知道反正有一行被锁了就行了。")])]),_._v(" "),l("p",[_._v("3.1. 表锁原理")]),_._v(" "),l("ul",[l("li",[_._v("表锁使用的是一次性锁技术，也就是说，在会话开始的地方使用 lock 命令将后续需要用到的表都加上锁，在表释放前，只能访问这些加锁的表，不能访问其他表，直到最后通过 unlock tables 释放所有表锁。")]),_._v(" "),l("li",[_._v("除了使用 unlock tables 显示释放锁之外，会话持有其他表锁时执行lock table 语句会释放会话之前持有的锁；")]),_._v(" "),l("li",[_._v("会话持有其他表锁时执行 start transaction 或者 begin 开启事务时，也会释放之前持有的锁。")])]),_._v(" "),l("p",[_._v("3.2. 行锁原理")]),_._v(" "),l("ul",[l("li",[_._v("行锁是基于索引的。InnoDB是聚簇索引，也就是B+树的叶节点既存储了主键索引也存储了数据行。而InnoDB的二级索引的叶节点存储的则是主键值，所以通过二级索引查询数据时，还需要拿对应的主键去聚簇索引中再次进行查询。")]),_._v(" "),l("li",[l("code",[_._v("update user set age = 10 where id = 49 ;")]),_._v("SQL使用主键索引来查询，则只需要在id=49这个主键索引上加上写锁")]),_._v(" "),l("li",[l("code",[_._v("update user set age = 10 where id > 49 ;")]),_._v("MySQL Server会根据WHERE条件读取第一条满足条件的记录，然后InnoDB引擎会将第一条记录返回并加锁，接着MySQLServer发起更新改行记录的UPDATE请求，更新这条记录。一条记录操作完成，再读取下一条记录，直至没有匹配的记录为止。")])]),_._v(" "),l("p",[_._v("3.3. 锁算法")]),_._v(" "),l("ul",[l("li",[_._v("记录锁(Record Locks)：所谓记录，就是指聚簇索引中真实存放的数据，比如上面的1、4、7、10都是记录。当我们使用唯一性的索引(包括唯一索引和聚簇索引)进行等值查询且精准匹配到一条记录时，此时就会直接将这条记录锁定。例如select * from t where id =4 for update;就会将id=4的记录锁定。")]),_._v(" "),l("li",[_._v("间隙锁(Gap Locks)： 间隙指的是两个记录之间逻辑上尚未填入数据的部分，比如上述的(1,4)、(4,7)等。当我们使用用等值查询或者范围查询，并且没有命中任何一个record，此时就会将对应的间隙区间锁定。例如select * from t where id =3 for update;或者select * from t where id > 1 and id < 4 for update;就会将(1,4)区间锁定。")]),_._v(" "),l("li",[_._v("临键锁(Next-Key Locks)： 临键指的是间隙加上它右边的记录组成的左开右闭区间。比如上述的(1,4]、(4,7]等。临键锁就是记录锁(Record Locks)和间隙锁(Gap Locks)的结合，即除了锁住记录本身，还要再锁住索引之间的间隙。当我们使用范围查询，并且命中了部分record记录，此时锁住的就是临键区间。注意，临键锁锁住的区间会包含最后一个record的右边的临键区间。例如select * from t where id > 5 and id <= 7 for update;会锁住(4,7]、(7,+∞)。mysql默认行锁类型就是临键锁(Next-Key Locks)。当使用唯一性索引，等值查询匹配到一条记录的时候，临键锁(Next-Key Locks)会退化成记录锁；没有匹配到任何记录的时候，退化成间隙锁。")]),_._v(" "),l("li",[_._v("插入意向锁：Insert Intention Locks，插入意向锁，是一种特殊的间隙锁，只有在执行INSERT操作时才会加锁，插入意向锁之间不冲突，可以向一个间隙中同时插入多行数据，但插入意向锁与间隙锁是冲突的，当有间隙锁存在时，插入语句将被阻塞，正是这个特性解决了幻读的问题。假设有一个记录索引包含键值4和7，不同的事务分别插入5和6，每个事务都会产生一个加在4-7之间的插入意向锁，获取在插入行上的排它锁，但是不会被互相锁住，因为数据行并不冲突。")]),_._v(" "),l("li",[_._v("间隙锁(Gap Locks)和临键锁(Next-Key Locks)都是用来解决幻读问题的，**在已提交读（READ COMMITTED）隔离级别下，间隙锁(Gap Locks)和临键锁(Next-Key Locks)都会失效！")])]),_._v(" "),l("p",[_._v("3.4. 如何尽可能避免死锁：")]),_._v(" "),l("ul",[l("li",[_._v("合理的设计索引，区分度高的列放到组合索引前面，使业务SQL尽可能通过索引定位更少的行，减少锁竞争。")]),_._v(" "),l("li",[_._v("尽量按主键/索引去查找记录，范围查找增加了锁冲突的可能性，也不要利用数据库做一些额外额度计算工作。比如有的程序会用到select … where … order by rand();这样的语句，类似这样的语句用不到索引，因此将导致整个表的数据都被锁住。")]),_._v(" "),l("li",[_._v("大事务拆小。大事务更倾向于死锁，如果业务允许，将大事务拆小。")]),_._v(" "),l("li",[_._v("以固定的顺序访问表和行。比如两个更新数据的事务，事务A更新数据的顺序为1，2;事务B更新数据的顺序为2，1。这样更可能会造成死锁。")]),_._v(" "),l("li",[_._v("降低隔离级别。如果业务允许，将隔离级别调低也是较好的选择，比如将隔离级别从RR调整为RC，可以避免掉很多因为gap锁造成的死锁。")]),_._v(" "),l("li",[_._v("以固定的顺序访问表和行。交叉访问更容易造成事务等待回路。")]),_._v(" "),l("li",[_._v("降低隔离级别。如果业务允许(上面4.3也分析了，某些业务并不能允许)，将隔离级别调低也是较好的选择，比如将隔离级别从RR调整为RC，可以避免掉很多因为gap锁造成的死锁。")]),_._v(" "),l("li",[_._v("为表添加合理的索引。防止没有索引出现表锁，出现的死锁的概率会突增。")])]),_._v(" "),l("p",[_._v("4.0. MVVC出现的背景")]),_._v(" "),l("ul",[l("li",[_._v("在 MySQL中，默认的隔离级别是可重复读，可以解决脏读和不可重复读的问题，但不能解决幻读问题。如果我们想要解决幻读问题，就需要采用串行化的方式，也就是将隔离级别提升到最高，但这样一来就会大幅降低数据库的事务并发能力。而MVCC就是通过乐观锁的方式来解决不可重复读和幻读问题，它可以在大多数情况下替代行级锁，降低系统的开销。MySQL 并发事务会引起更新丢失问题，解决办法是锁，主要分两类：")]),_._v(" "),l("li",[_._v("乐观锁：其实现如同它的名字一样，是假设比较好的情况。每次取数据的时候都认为他人不会对其修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号机制和CAS算法实现。")]),_._v(" "),l("li",[_._v("悲观锁：悲观锁也如同它的名字一样，总是假设比较坏的情况，每次取数据的时候都认为他人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁（共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程）。")])]),_._v(" "),l("p",[_._v("4.1. MVCC简介")]),_._v(" "),l("ul",[l("li",[_._v("MVCC是啥 MVCC指的是一种提高并发的技术。最早的数据库系统，只有读读之间可以并发，读写，写读，写写都要阻塞。引入多版本之后，只有写写之间相互阻塞，其他三种操作都可以并行，这样大幅度提高了InnoDB的并发度。")]),_._v(" "),l("li",[_._v("在内部实现中，InnoDB是在undo log中实现的，通过undo log可以找回数据的历史版本。找回的数据历史版本可以提供给用户读(按照隔离级别的定义，有些读请求只能看到比较老的数据版本)，也可以在回滚的时候覆盖数据页上的数据。")]),_._v(" "),l("li",[_._v("在InnoDB内部中，会记录一个全局的活跃读写事务数组，其主要用来判断事务的可见性。")]),_._v(" "),l("li",[_._v("多版本并发控制技术的英文全称是 Multiversion Concurrency Control，简称 MVCC，是通过保存数据在某个时间点的快照来实现并发控制的。也就是说，不管事务执行多长时间，事务内部看到的数据是不受其它事务影响的，根据事务开始的时间不同，每个事务对同一张表，同一时刻看到的数据可能是不一样的。 简单来说，多版本并发控制的思想就是保存数据的历史版本，通过对数据行的多个版本管理来实现数据库的并发控制。这样我们就可以通过比较版本号决定数据是否显示出来，读取数据的时候不需要加锁也可以保证事务的隔离效果。 - 可以认为多版本并发控制（MVCC）是行级锁的一个变种，但是它在很多情况下避免了加锁操作，因此开销更低。虽然实现机制有所不同，但大都实现了非阻塞的读操作，写操作也只锁定必要的行。")])]),_._v(" "),l("p",[_._v("4.2. MVCC解决了什么问题")]),_._v(" "),l("ul",[l("li",[l("p",[_._v("思路：一个支持MVCC的数据库，在更新某些数据时，并非使用新数据覆盖旧数据，而是标记旧数据是过时的，同时在其他地方新增一个数据版本。因此，同一份数据有多个版本存储，但只有一个是最新的。 MVCC提供了 时间一致性的 处理思路，在MVCC下读事务时，通常使用一个时间戳或者事务ID来确定访问哪个状态的数据库及哪些版本的数据。读事务跟写事务彼此是隔离开来的，彼此之间不会影响。")]),_._v(" "),l("ul",[l("li",[_._v("普通锁，只能串行执行；")]),_._v(" "),l("li",[_._v("读写锁，可以实现读读并发；")]),_._v(" "),l("li",[_._v("数据多版本并发控制，可以实现读写并发。")])])]),_._v(" "),l("li",[l("p",[_._v("解决：读写之间阻塞的问题，通过 MVCC 可以让读写互相不阻塞，即读不阻塞写，写不阻塞读，这样就可以提升事务并发处理能力。")])]),_._v(" "),l("li",[l("p",[_._v("解决：降低了死锁的概率。这是因为 MVCC 采用了乐观锁的方式，读取数据时并不需要加锁，对于写操作，也只锁定必要的行。")])]),_._v(" "),l("li",[l("p",[_._v("解决：解决一致性读的问题。一致性读也被称为快照读，当我们查询数据库在某个时间点的快照时，只能看到这个时间点之前事务提交更新的结果，而不能看到这个时间点之后事务提交的更新结果。")])])]),_._v(" "),l("p",[_._v("4.3. InnoDB 是如何存储记录的多个版本的")]),_._v(" "),l("ul",[l("li",[_._v("事务版本号：是每开启一个事务，我们都会从数据库中获得一个事务ID（也就是事务版本号），这个事务ID是自增长的，通过ID大小，我们就可以判断事务的时间顺序。")]),_._v(" "),l("li",[_._v("行记录的隐藏列：InnoDB 的叶子段存储了数据页，数据页中保存了行记录，而在行记录中有一些重要的隐藏字段：\n"),l("ul",[l("li",[_._v("行ID：DB_ROW_ID：6-byte，隐藏的行 ID，用来生成默认聚簇索引。如果我们创建数据表的时候没有指定聚簇索引，这时 InnoDB 就会用这个隐藏 ID 来创建聚集索引。采用聚簇索引的方式可以提升数据的查找效率。")]),_._v(" "),l("li",[_._v("事务ID：DB_TRX_ID：6-byte，操作这个数据的事务ID，也就是最后一个对该数据进行插入或更新的事务 ID。")]),_._v(" "),l("li",[_._v("回滚指针：DB_ROLL_PTR：7-byte，回滚指针，也就是指向这个记录的 Undo Log 信息。")])])]),_._v(" "),l("li",[_._v("Undo Log：InnoDB 将行记录快照保存在了 Undo Log 里，我们可以在回滚段中找到它们，回滚指针将数据行的所有快照记录都通过链表的结构串联了起来，每个快照的记录都保存了当时的 db_trx_id，也是那个时间点操作这个数据的事务 ID。这样如果我们想要找历史快照，就可以通过遍历回滚指针的方式进行查找。")])]),_._v(" "),l("p",[_._v("4.4. 在可重复读（REPEATABLE READ）隔离级别下，InnoDB的MVCC是如何工作的")]),_._v(" "),l("ul",[l("li",[_._v("查询（SELECT）:InnoDB 会根据以下两个条件检查每行记录(需要全部符合)：InnoDB只查找版本早于当前事务版本的数据行（也就是，行的系统版本号小于或等于事务的系统版本号），这样可以确保事务读取的行，要么是在事务开始前已经存在的，要么是事务自身插入或者修改过的；行的删除版本要么未定义，要么大于当前事务版本号。这可以确保事务读取到的行，在事务开始之前未被删除。")]),_._v(" "),l("li",[_._v("插入（INSERT）：InnoDB为新插入的每一行保存当前系统版本号作为行版本号。")]),_._v(" "),l("li",[_._v("删除（DELETE）：InnoDB为删除的每一行保存当前系统版本号作为行删除标识。删除在内部被视为更新，行中的一个特殊位会被设置为已删除。")]),_._v(" "),l("li",[_._v("更新（UPDATE）：InnoDB为插入一行新记录，保存当前系统版本号作为行版本号，同时保存当前系统版本号到原来的行作为行删除标识。")])]),_._v(" "),l("p",[_._v("4.5. read view（一致性视图）")]),_._v(" "),l("ul",[l("li",[_._v("快照snapshot 在innodb中，创建一个新事务的时候，innodb会将当前系统中的活跃事务列表创建一个副本（read view），副本中保存的是系统当前不应该被本事务看到的其他事务id列表。")]),_._v(" "),l("li",[_._v("当用户在这个事务中要读取该行记录的时候，innodb会将该行当前的版本号与该read view进行比较。")]),_._v(" "),l("li",[_._v("当执行查询sql时，会生成一致性视图 read-view，它由执行查询时所有未提交事务id数组（）和已创建最大事务id（max_id）组成。查询的数据结果需要跟read-view做对比从而得到快照结果")])]),_._v(" "),l("p",[_._v("4.6. read view的生成时机")]),_._v(" "),l("ul",[l("li",[_._v("在READ COMMITTED 中每次查询都会生成一个实时的 ReadView，做到保证每次提交后的数据是处于当前的可见状态。")]),_._v(" "),l("li",[_._v("在REPEATABLE READ 中，在当前事务第一次查询时生成当前的ReadView，并且当前的ReadView会一直沿用到当前事务提交，以此来保证可重复读（REPEATABLE READ）。")])]),_._v(" "),l("p",[_._v("4.7. MVCC+ Next-key-Lock 防止幻读")]),_._v(" "),l("ul",[l("li",[_._v("执行普通 select，此时会以 MVCC 快照读的方式读取数据：在快照读的情况下，RR 隔离级别只会在事务开启后的第一次查询生成 Read View ，并使用至事务提交。所以在生成 Read View 之后其它事务所做的更新、插入记录版本对当前事务并不可见，实现了可重复读和防止快照读下的 “幻读”")])]),_._v(" "),l("p",[_._v("4.8. MVCC总结")]),_._v(" "),l("ul",[l("li",[_._v("MVCC 的核心就是 Undo Log+ Read View。“MV”就是通过 Undo Log 来保存数据的历史版本，实现多版本的管理；“CC”是通过 Read View 来实现管理，通过 Read View 原则来决定数据是否显示。")]),_._v(" "),l("li",[_._v("MVCC（Multi-Version Concurrency Control ，多版本并发控制）指的就是在使用READ COMMITTD、REPEATABLE READ这两种隔离级别的事务在执行普通的SEELCT操作时访问记录的版本链的过程，这样子可以使不同事务的读-写、写-读操作并发执行，从而提升系统性能。")]),_._v(" "),l("li",[_._v("READ COMMITTD、REPEATABLE READ这两个隔离级别的一个很大不同就是生成ReadView的时机不同，READ COMMITTD在每一次进行普通SELECT操作前都会生成一个ReadView，而REPEATABLE READ只在第一次进行普通SELECT操作前生成一个ReadView，之后的查询操作都重复这个ReadView就好了。")])]),_._v(" "),l("p",[_._v("5.0. 事务的隔离级别和问题")]),_._v(" "),l("ul",[l("li",[_._v("读未提交，脏读：一个事务读取到了另外一个事务没有提交的数据；")]),_._v(" "),l("li",[_._v("读已提交，不可重复读：在同一事务中，两次读取同一数据，得到内容不同；")]),_._v(" "),l("li",[_._v("可重复读，幻读：同一事务中，用同样的操作读取两次，得到的记录数不相同。")]),_._v(" "),l("li",[_._v("串行读，慢。")])]),_._v(" "),l("p",[_._v("5.1. 幻读和不可重复读的区别：")]),_._v(" "),l("ul",[l("li",[_._v("不可重复读的重点是修改：在同一事务中，同样的条件，第一次读的数据和第二次读的数据不一样。（因为中间有其他事务提交了修改）")]),_._v(" "),l("li",[_._v("幻读的重点在于新增或者删除：在同一事务中，同样的条件,，第一次和第二次读出来的记录数不一样。（因为中间有其他事务提交了插入/删除）")])]),_._v(" "),l("p",[_._v("5.2. 并发事务带来的问题和解决方案")]),_._v(" "),l("ul",[l("li",[_._v("问题：“脏读” 、 “不可重复读”和“幻读”")]),_._v(" "),l("li",[_._v("方案：一种是加锁：在读取数据前，对其加锁，阻止其他事务对数据进行修改。")]),_._v(" "),l("li",[_._v("方案：一种是数据多版本并发控制（MultiVersion Concurrency Control，简称 MVCC 或 MCC），也称为多版本数据库：不用加任何锁， 通过一定机制生成一个数据请求时间点的一致性数据快照 （Snapshot)， 并用这个快照来提供一定级别 （语句级或事务级） 的一致性读取。从用户的角度来看，好象是数据库可以提供同一数据的多个版本。")])]),_._v(" "),l("p",[_._v("5.3. 单纯加锁是怎么实现read committed的？")]),_._v(" "),l("ul",[l("li",[_._v("从此隔离级别效果入手：事务只能读其他事务已提交的记录。数据库事务隔离级别的实现，InnoDB支持行级锁，写时加的是行级排他锁（X锁），那么当其他事务访问另一个事务正在更新（除选择操作外其他操作本质上都是写操作）的同一条记录时，事务的读操作会被阻塞。所以只能等到记录（其实是索引上的锁）上的排他锁释放后才能进行访问，也就是事务提交的时候。")]),_._v(" "),l("li",[_._v("这样确实能实现read commited隔离级别效果。数据库这样做确实可以实现事务只能读其他事务已提交的记录的效果，但是这是很低效的一种做法，为什么呢？因为对于大部分应用来说，读操作是多于写操作的，当写操作加锁时，那么读操作全部被阻塞，这样会导致应用的相应能力受数据库的牵制。")])]),_._v(" "),l("p",[_._v("5.4. 事务原理（基于锁的方式，正确的是基于MVCC的）")]),_._v(" "),l("ul",[l("li",[_._v("相对于传统隔离级别基于锁的实现方式，MySQL是通过MVCC（多版本并发控制）来实现读-写并发控制，又是通过两阶段锁来实现写-写并发控制的。MVCC是一种无锁方案，用以解决事务读-写并发的问题，能够极大提升读-写并发操作的性能。")]),_._v(" "),l("li",[_._v("READ_UNCOMMITED 的原理:事务对当前被读取的数据不加锁；事务在更新某数据的瞬间（就是发生更新的瞬间），必须先对其加行级共享锁，直到事务结束才释放。 表现：事务1读取某行记录时，事务2也能对这行记录进行读取、更新；当事务2对该记录进行更新时，事务1再次读取该记录，能读到事务2对该记录的修改版本，即使该修改尚未被提交。事务1更新某行记录时，事务2不能对这行记录做更新，直到事务1结束。")]),_._v(" "),l("li",[_._v("READ_COMMITED 的原理:事务对当前被读取的数据加行级共享锁（当读到时才加锁），一旦读完该行，立即释放该行级共享锁；事务在更新某数据的瞬间（就是发生更新的瞬间），必须先对其加行级排他锁，直到事务结束才释放。 表现：事务1读取某行记录时，事务2也能对这行记录进行读取、更新；当事务2对该记录进行更新时，事务1再次读取该记录，读到的只能是事务2对其更新前的版本，要不就是事务2提交后的版本；事务1更新某行记录时，事务2不能对这行记录做更新，直到事务1结束。")]),_._v(" "),l("li",[_._v("REPEATABLE READ的原理:事务在读取某数据的瞬间（就是开始读取的瞬间），必须先对其加行级共享锁，直到事务结束才释放；事务在更新某数据的瞬间（就是发生更新的瞬间），必须先对其加行级排他锁，直到事务结束才释放。 表现：事务1读取某行记录时，事务2也能对这行记录进行读取、更新；当事务2对该记录进行更新时，事务1再次读取该记录，读到的仍然是第一次读取的那个版本；事务1更新某行记录时，事务2不能对这行记录做更新，直到事务1结束。")]),_._v(" "),l("li",[_._v("SERIALIZABLE 的原理:事务在读取数据时，必须先对其加表级共享锁，直到事务结束才释放；事务在更新数据时，必须先对其加表级排他锁 ，直到事务结束才释放。 表现：事务1正在读取A表中的记录时，则事务2也能读取A表，但不能对A表做更新、新增、删除，直到事务1结束；事务1正在更新A表中的记录时，则事务2不能读取A表的任意记录，更不可能对A表做更新、新增、删除，直到事务1结束。")])]),_._v(" "),l("p",[_._v("5.5. 分布式事务（分布式事务采用两段式提交（two-phase commit）的方式：）")]),_._v(" "),l("ul",[l("li",[_._v("第一阶段所有的事务节点开始准备，告诉事务管理器ready。")]),_._v(" "),l("li",[_._v("第二阶段事务管理器告诉每个节点是commit还是rollback。如果有一个节点失败，就需要全局的节点全部rollback，以此保障事务的原子性。")])]),_._v(" "),l("p",[_._v("6.0. 事务日志 redo log（重做日志）")]),_._v(" "),l("p",[_._v("6.0.0. 简单")]),_._v(" "),l("ul",[l("li",[_._v("作用：确保事务的持久性。防止在发生故障的时间点，尚有脏页未写入磁盘，在重启mysql服务的时候，根据redo log进行重做，从而达到事务的持久性这一特性。")]),_._v(" "),l("li",[_._v("内容：物理格式的日志，记录的是物理数据页面的修改的信息，其redo log是顺序写入redo log file的物理文件中去的。")]),_._v(" "),l("li",[_._v("什么时候产生：事务开始之后就产生redo log，redo log的落盘并不是随着事务的提交才写入的，而是在事务的执行过程中，便开始写入redo log文件中。")]),_._v(" "),l("li",[_._v("什么时候释放：当对应事务的脏页写入到磁盘之后，redo log的使命也就完成了，重做日志占用的空间就可以重用（被覆盖）。")])]),_._v(" "),l("p",[_._v("6.0.1. 其他")]),_._v(" "),l("ul",[l("li",[_._v("事务日志包括：重做日志redo和回滚日志undo")]),_._v(" "),l("li",[_._v("redo log（重做日志）是InnoDB存储引擎独有的，它让MySQL拥有了崩溃恢复能力。比如MySQL实例挂了或宕机了，重启时，InnoDB存储引擎会使用redo log恢复数据，保证数据的持久性与完整性。")]),_._v(" "),l("li",[_._v("redo log包括两部分：一是内存中的日志缓冲(redo log buffer)，该部分日志是易失性的；二是磁盘上的重做日志文件(redo log file)，该部分日志是持久的。")]),_._v(" "),l("li",[_._v("innodb通过force log at commit机制实现事务的持久性，即在事务提交的时候，必须先将该事务的所有事务日志写入到磁盘上的redo log file和undo log file中进行持久化。")]),_._v(" "),l("li",[_._v("为了确保每次日志都能写入到事务日志文件中，在每次将log buffer中的日志写入日志文件的过程中都会调用一次操作系统的fsync操作(即fsync()系统调用)。因为MariaDB/MySQL是工作在用户空间的，MariaDB/MySQL的log buffer处于用户空间的内存中。要写入到磁盘上的log file中(redo:ib_logfileN文件,undo:share tablespace或.ibd文件)，中间还要经过操作系统内核空间的os buffer，调用fsync()的作用就是将OS buffer中的日志刷到磁盘上的log file中。")]),_._v(" "),l("li",[_._v("在innoDB的存储引擎中，事务日志通过重做(redo)日志和innoDB存储引擎的日志缓冲(InnoDB Log Buffer)实现。事务开启时，事务中的操作，都会先写入存储引擎的日志缓冲中，在事务提交之前，这些缓冲的日志都需要提前刷新到磁盘上持久化，这就是DBA们口中常说的“日志先行”(Write-Ahead Logging)。当事务提交之后，在Buffer Pool中映射的数据文件才会慢慢刷新到磁盘。此时如果数据库崩溃或者宕机，那么当系统重启进行恢复时，就可以根据redo log中记录的日志，把数据库恢复到崩溃前的一个状态。未完成的事务，可以继续提交，也可以选择回滚，这基于恢复的策略而定。")])]),_._v(" "),l("p",[_._v("6.1. undo log（回滚日志）")]),_._v(" "),l("p",[_._v("6.1.0. 简单")]),_._v(" "),l("ul",[l("li",[_._v("作用：保存了事务发生之前的数据的一个版本，可以用于回滚，同时可以提供多版本并发控制下的读（MVCC），也即非锁定读，保障了事务的原子性，Undo Log也可以用来辅助完成事务的持久化。")]),_._v(" "),l("li",[_._v("内容：逻辑格式的日志，在执行undo的时候，仅仅是将数据从逻辑上恢复至事务之前的状态，而不是从物理页面上操作实现的，这一点是不同于redo log的。")]),_._v(" "),l("li",[_._v("什么时候产生：事务开始之前，将当前是的版本生成undo log，undo 也会产生 redo 来保证undo log的可靠性")]),_._v(" "),l("li",[_._v("什么时候释放：当事务提交之后，undo log并不能立马被删除，而是放入待清理的链表，由purge线程判断是否由其他事务在使用undo段中表的上一个事务之前的版本信息，决定是否可以清理undo log的日志空间。")])]),_._v(" "),l("p",[_._v("6.1.1. 其他")]),_._v(" "),l("ul",[l("li",[_._v("数据库事务开始之前，会将要修改的记录存放到 Undo 日志里，当事务回滚时或者数据库崩溃时，可以利用 Undo 日志，撤销未提交事务对数据库产生的影响。")]),_._v(" "),l("li",[_._v("作用：保障事务的原子性。事务中的所有更新语句，要么全被执行，要么全被回滚。通过将同一个trx_id 的undo log 就可以实现回滚同一事务的所有更新语句了。")]),_._v(" "),l("li",[_._v("作用：提供版本链，支持MVCC。undo log 链为实现MVCC 提供了底层的物质基础。为了实现MVCC ,还需要借助Read View 。")]),_._v(" "),l("li",[_._v("undo log记录的是逻辑日志，redo log记录的是物理日志。对记录做变更操作时不仅会产生redo记录，也会产生undo记录（insert,update,delete），undo log 日志用于存放数据被修改前的值。")]),_._v(" "),l("li",[_._v("undo log分为两种类型：insert undo log：插入产生的undo log。不需要维护历史版本链，因为没有历史数据，所以其产生的undo log可以在事务提交之后删除，不需要purge操作；update undo log：更新或删除产生的undo log。不会在提交后就立即删除，而是会放入undo log历史版本链，用于MVCC，最后由purge线程清理。")])]),_._v(" "),l("p",[_._v("6.2. 二进制日志 binlog（归档日志）")]),_._v(" "),l("ul",[l("li",[_._v("作用：　1，用于复制，在主从复制中，从库利用主库上的binlog进行重播，实现主从同步。2，用于数据库的基于时间点的还原。")]),_._v(" "),l("li",[_._v("内容：逻辑格式的日志，可以简单认为就是执行过的事务中的sql语句。但又不完全是sql语句这么简单，而是包括了执行的sql语句（增删改）反向的信息，也就意味着delete对应着delete本身和其反向的insert；update对应着update执行前后的版本的信息；insert对应着delete和insert本身的信息。")]),_._v(" "),l("li",[_._v("什么时候产生：事务提交的时候，一次性将事务中的sql语句（一个事物可能对应多个sql语句）按照一定的格式记录到binlog中。这里与redo log很明显的差异就是redo log并不一定是在事务提交的时候刷新到磁盘，redo log是在事务开始之后就开始逐步写入磁盘。")])]),_._v(" "),l("p",[_._v("7.0. mysql主从复制的过程 MySQL复制过程分成三步：")]),_._v(" "),l("ul",[l("li",[_._v("master将改变记录到二进制日志（binary log）。")]),_._v(" "),l("li",[_._v("slave将master的binary log events拷贝到它的中继日志（relay log）；")]),_._v(" "),l("li",[_._v("slave重做中继日志中的事件，将改变应用到自己的数据库中。")])]),_._v(" "),l("p",[_._v("7.1. MySQL 主从复制原理的是啥？")]),_._v(" "),l("ul",[l("li",[_._v("主库将变更写入 binlog 日志")]),_._v(" "),l("li",[_._v("从库连接到主库之后，从库有一个 IO 线程，将主库的 binlog 日志拷贝到自己本地，写入一个 relay 中继日志中。")]),_._v(" "),l("li",[_._v("接着从库中有一个 SQL 线程会从中继日志读取 binlog，然后执行 binlog 日志中的内容，也就是在自己本地再次执行一遍 SQL，这样就可以保证自己跟主库的数据是一样的。")])]),_._v(" "),l("p",[_._v("7.2. mysql 同步的三种方式")]),_._v(" "),l("ul",[l("li",[_._v("异步复制（Asynchronous replication）, 逻辑上：MySQL默认的复制即是异步的，主库在执行完客户端提交的事务后会立即将结果返给给客户端，并不关心从库是否已经接收并处理，这样就会有一个问题，主如果crash掉了，此时主上已经提交的事务可能并没有传到从库上，如果此时，强行将从提升为主，可能导致新主上的数据不完整。 技术上：主库将事务 Binlog 事件写入到 Binlog 文件中，此时主库只会通知一下 Dump 线程发送这些新的 Binlog，然后主库就会继续处理提交操作，而此时不会保证这些 Binlog 传到任何一个从库节点上。")]),_._v(" "),l("li",[_._v("全同步复制（Fully synchronous replication） 逻辑上：指当主库执行完一个事务，所有的从库都执行了该事务才返回给客户端。因为需要等待所有从库执行完该事务才能返回，所以全同步复制的性能必然会收到严重的影响。 技术上：当主库提交事务之后，所有的从库节点必须收到、APPLY并且提交这些事务，然后主库线程才能继续做后续操作。但缺点是，主库完成一个事务的时间会被拉长，性能降低。")]),_._v(" "),l("li",[_._v("半同步复制（Semisynchronous replication） 逻辑上：是介于全同步复制与全异步复制之间的一种，主库只需要等待至少一个从库节点收到并且 Flush Binlog 到 Relay Log 文件即可，主库不需要等待所有从库给主库反馈。同时，这里只是一个收到的反馈，而不是已经完全完成并且提交的反馈，如此，节省了很多时间。 技术上：介于异步复制和全同步复制之间，主库在执行完客户端提交的事务后不是立刻返回给客户端，而是等待至少一个从库接收到并写到relay log中才返回给客户端。相对于异步复制，半同步复制提高了数据的安全性，同时它也造成了一定程度的延迟，这个延迟最少是一个TCP/IP往返的时间。所以，半同步复制最好在低延时的网络中使用。")])]),_._v(" "),l("p",[_._v("8.0. 优化")]),_._v(" "),l("ul",[l("li",[_._v("Explain")]),_._v(" "),l("li",[_._v("优化")])])])}),[],!1,null,null,null);v.default=i.exports}}]);