{"code":"(window.webpackJsonp=window.webpackJsonp||[]).push([[236],{613:function(e,i,t){\"use strict\";t.r(i);var n=t(13),l=Object(n.a)({},(function(){var e=this,i=e.$createElement,t=e._self._c||i;return t(\"ContentSlotsDistributor\",{attrs:{\"slot-key\":e.$parent.slotKey}},[t(\"p\",[e._v(\"0.0. 分类总结\")]),e._v(\" \"),t(\"ul\",[t(\"li\",[e._v(\"多线程的一些概念（进程、线程、并行、并发啥的，谈谈你对高并发的认识）\")]),e._v(\" \"),t(\"li\",[e._v(\"同步机制（locks、synchronzied、atomic）\")]),e._v(\" \"),t(\"li\",[e._v(\"并发容器类ConcurrentHashMap、CopyOnWriteArrayList、CopyOnWriteArraySet\")]),e._v(\" \"),t(\"li\",[e._v(\"阻塞队列（顺着就会问到线程池）\")]),e._v(\" \"),t(\"li\",[e._v(\"线程池（Executor、Callable 、Future、ExecutorService等等，底层原理）\")]),e._v(\" \"),t(\"li\",[e._v(\"AQS 原理，工具类：CountDownLatch、ReentrantLock、Semaphore、Exchanger\")]),e._v(\" \"),t(\"li\",[e._v(\"atomic 类（atomic常用类，方法，到 CAS，或者 ABA问题）\")]),e._v(\" \"),t(\"li\",[e._v(\"Fork/Join并行计算框架\")])]),e._v(\" \"),t(\"p\",[e._v(\"1.0. sleep()方法和wait()方法区别和共同点?\")]),e._v(\" \"),t(\"ul\",[t(\"li\",[e._v(\"两者最主要的区别在于：sleep 方法没有释放锁，而 wait 方法释放了锁 。\")]),e._v(\" \"),t(\"li\",[e._v(\"两者都可以暂停线程的执行。sleep 通常被用于暂停执行。wait 通常被用于线程间交互/通信。\")]),e._v(\" \"),t(\"li\",[e._v(\"wait() 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 notify() 或者 notifyAll() 方法。sleep() 方法执行完成后，线程会自动苏醒。或者可以使用 wait(long timeout)超时后线程会自动苏醒。\")])]),e._v(\" \"),t(\"p\",[e._v(\"1.2. Java 多线程之间的通信方式\")]),e._v(\" \"),t(\"ul\",[t(\"li\",[e._v(\"同步 这里讲的同步是指多个线程通过synchronized关键字这种方式来实现线程间的通信。\")]),e._v(\" \"),t(\"li\",[e._v(\"while轮询的方式\")]),e._v(\" \"),t(\"li\",[e._v(\"wait/notify机制\")])]),e._v(\" \"),t(\"p\",[e._v(\"1.3. Java同步机制有哪些\")]),e._v(\" \"),t(\"ul\",[t(\"li\",[e._v(\"synchronized 关键字，这个相信大家很了解，最好能理解其中的原理\")]),e._v(\" \"),t(\"li\",[e._v(\"Lock 接口及其实现类，如 ReentrantLock.ReadLock 和 ReentrantReadWriteLock.WriteLock\")]),e._v(\" \"),t(\"li\",[e._v(\"信号量（Semaphore）：是一种计数器，用来保护一个或者多个共享资源的访问，它是并发编程的一种基础工具，大多数编程语言都提供这个机制，这也是操作系统中经常提到的\")]),e._v(\" \"),t(\"li\",[e._v(\"CountDownLatch：是 Java 语言提供的同步辅助类，在完成一组正在其他线程中执行的操作之前，他允许线程一直等待\")]),e._v(\" \"),t(\"li\",[e._v(\"CyclicBarrier：也是 java 语言提供的同步辅助类，他允许多个线程在某一个集合点处进行相互等待；\")])]),e._v(\" \"),t(\"p\",[e._v(\"1.4. 如何避免线程死锁?\")]),e._v(\" \"),t(\"ul\",[t(\"li\",[e._v(\"破坏互斥条件 ：这个条件我们没有办法破坏，因为我们用锁本来就是想让他们互斥的（临界资源需要互斥访问）。\")]),e._v(\" \"),t(\"li\",[e._v(\"破坏请求与保持条件 ：一次性申请所有的资源。\")]),e._v(\" \"),t(\"li\",[e._v(\"破坏不剥夺条件 ：占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。\")]),e._v(\" \"),t(\"li\",[e._v(\"破坏循环等待条件 ：靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件。\")])]),e._v(\" \"),t(\"p\",[e._v(\"1.5. 死锁预防\")]),e._v(\" \"),t(\"ul\",[t(\"li\",[e._v(\"以确定的顺序获得锁,如果必须获取多个锁，那么在设计的时候需要充分考虑不同线程之前获得锁的顺序\")]),e._v(\" \"),t(\"li\",[e._v(\"超时放弃：当使用synchronized关键词提供的内置锁时，只要线程没有获得锁，那么就会永远等待下去，然而Lock接口提供了boolean tryLock(long time, TimeUnit unit) throws InterruptedException方法，该方法可以按照固定时长等待锁，因此线程可以在获取锁超时以后，主动释放之前已经获得的所有的锁。通过这种方式，也可以很有效地避免死锁。\")])]),e._v(\" \"),t(\"p\",[e._v(\"1.6. 如何减少CPU的线程切换\")]),e._v(\" \"),t(\"ul\",[t(\"li\",[e._v(\"程序在执行时，多线程是 CPU 通过给每个线程分配 CPU 时间片来实现的，时间片是CPU分配给每个线程执行的时间，因时间片非常短，所以CPU 通过不停地切换线程执行，一般有如下几个办法：\")]),e._v(\" \"),t(\"li\",[e._v(\"无锁并发编程。多线程竞争时，会引起上下文切换，所以多线程处理数据时，可以用一些办法来避免使用锁，如将数据的 ID 按照Hash取模分段，不同的线程处理不同段的数据\")]),e._v(\" \"),t(\"li\",[e._v(\"CAS算法。Java 的 Atomic 包使用 CAS 算法来更新数据，而不需要加锁。\")]),e._v(\" \"),t(\"li\",[e._v(\"控制线程数量。避免创建不需要的线程，比如任务很少，但是创建了很多线程来处理，这样会造成大量线程都处于等待状态\")])]),e._v(\" \"),t(\"p\",[e._v(\"1.7. JAVA多线程实现的三种方式\")]),e._v(\" \"),t(\"ul\",[t(\"li\",[e._v(\"继承Thread；实现Runnable接口；实现Callable接口\")]),e._v(\" \"),t(\"li\",[e._v(\"区别：第一种方式继承Thread就不能继承其他类了，后面两种可以；使用后两种方式可以多个线程共享一个target；Callable比Runnable多一个返回值，并且call()方法可以抛出异常；\")])]),e._v(\" \"),t(\"p\",[e._v(\"2.1. volatile原理\")]),e._v(\" \"),t(\"ul\",[t(\"li\",[e._v(\"volatile 关键字，能够保证volatile变量的可见性，不能保证volatile变量的原子性。深入来说：通过加入内存屏障和禁止重排序优化来实现的。通俗的讲：volatile 变量在每次被线程访问时，都强迫从主内存中重读该变量的值，而当变量发生变化时，又强迫线程将最新的值刷新到主内存。这样任何时刻，不同的线程总能看到该变量的最新的值。\")]),e._v(\" \"),t(\"li\",[e._v(\"对 volatile 变量执行写操作时，会在写操作后加入一条 store 屏障指令。store 指令会在写操作后把最新的值强制刷新到主内存中。同时还会禁止 cpu 对代码进行重排序优化。这样就保证了值在主内存中是最新的。\")]),e._v(\" \"),t(\"li\",[e._v(\"对 volatile 变量执行读操作时，会在读操作前加入一条 load 屏障指令。load 指令会在读操作前把工作内存缓存中的值清空后，再从主内存中读取最新的值。\")]),e._v(\" \"),t(\"li\",[e._v(\"从 Load 到store 到内存屏障，一共4步，其中最后一步jvm让这个最新的变量的值在所有线程可见，也就是最后一步让所有的CPU内核都获得了最新的值，但中间的几步（从Load到Store）是不安全的，中间如果其他的 CPU 修改了值将会丢失。为 volatile 变量赋值的场景，不要存在依赖于 volatile 变量情况。\")])]),e._v(\" \"),t(\"p\",[e._v(\"2.2. CAS步骤、弊端和java8的优化\")]),e._v(\" \"),t(\"ul\",[t(\"li\",[e._v(\"步骤：1. 获得L(内存地址)上的数据初始值D1；2. 对D1的数据进行增减后最终等到D2；3. 尝试将D2 放到原来L的位置上；4. 放之前先比较目前L里的数据是否跟我之前取出的D1值跟版本号都对应。5. 对应了 我就将数据放到L中，但有一个不对应则写入失败。重新执行步骤1；6. 上面的步骤如果失败了就会重复进入一个1～5的死循环，俗称自旋。\")]),e._v(\" \"),t(\"li\",[e._v(\"弊端：1. ABA问题，现象：在内存中数据变化为A==>B==>A,这样如何判别，因为这样其实数据已经修改过了。解决方法：引入版本号。思路很简单，每次compareAndSwap后给数据的版本号加1，下次compareAndSwap的时候不仅比较数据，也比较版本号，值相同，版本号不同也不能执行成功。Java中提供了AtomicStampedReference来解决该问题，AtomicStampedReference内部维护了一个Pair的数据结构，用volatile修饰，保证可见性，用于打包数据对象和版本号；2. 开销问题：如果长期不成功那就会进入自旋。JVM支持处理器提供的pause指令，使得效率会有一定的提升，pause指令有两个作用：它可以延迟流水线执行指令，使CPU不会消耗过多的执行资源；它可以避免在退出循环的时候因内存顺序冲突（memory order violation）而引起CPU流水线被清空（CPU pipeline flush），从而提高CPU的执行效率；3. 只能保证一个共享变量之间的原则性操作，问题描述：当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁来保证原子性。解决办法：从JDK5开始提供了AtomicReference类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行CAS操作。\")]),e._v(\" \"),t(\"li\",[e._v(\"优化：针对大量线程访问性能和效率问题，在java中引入了新类LongAdder，它对CAS进行了优化，采用了CAS分段机制与自动分段迁移机制。如果发现并发更新的线程数量过多，就会开始施行分段CAS的机制，也就是内部会搞一个Cell数组，每个数组是一个数值分段。这时，让大量的线程分别去对不同Cell内部的value值进行CAS累加操作，这样就把CAS计算压力分散到了不同的Cell分段数值中了。最后，如果你要从LongAdder中获取当前累加的总值，就会把base值和所有Cell分段数值加起来返回给你。\")])]),e._v(\" \"),t(\"p\",[e._v(\"2.3. Java Object对象的存储结构\")]),e._v(\" \"),t(\"ul\",[t(\"li\",[e._v(\"JavaObject对象在内存中存储中的存储布局分为三个区域，分别是对象头、示例数据、对象填充。\")]),e._v(\" \"),t(\"li\",[e._v(\"对象头部包括两部分，分别是对象标记和类元信息（类型指针）。对象标记，也就是Markword存储对象的哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等信息。类元信息存储“类对象信息的指针”。\")])]),e._v(\" \"),t(\"p\",[e._v(\"2.4. synchoronized的底层是怎么实现的\")]),e._v(\" \"),t(\"ul\",[t(\"li\",[e._v(\"synchronized 同步语句块的情况：synchronized 同步语句块的实现使用的是 monitorenter 和 monitorexit 指令，其中 monitorenter 指令指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。 当执行 monitorenter 指令时，线程试图获取锁也就是获取 monitor(monitor对象存在于每个 Java 对象的对象头中，synchronized 锁便是通过这种方式获取锁的，也是为什么 Java 中任意对象可以作为锁的原因) 的持有权。当计数器为0则可以成功获取，获取后将锁计数器设为1也就是加1。相应的在执行 monitorexit 指令后，将锁计数器设为0，表明锁被释放。如果获取对象锁失败，那当前线程就要阻塞等待，直到锁被另外一个线程释放为止。\")]),e._v(\" \"),t(\"li\",[e._v(\"synchronized 修饰方法的的情况：synchronized 修饰的方法并没有 monitorenter 指令和 monitorexit 指令，取得代之的确实是 ACC_SYNCHRONIZED 标识，该标识指明了该方法是一个同步方法，JVM 通过该 ACC_SYNCHRONIZED 访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。\")]),e._v(\" \"),t(\"li\",[e._v(\"进一步总结：底层是利用monitor对象（很多线程竞争对象的monitor），CAS和mutex互斥锁来实现的。任何对象都有一个monitor与之关联，当且一个monitor被持有后，它将处于锁定状态。线程执行到monitorenter指令时，将会尝试获取对象所对应的monitor的所有权，即尝试获得对象的锁。修饰代码块，编译后的字节码文件会被加上 monitorenter、monitorexit 指令；修饰方法，锁对象就是当前类的实例，该方法会被打上标记ACC_SYNCHRONIZED，标识是同步方法；修饰静态方法，锁对象则是当前类Class对象。利用javap查看字节码文件，同步代码块中有两个monitorexit是因为需要考虑异常情况也要释放锁。\")]),e._v(\" \"),t(\"li\",[e._v(\"未竞争到锁去哪里了：objectMonitor内部会有等待队列（cxq和Entrylist）和条件等待队列（waitSet）来存放相应的阻塞线程。未竞争到锁的线程存储到等待队列中，获得锁的线程调用wait后存放到条件等待队列中，解锁会唤醒相应队列中的等待线程来竞争锁。\")])]),e._v(\" \"),t(\"p\",[e._v(\"2.5. 锁优化\")]),e._v(\" \"),t(\"ul\",[t(\"li\",[e._v(\"编译期：锁粗化，锁消除 ->运行期：自旋 -> 运行期：锁升级。\")]),e._v(\" \"),t(\"li\",[e._v(\"锁粗化：就是将「多个连续的加锁、解锁操作连接在一起」，扩展成一个范围更大的锁，避免频繁的加锁解锁操作。\")]),e._v(\" \"),t(\"li\",[e._v(\"锁消除：除不可能存在共享资源竞争的锁，通过这种方式消除没有必要的锁，可以节省毫无意义的时间消耗，比如就是方法内部的1+1；\")]),e._v(\" \"),t(\"li\",[e._v(\"自适应自旋锁：在JDK1.6中自旋锁默认开启。可以使用-XX:+UseSpinning开启，-XX:-UseSpinning关闭自旋锁优化。自旋的默认次数为10次，可以使用-XX:preBlockSpin参数修改默认的自旋次数。 适应性自旋：是赋予了自旋一种学习能力，它并不固定自旋10次。他可以根据它前面线程的自旋情况，从而调整它的自旋\")]),e._v(\" \"),t(\"li\",[e._v(\"锁升级：无锁—>偏向锁：JDK6中引进了偏向锁。当一个线程访问同步代码块并获取锁时，会在Mark Word里存储锁偏向的线程ID。在线程进入和退出同步块时不再通过CAS操作来加锁和解锁，而是检测MarkWord里是否存储着指向当前线程的偏向锁。引入偏向锁是为了在没有多线程竞争的情况下尽量减少不必要的轻量级锁执行路径，偏向锁只需要在置换ThreadID的时候依赖一次CAS原子指令即可。\")]),e._v(\" \"),t(\"li\",[e._v(\"锁升级：偏向锁—>轻量级锁：偏向锁多应用只有一个线程访问同步块场景中，一旦偏向锁被其他线程访问，就会升级为轻量级锁。其他线程会通过自旋的形式尝试获取锁，不会阻塞，从而提高性能。\")]),e._v(\" \"),t(\"li\",[e._v(\"锁升级：轻量级锁—>重量级锁：轻量级锁膨胀之后，就升级为重量级锁，重量级锁是依赖操作系统的MutexLock（互斥锁）来实现的，需要从用户态转到内核态，这个成本非常高，这就是为什么Java1.6之前Synchronized效率低的原因。升级为重量级锁时，锁标志位的状态值变为10，此时Mark Word中存储内容的是重量级锁的指针，等待锁的线程都会进入阻塞状态。\")])]),e._v(\" \"),t(\"p\",[e._v(\"2.6. notify&wait原理:\")]),e._v(\" \"),t(\"ul\",[t(\"li\",[e._v(\"Monitor对象 中包含一个同步队列（由 _cxq 和 _EntryList 组成）和一个等待队列（ _WaitSet ）。\")]),e._v(\" \"),t(\"li\",[e._v(\"当一个线程尝试获得锁时，如果该锁已经被占用，则会将该线程封装成一个ObjectWaiter对象插入到cxq的队列尾部，然后暂停当前线程。\")]),e._v(\" \"),t(\"li\",[e._v(\"当持有锁的线程释放锁前，会将cxq中的所有元素移动到EntryList中去，并唤醒EntryList的队首线程。\")]),e._v(\" \"),t(\"li\",[e._v(\"如果一个线程在同步块中调用了Object#wait方法，会将该线程对应的ObjectWaiter从EntryList移除并加入到WaitSet中，然后释放锁。\")]),e._v(\" \"),t(\"li\",[e._v(\"当wait的线程被notify之后，会将对应的ObjectWaiter从WaitSet移动到EntryList中。\")]),e._v(\" \"),t(\"li\",[e._v(\"synchronized的同步队列和等待队列 与 基于AQS（lock/condition）的同步队列和等待队列实现原理类似，只不过前者是一个同步队列对应一个等待队列，而后者是一个同步队列可以对应多个等待队列。\")]),e._v(\" \"),t(\"li\",[e._v(\"执行Object.wait/notify，为什么必须要在synchronized中呢？保证原子性：是为了保证在Object.wait时，将当前线程添加到_WaitSet等待队列和monitor out唤醒其他线程的原子性；为了保证在Object.notify 时，在将当前线程从WaitSet移到同步队列时，锁相关的线程状态不会发生变化。\")])]),e._v(\" \"),t(\"p\",[e._v(\"3.1. 什么是AQS\")]),e._v(\" \"),t(\"ul\",[t(\"li\",[e._v(\"AQS是JDK1.5提供的一个基于FIFO等待队列实现的一个用于实现同步器的基础框架，这个基础框架的重要性可以这么说，JCU包里面几乎所有的有关锁、多线程并发以及线程同步器等重要组件的实现都是基于AQS这个框架\")]),e._v(\" \"),t(\"li\",[e._v(\"AQS的核心思想是基于volatile int state这样的一个属性同时配合Unsafe工具对其原子性的操作来实现对当前锁的状态进行修改。当state的值为0的时候，标识改Lock不被任何线程所占有。\")]),e._v(\" \"),t(\"li\",[e._v(\"AQS由三部分组成，state同步状态、Node组成的CLH队列、ConditionObject条件变量（包含Node组成的条件单向队列），线程的阻塞和解除阻塞。\")]),e._v(\" \"),t(\"li\",[e._v(\"AQS的设计使用了模板方法的设计模式，模板方法一般在父类中封装不变的部分（如算法骨架），把扩展的可变部分交给子类进行扩展，子类的执行结果会影响父类的结果，是一种反向的控制结构。AQS中应用了这种设计模式，将一部分方法交给子类进行重写，而自定义的同步组件在调用同步器提供的模板方法（父类中的方法）时，又会调用子类重写的方法。\")]),e._v(\" \"),t(\"li\",[e._v(\"AQS中采用了LockSupport.park(thread) 来挂起线程，用unpark来唤醒线程。因为争抢锁的线程可能很多，但是只能有一个线程拿到锁，其他的线程都必须等待，这个时候就需要一个queue来管理这些线程，AQS用的是一个FIFO的队列，就是一个链表，每个node都持有后继节点的引用。\")]),e._v(\" \"),t(\"li\",[e._v(\"AQS：短了说就是state，长了说就是：3.2、3.3、3.4。\")])]),e._v(\" \"),t(\"p\",[e._v(\"3.2. 同步状态\")]),e._v(\" \"),t(\"ul\",[t(\"li\",[e._v(\"在AQS中维护了一个同步状态变量state，getState函数获取同步状态，setState、compareAndSetState函数修改同步状态。\")]),e._v(\" \"),t(\"li\",[e._v(\"state语义都不一样：ReentrantLock的state用来表示是否有锁资源；ReentrantReadWriteLock的state高16位代表读锁状态，低16位代表写锁状态；Semaphore的state用来表示可用信号的个数；CountDownLatch的state用来表示计数器的值\")]),e._v(\" \"),t(\"li\",[e._v(\"锁状态。我们要知道锁是不是被别的线程占有了，这个就是state的作用，它为0的时候代表没有线程占有锁，可以去争抢这个锁，用CAS将state设为1，如果CAS成功，说明抢到了锁，这样其他线程就抢不到了，如果锁重入的话，state进行+1就可以，解锁就是减1，直到state又变为0，代表释放锁，所以lock() 和unlock() 必须要配对啊。然后唤醒等待队列中的第一个线程，让其来占有锁。\")])]),e._v(\" \"),t(\"p\",[e._v(\"3.3. CLH队列\")]),e._v(\" \"),t(\"ul\",[t(\"li\",[e._v(\"CLH锁是一种自旋锁，自旋锁适用于锁占用时间短的场合，互斥锁适用于锁占用时间长的场合。CLH锁其实就是一种是基于逻辑队列非线程饥饿的一种自旋公平锁。\")]),e._v(\" \"),t(\"li\",[e._v(\"CLH数据模型：CLH队列中的结点QNode中含有一个locked字段，该字段若为true表示该线程需要获取锁，且不释放锁，为false表示线程释放了锁。结点之间是通过隐形的链表相连，之所以叫隐形的链表是因为这些结点之间没有明显的 next 指针，而是通过myPred所指向的结点的变化情况来影响myNode的行为。\")]),e._v(\" \"),t(\"li\",[e._v(\"CLH原理：首先有一个尾节点指针，通过这个尾结点指针来构建等待线程的逻辑队列，因此能确保线程线程先到先服务的公平性，因此尾指针可以说是构建逻辑队列的桥梁；此外这个尾节点指针是原子引用类型，避免了多线程并发操作的线程安全性问题；通过等待锁的每个线程在自己的某个变量上自旋等待，这个变量将由前一个线程写入。由于某个线程获取锁操作时总是通过尾节点指针获取到前一线程写入的变量，而尾节点指针又是原子引用类型，因此确保了这个变量获取出来总是线程安全的。\")]),e._v(\" \"),t(\"li\",[e._v(\"CLH是AQS内部维护的FIFO（先进先出）双端双向队列（方便尾部节点插入），基于链表数据结构，当一个线程竞争资源失败，就会将等待资源的线程封装成一个Node节点，通过CAS原子操作插入队列尾部，最终不同的Node节点连接组成了一个CLH队列，所以说AQS通过CLH队列管理竞争资源的线程，个人总结CLH队列具有如下几个优点：先进先出保证了公平性；非阻塞的队列，通过自旋锁和CAS保证节点插入和移除的原子性，实现无锁快速插入；采用了自旋锁思想，所以CLH也是一种基于链表的可扩展、高性能、公平的自旋锁。\")])]),e._v(\" \"),t(\"p\",[e._v(\"3.4. 条件变量\")]),e._v(\" \"),t(\"ul\",[t(\"li\",[e._v(\"Object的wait、notify函数是配合Synchronized锁实现线程间同步协作的功能，AQS的ConditionObject条件变量也提供这样的功能，通过ConditionObject的await和signal两类函数完成。\")]),e._v(\" \"),t(\"li\",[e._v(\"不同于Synchronized锁，一个AQS可以对应多个条件变量，而Synchronized只有一个。\")]),e._v(\" \"),t(\"li\",[e._v(\"ConditionObject内部维护着一个单向条件队列，不同于CHL队列，条件队列只入队执行await的线程节点，并且加入条件队列的节点，不能在CHL队列， 条件队列出队的节点，会入队到CHL队列。当某个线程执行了ConditionObject的await函数，阻塞当前线程，线程会被封装成Node节点添加到条件队列的末端，其他线程执行ConditionObject的signal函数，会将条件队列头部线程节点转移到CHL队列参与竞争资源\")])]),e._v(\" \"),t(\"p\",[e._v(\"3.5. ReentrantLock\")]),e._v(\" \"),t(\"ul\",[t(\"li\",[e._v(\"ReentrantLock内部定义了专门的组件Sync，Sync继承AbstractQueuedSynchronizer提供释放资源的实现，NonfairSync和FairSync是基于Sync扩展的子类，即ReentrantLock的非公平模式与公平模式，它们作为Lock接口功能的基本实现。ReentrantLock类中带有两个构造函数，一个是默认的构造函数，不带任何参数；一个是带有 fair 参数的构造函数。\")]),e._v(\" \"),t(\"li\",[e._v(\"为什么是重入锁在ReentrantLock中，它对AbstractQueuedSynchronizer的state状态值定义为线程获取该锁的重入次数，state状态值为0表示当前没有被任何线程持有，state状态值为1表示被其他线程持有，因为支持可重入，如果是持有锁的线程，再次获取同一把锁，直接成功，并且state状态值+1，线程释放锁state状态值-1，同理重入多次锁的线程，需要释放相应的次数。\")]),e._v(\" \"),t(\"li\",[e._v(\"NonfairSync：AQS为加锁和解锁过程提供了统一的模板函数，加锁与解锁的模板流程是，获取锁失败的线程，会进入CLH队列阻塞，其他线程解锁会唤醒CLH队列线程。线程释放锁时，会唤醒CLH队列阻塞的线程，重新竞争锁，要注意，此时可能还有非CLH队列的线程参与竞争，所以非公平就体现在这里，非CLH队列线程与CLH队列线程竞争，各凭本事，不会因为你是CLH队列的线程，排了很久的队，就把锁让给你。\")]),e._v(\" \"),t(\"li\",[e._v(\"FairSync：公平策略就是，严格按照CLH队列顺序获取锁，线程释放锁时，会唤醒CLH队列阻塞的线程，重新竞争锁，要注意，此时可能还有非CLH队列的线程参与竞争，为了保证公平，一定会让CLH队列线程竞争成功，如果非CLH队列线程一直占用时间片，那就一直失败（构建成节点插入到CLH队尾，由A S Q模板流程执行），直到时间片轮到CLH队列线程为止，所以公平策略的性能会更差。\")]),e._v(\" \"),t(\"li\",[e._v(\"FairSync流程与NonfairSync基本一致，唯一的区别就是在CAS执行前，多了一步hasQueuedPredecessors函数，这一步就是判断当前线程是不是CLH队列被唤醒的线程，如果是就执行CAS，否则获取资源失败.ReentrantLock默认是使用非公平策略，如果想指定模式，可以通过入参fair来选择，这里就不做过多概述，接下来看看ReentrantLock对Lock的实现。\")])]),e._v(\" \"),t(\"p\",[e._v(\"3.6. ReentrantReadWriteLock\")]),e._v(\" \"),t(\"ul\",[t(\"li\",[e._v(\"有了CopyOnWrite为何又要有ReadWriteLock？内存占用问题：因为CopyOnWrite的写时复制机制每次进行写操作的时候都会有两个数组对象的内存，如果这个数组对象占用的内存较大的话，如果频繁的进行写入就会造成频繁的Yong GC和Full GC；数据一致性问题：CopyOnWrite容器只能保证数据的最终一致性，不能保证数据的实时一致性。读操作的线程可能不会立即读取到新修改的数据，因为修改操作发生在副本上。\")]),e._v(\" \"),t(\"li\",[e._v(\"ReentrantReadWriteLock中的类分成三个部分：ReentrantReadWriteLock本身实现了ReadWriteLock接口，这个接口只提供了两个方法readLock()和writeLock（）；同步器，包含一个继承了AQS的Sync内部类，以及其两个子类FairSync和NonfairSync；ReadLock和WriteLock两个内部类实现了Lock接口，它们具有锁的一些特性。\")]),e._v(\" \"),t(\"li\",[e._v(\"在获取读锁时：如果写锁已经被其他线程获取，那么此线程将会加入到同步队列，挂起等待唤醒；如果写锁没有被其他线程获取，但是同步队列的第一个节点是写线程的节点，那么此线程让位给写线程，挂起等待唤醒；如果获取读锁的线程，已经持有了写锁，那么即使同步队列的第一个节点是写线程的节点，它也不会让位给同步队列中的写线程，而是自旋去获取读锁。因为此时让位会造成死锁。\")]),e._v(\" \"),t(\"li\",[e._v(\"获取写锁时：如果读锁已经被获取，那么不允许获取写锁。将此线程加入到同步队列，挂起等待唤醒；如果读锁没有被获取，但是写锁已经被其他线程抢占，那么还是将此线程加入到同步队列，挂起等待唤醒；如果写锁已经被此线程持有，那么重入，即写状态+1；如果读锁和写锁都没有被获取，那么CAS尝试获取写锁\")])]),e._v(\" \"),t(\"p\",[e._v(\"3.7. StampedLock锁\")]),e._v(\" \"),t(\"ul\",[t(\"li\",[e._v(\"从ReentrantLock到ReentrantReadWriteLock，再到StampedLock，读操作并发度依次提高。ReentrantReadWriteLock采用“悲观读”策略，当第一个读线程抢到共享锁，第二个、第三个读线程还可以抢到共享锁，使得写线程一直无法获取互斥写锁，会导致写线程“饿死”。\")]),e._v(\" \"),t(\"li\",[e._v(\"StampedLock通过读写不互斥进一步提高读的并发量。读写不互斥的问题在于：会产生不可重复读，两次读取结果不一样。即读取的时候，可能另一个线程正在修改该值，还没有完成，读完之后，写线程也操作结束，此时读线程读到的数据和真实的数据不一致。\")]),e._v(\" \"),t(\"li\",[e._v(\"StampedLock引入了“乐观读”策略：读的时候不加读锁，读出来发现数据被修改了，再升级为“悲观读”；即读错了再严格读一次；相当于降低了“读”的地位，把抢锁的天平往“写”的一方倾斜了一下，避免写线程被饿死。StampedLock是一个读写锁，悲观读和悲观写的锁状态需要同步，互斥，锁状态操作需要是原子操作。\")])]),e._v(\" \"),t(\"p\",[e._v(\"4.0. 为什么要有线程池\")]),e._v(\" \"),t(\"ul\",[t(\"li\",[e._v(\"线程是一个重资源，JVM 中的线程与操作系统的线程是一对一的关系，所以在JVM中每创建一个线程就需要调用操作系统提供的API创建线程，赋予资源，并且销毁线程同样也需要系统调用。而系统调用就意味着上下文切换等开销，并且线程也是需要占用内存的，而内存也是珍贵的资源。\")]),e._v(\" \"),t(\"li\",[e._v(\"在单核时代，如果是纯运算的操作是不需要多线程的，一个线程一直执行运算即可。但如果这个线程正在等待 I/O 操作，此时 CPU 就处于空闲状态，这就浪费了 CPU 的算力，因此有了多线程，在某线程等待 I/O 等操作的时候，另一个线程顶上，充分利用 CPU，提高处理效率。\")]),e._v(\" \"),t(\"li\",[e._v(\"在多核时代，随着CPU的发展，核心数越来越多，能同时运行的线程数也提升了，此时的多线程不仅是为了提高单核CPU的利用率，也是为了充分利用多个核心。\")]),e._v(\" \"),t(\"li\",[e._v(\"CPU的核心数有限，同时能运行的线程数有限，所以需要根据调度算法切换执行的线程，而线程的切换需要开销，比如替换寄存器的内容、高速缓存的失效等等。如果线程数太多，切换的频率就变高，可能使得多线程带来的好处抵不过线程切换带来的开销，得不偿失。因为线程数太少无法充分利用 CPU ，太多的话由于上下文切换的消耗又得不偿失，所以我们需要评估系统所要承载的并发量和所执行任务的特性，得出大致需要多少个线程数才能充分利用 CPU，因此需要控制线程数量。\")])]),e._v(\" \"),t(\"p\",[e._v(\"4.1. 池化原理是什么(线程池为什么可以复用)\")]),e._v(\" \"),t(\"ul\",[t(\"li\",[e._v(\"线程池可以把线程和任务进行解耦，线程归线程，任务归任务，摆脱了之前通过Thread创建线程时的一个线程必须对应一个任务的限制。\")]),e._v(\" \"),t(\"li\",[e._v(\"在线程池中，同一个线程可以从BlockingQueue中不断提取新任务来执行，其核心原理在于线程池对 Thread 进行了封装，并不是每次执行任务都会调用Thread.start()来创建新线程，而是让每个线程去执行一个“循环任务”，在这个“循环任务”中，不停地检查是否还有任务等待被执行，如果有则直接去执行这个任务，也就是调用任务的run方法，把run方法当作和普通方法一样的地位去调用，相当于把每个任务的 run() 方法串联了起来，所以线程数量并不增加。\")]),e._v(\" \"),t(\"li\",[e._v(\"线程池的本质是一个典型的生产者-消费者模式。线程池内部会有一个队列来存储我们提交的任务，而内部线程不断地从队列中索取任务来执行，这就是线程池最原始的执行机制。\")])]),e._v(\" \"),t(\"p\",[e._v(\"4.2. 手写一个线程池？\")]),e._v(\" \"),t(\"div\",{staticClass:\"language- line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[t(\"code\",[e._v('@Slf4j\\npublic class YesThreadPool {\\n\\n    BlockingQueue<Runnable> taskQueue;  //存放任务的阻塞队列\\n    List<YesThread> threads; //线程列表\\n\\n    YesThreadPool(BlockingQueue<Runnable> taskQueue, int threadSize) {\\n        this.taskQueue = taskQueue;\\n        threads = new ArrayList<YesThread>(threadSize);\\n        for(int i =0; i< threadSize; i++){\\n            YesThread thread = new YesThread(\"yes-task-thread-\" + i);\\n            thread.start();\\n            threads.add(thread);\\n        }\\n    }\\n    //提交任务只是往任务队列里面塞任务\\n    public void execute(Runnable task) throws InterruptedException {\\n        taskQueue.put(task);\\n    }\\n\\n    class YesThread extends Thread { //自定义一个线程\\n        public YesThread(String name) {\\n            super(name);\\n        }\\n        @Override\\n        public void run() {\\n            while (true) { //死循环\\n                Runnable task = null;\\n                try {\\n                    task = taskQueue.take(); //不断从任务队列获取任务\\n                } catch (InterruptedException e) {\\n                }\\n                task.run(); //执行\\n            }\\n        }\\n    }\\n}\\n\\n')])]),e._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[e._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[e._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[e._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[e._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[e._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[e._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[e._v(\"7\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[e._v(\"8\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[e._v(\"9\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[e._v(\"10\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[e._v(\"11\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[e._v(\"12\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[e._v(\"13\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[e._v(\"14\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[e._v(\"15\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[e._v(\"16\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[e._v(\"17\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[e._v(\"18\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[e._v(\"19\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[e._v(\"20\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[e._v(\"21\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[e._v(\"22\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[e._v(\"23\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[e._v(\"24\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[e._v(\"25\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[e._v(\"26\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[e._v(\"27\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[e._v(\"28\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[e._v(\"29\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[e._v(\"30\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[e._v(\"31\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[e._v(\"32\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[e._v(\"33\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[e._v(\"34\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[e._v(\"35\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[e._v(\"36\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[e._v(\"37\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[e._v(\"38\")]),t(\"br\")])]),t(\"p\",[e._v(\"4.3. 当一个线程进入线程池会发什么？（线程池的流程运转原理）\")]),e._v(\" \"),t(\"ul\",[t(\"li\",[e._v(\"当提交任务后,,线程池首先会检查当前线程数,如果当前线程数小于核心线程数,则新建线程并执行任务.\")]),e._v(\" \"),t(\"li\",[e._v(\"随着任务不断增加,线程数达到了核心线程数的数量,此时任务依然在增加,那么新来的任务将会放到workQueue等待队列中,等核心线程执行完任务后重新从队列中提取出等待被执行的任务\")]),e._v(\" \"),t(\"li\",[e._v(\"如果已经达到了核心线程数,且任务队列也满了,则线程池就会继续创建线程来执行任务,如果任务不断提交,线程池会持续创建线程直到达到maximumPoolSize最大线程数,当达到了最大线程数后,任务仍不断提交,那么此时就超过了线程池的最大处理能力,这个时候线程池就会拒绝处理这些任务,处理策略就是handler.\")]),e._v(\" \"),t(\"li\",[e._v(\"线程池里的线程不是一开始就直接拉满的，是根据任务量开始慢慢增多的，这就算一种懒加载，到用的时候再创建线程，节省资源。\")]),e._v(\" \"),t(\"li\",[e._v(\"更完整分两步，第一步：当有新任务来的时候，首先判断当前的线程数有没有超过核心线程数，如果没超过则直接新建一个线程来执行新的任务，如果超过了则判断缓存队列有没有满，没满则将新任务放进缓存队列中，如果队列已满并且线程池中的线程数已经达到了指定的最大线程数，那就根据相应的策略拒绝任务，默认为抛异常。\")]),e._v(\" \"),t(\"li\",[e._v(\"更完整分两步，第二步：当缓存队列中的任务都执行完毕后，线程池中的线程数如果大于核心线程数并且已经超过了指定的存活时间（存活时间通过队列的poll方法传入，如果指定时间内没有获取到任务，则break退出，线程运行结束），就销毁多出来的线程，直到线程池中的线程数等于核心线程数。此时剩余的线程会一直处于阻塞状态，等待新的任务到来。\")])]),e._v(\" \"),t(\"p\",[e._v(\"4.4. ThreadPoolExecutor构造方法\")]),e._v(\" \"),t(\"ul\",[t(\"li\",[e._v(\"poolSize：线程池中当前线程的数量，当该值为0的时候，意味着没有任何线程，线程池会终止；同一时刻，poolSize不会超过maximumPoolSize。\")]),e._v(\" \"),t(\"li\",[e._v(\"corePoolSize，线程池核心线程数量：线程池在完成初始化之后，默认情况下，线程池中不会有任何线程，线程池会等有任务来的时候再去创建线程。核心线程创建出来后即使超出了线程保持的存活时间配置也不会销毁，核心线程只要创建就永驻了，就等着新任务进来进行处理。\")]),e._v(\" \"),t(\"li\",[e._v(\"maximumPoolSize，线程池最大线程数量：核心线程忙不过来且任务存储队列满了的情况下，还有新任务进来的话就会继续开辟线程，但是也不是任意的开辟线程数量，线程数（包含核心线程）达到maximumPoolSize后就不会产生新线程了，就会执行拒绝策略。\")]),e._v(\" \"),t(\"li\",[e._v(\"keepAliverTime，当活跃线程数大于核心线程数时，空闲的多余线程最大存活时间：如果线程池当前的线程数多于corePoolSize，那么如果多余的线程空闲时间超过keepAliveTime，那么这些多余的线程（超出核心线程数的那些线程）就会被回收。\")]),e._v(\" \"),t(\"li\",[e._v(\"unit，存活时间的单位：比如：TimeUnit.MILLISECONDS、TimeUnit.SECONDS。\")]),e._v(\" \"),t(\"li\",[e._v(\"workQueue，存放任务的队列，阻塞队列类型：核心线程数满了后还有任务继续提交到线程池的话，就先进入workQueue。\\n\"),t(\"ul\",[t(\"li\",[e._v(\"ArrayBlockingQueue：是一个基于数组结构的有界阻塞队列，此队列按 FIFO（先进先出）原则对元素进行排序。初始化时需指定队列的容量 capacity。\")]),e._v(\" \"),t(\"li\",[e._v(\"LinkedBlockingQueue：一个基于链表结构的阻塞队列，此队列按FIFO （先进先出） 排序元素，吞吐量通常要高于ArrayBlockingQueue。静态工厂方法Executors.newFixedThreadPool()使用了这个队列\")]),e._v(\" \"),t(\"li\",[e._v(\"SynchronousQueue：一个不存储元素的阻塞队列（SynchronousQueue 也可以存储数据，且是无锁实现，只是size()方法直接返回0而已。）。每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于LinkedBlockingQueue，静态工厂方法Executors.newCachedThreadPool使用了这个队列。同步队列，阻塞队列的特殊版，即没有容量的阻塞队列，随进随出，不做停留。\")]),e._v(\" \"),t(\"li\",[e._v(\"PriorityBlockingQueue：一个具有优先级的无限阻塞队列(优先级通过参数Comparator实现)。优先级阻塞队列，这是一个无界队列，不遵循FIFO，而是根据任务自身的优先级顺序来执行，初始化可不指定容量，默认11（既然有容量，怎么还是无界的呢？因为它添加元素时会进行扩容）。-\")]),e._v(\" \"),t(\"li\",[e._v(\"DelayedWorkQueu队列的特点是内部的任务并不是按照放入的时间排序,而是会按照延迟的时间长短对任务进行排序,内部采用的是“堆”数据结构.而且它也是一个无界队列.\")])])]),e._v(\" \"),t(\"li\",[e._v(\"threadFactory：当线程池需要新的线程时，会用threadFactory来生成新的线程，默认采用的是DefaultThreadFactory，主要负责创建线程。newThread()方法。创建出来的线程都在同一个线程组且优先级也是一样的。\")]),e._v(\" \"),t(\"li\",[e._v(\"handler：拒绝策略，任务量超出线程池的配置限制或执行shutdown还在继续提交任务的话，会执行handler的逻辑。默认采用的是AbortPolicy，遇到上面的情况，线程池将直接采取直接拒绝策略，也就是直接抛出异常。RejectedExecutionException\\n\"),t(\"ul\",[t(\"li\",[e._v(\"AbortPolicy：直接抛出异常，如果线程数达到最大，且工作队列也满，此时再进来任务，则抛出 RejectedExecutionException（系统会停止运行，但是不会退出）\")]),e._v(\" \"),t(\"li\",[e._v(\"CallerRunsPolicy：只用调用所在的线程运行任务，让新来的任务返回到调用它的线程中去执行（比如main线程调用了executors.execute(task)，那么就会将task返回到main线程中去执行）\")]),e._v(\" \"),t(\"li\",[e._v(\"DiscardOldestPolicy：丢弃队列里最近的一个任务，并执行当前任务。如果线程数达到最大，且工作队列也满，此时再进来任务，则丢掉最先进入队列的任务（有点残忍了），并再次插入任务\")]),e._v(\" \"),t(\"li\",[e._v(\"DiscardPolicy：不处理，丢弃掉。如果线程数达到最大，且工作队列也满，此时再进来任务，则直接丢掉（看任务的重要程度，不重要的任务可以用这个策略）\")])])])]),e._v(\" \"),t(\"p\",[e._v(\"4.5. 核心线程\")]),e._v(\" \"),t(\"ul\",[t(\"li\",[e._v(\"线程池其实想要的只是核心线程数个线程，但是又预留了一些数量来预防突发状况，当突发状况过去之后，线程池希望只维持核心线程数的线程，所以就弄了个 KeepAliveTime，当线程数大于核心数之后，如果线程空闲了一段时间（KeepAliveTime），就回收线程，直到数量与核心数持平。\")]),e._v(\" \"),t(\"li\",[e._v(\"在JDK1.6之前，线程池会尽量保持corePoolSize个核心线程，即使这些线程闲置了很长时间。这一点曾被开发者诟病，所以从JDK1.6开始，提供了方法allowsCoreThreadTimeOut，如果传参为true，则允许闲置的核心线程被终止。请注意这种策略和corePoolSize=0的区别。我总结的区别是：corePoolSize=0：在一般情况下只使用一个线程消费任务，只有当并发请求特别多、等待队列都满了之后，才开始用多线程。allowsCoreThreadTimeOut=true && corePoolSize>1：在一般情况下就开始使用多线程（corePoolSize个），当并发请求特别多，等待队列都满了之后，继续加大线程数。但是当请求没有的时候，允许核心线程也终止。所以corePoolSize=0的效果，基本等同于allowsCoreThreadTimeOut=true && corePoolSize=1，但实现细节其实不同。\")]),e._v(\" \"),t(\"li\",[e._v(\"线程池创建之后，会立即创建核心线程么？不会。从上面的源码可以看出，在刚刚创建ThreadPoolExecutor的时候，线程并不会立即启动，而是要等到有任务提交时才会启动，除非调用了prestartCoreThread/prestartAllCoreThreads事先启动核心线程。\")])]),e._v(\" \"),t(\"p\",[e._v(\"4.6. 线程池的使用原则\")]),e._v(\" \"),t(\"ul\",[t(\"li\",[e._v(\"一定要传递threadFactory这个参数，定义有意义的线程名\")]),e._v(\" \"),t(\"li\",[e._v(\"尽量避免局部变量创建线程池：引入线程池的目的提高资源复用，如果在局部变量创建线程池，基本上达不到提高资源复用，而且很有可能因为忘记调用shutdown出现资源泄漏。\")]),e._v(\" \"),t(\"li\",[e._v(\"最好能设计一个可监控的线程池：handler的监控。一旦任务进入handler说明此时线程池数目在max的时候都处理不过来了，服务肯定会收到影响。这种情况要及时处理；workQueue的大小。如果workQueue里面有挤压，说明线程数在core任务处理不过来，要注意这种情况对服务带来的影响；监控activeCount的数目。这样可以了解设置的参数是否合理，比如core设置的太大，浪费资源；监控通过线程池创建的线程总数。在创建线程时候+1，销毁的时候-1，这样可以监控是否有资源泄漏。ThreadPoolExecutor提供了beforeExecute, afterExecute 等钩子方法，我们可以可以在钩子方法中对线程池任务的执行时间上报CAT\")]),e._v(\" \"),t(\"li\",[e._v(\"线程池大小和队列设置原则，避免任务堆积：（因素：处理时间 + 线程数 + CPU数量）核心接口以及没有突发流量情况下，我通过给出的建议是使用SynchronousQueue这个队列，并且maxPoolSize尽量大一些；当使用有界队列的时候，corePoolSize设置的应该尽可能和maximumPoolSize相等，并且针对队列应该设置监控；还有可以根据任务特点来设置线程数。比如任务要是IO密集型线程池大小可以设置的大一些；要是CPU密集型设置小一点，可以简单设置为cpu ~ cpu *2。\")])]),e._v(\" \"),t(\"p\",[e._v(\"4.7. 为什么可以返回，FutrueTask的执行原理\")]),e._v(\" \"),t(\"ul\",[t(\"li\",[e._v(\"FutureTask中有一个全局变量state，通过这个值来界定任务是否已经执行完毕；\")]),e._v(\" \"),t(\"li\",[e._v(\"同时定义了线程执行的结果：outcome；\")]),e._v(\" \"),t(\"li\",[e._v(\"同时定义了用于保存由于调用Future.get方法而阻塞的线程的堆：WaitNode waiters；\")]),e._v(\" \"),t(\"li\",[e._v(\"主线程在新建完FutureTask后一直阻塞等待结果，任务线程负责执行任务，并将最后结果塞回到输出outcome字段，并通知等待线程，由于可以由多个线程阻塞等待，在内部实现中使用等待链表和LockSupport的park/unpark操作来进行不同线程之间的同步操作。\")]),e._v(\" \"),t(\"li\",[e._v(\"向线程池中提交任务的submit方法不是阻塞方法，而Future.get方法是一个阻塞方法，当submit提交多个任务时，只有所有任务都完成后，才能使用get按照任务的提交顺序得到返回结果，所以一般需要使用future.isDone先判断任务是否全部执行完成，完成后再使用future.get得到结果。（\")]),e._v(\" \"),t(\"li\",[e._v(\"也可以用get (long timeout, TimeUnit unit)方法可以设置超时时间，防止无限时间的等待） 三段式的编程：1.启动多线程任务2.处理其他事3.收集多线程任务结果，Future虽然可以实现获取异步执行结果的需求，但是它没有提供通知的机制，要么使用阻塞，在future.get()的地方等待future返回的结果，这时又变成同步操作；要么使用isDone()轮询地判断Future是否完成，这样会耗费CPU的资源。\")])]),e._v(\" \"),t(\"p\",[e._v(\"4.8. submit和executor区别\")]),e._v(\" \"),t(\"ul\",[t(\"li\",[e._v(\"execute和submit都属于线程池的方法，execute只能提交Runnable类型的任务，而submit既能提交Runnable类型任务也能提交Callable类型任务。\")]),e._v(\" \"),t(\"li\",[e._v(\"execute会直接抛出任务执行时的异常，submit会吃掉异常，可通过Future的get方法[会阻塞]将任务执行时的异常重新抛出。\")]),e._v(\" \"),t(\"li\",[e._v(\"execute所属顶层接口是Executor,submit所属顶层接口是ExecutorService，实现类ThreadPoolExecutor重写了execute方法,抽象类AbstractExecutorService重写了submit方法。\")]),e._v(\" \"),t(\"li\",[e._v(\"execute方法，适用于不需要关注返回值的场景，只需要将线程丢到线程池中去执行就可以了。而submit()方法，适用于需要关注返回值的场景，不过最终会调用execute()方法。考虑到性能提升，如果不需要关注返回值，则建议直接调用 execute() 方法，因为那样会屏蔽很多中间调度。submit和execute由于参数不同有四种实现形式，如下所示，本文主要研究这四种形式在各自使用场景下的区别和联系：\\n\"),t(\"ul\",[t(\"li\",[e._v(\"这种提交的方式会返回一个Future对象，这个Future对象代表这线程的执行结果，当主线程调用Future的get方法的时候会获取到从线程中返回的结果数据。如果在线程的执行过程中发生了异常，get会获取到异常的信息。\"),t(\"T\",[e._v(\" Future\"),t(\"T\",[e._v(\" submit(Callable\"),t(\"T\",[e._v(\" task);\")])],1)],1)],1),e._v(\" \"),t(\"li\",[e._v(\"当线程正常结束的时候调用Future的get方法会返回result对象，当线程抛出异常的时候会获取到对应的异常的信息。\"),t(\"T\",[e._v(\" Future\"),t(\"T\",[e._v(\" submit(Runnable task, T result);\")])],1)],1),e._v(\" \"),t(\"li\",[e._v(\"提交一个Runable接口的对象，这样当调用get方法的时候，如果线程执行成功会直接返回null，如果线程执行异常会返回异常的信息，Future<?> submit(Runnable task);\")]),e._v(\" \"),t(\"li\",[e._v(\"void execute(Runnable command);execute提交的方式只能提交一个Runnable的对象，且该方法的返回值是void，也即是提交后如果线程运行后，和主线程就脱离了关系了，当然可以设置一些变量来获取到线程的运行结果。并且当线程的执行过程中抛出了异常通常来说主线程也无法获取到异常的信息的，只有通过ThreadFactory主动设置线程的异常处理类才能感知到提交的线程中的异常信息。\")])])])]),e._v(\" \"),t(\"p\",[e._v(\"4.9. 线程池原理\")]),e._v(\" \"),t(\"ul\",[t(\"li\",[t(\"p\",[e._v(\"我们首先要了解的线程池里面的状态控制的参数 ctl，线程池的ctl是一个原子的 AtomicInteger。这个ctl包含两个参数 ：workerCount 激活的线程数；runState 当前线程池的状态，它的低29位用于存放当前的线程数, 因此一个线程池在理论上最大的线程数是 536870911（5亿多）; 高 3 位是用于表示当前线程池的状态, 其中高三位的值和状态对应如下:111: RUNNING；000: SHUTDOWN；001: STOP；010: TIDYING；110: TERMINATED。\")])]),e._v(\" \"),t(\"li\",[t(\"p\",[e._v(\"主流程：首先判断是否增加核心线程，添加完直接return；如果不是核心线程，则直接进入队列workQueue，然后再增加Worker（非核心的）。 Worker流程：Worker的核心逻辑是通过while循环+BlockingQueue的阻塞机制来实现对任务的执行，同时通过自身继承的AQS机制保证任务执行的线程安全。Worker是自我运行的，通过getTask()方法不断从队列中获取任务，addWork只是增加了处理问题的能力，而实际上的任务还是要从队列中获取。但是第一次执行AddWorker的时候会传入第一线程，其他时候不传递，因此Worker中的第一个任务不是从队列中获取的，可以直接执行。\")])]),e._v(\" \"),t(\"li\",[t(\"p\",[e._v(\"总结：线程池在内部实际上构建了一个生产者消费者模型，将线程和任务两者解耦，并不直接关联，从而良好的缓冲任务，复用线程。线程池的运行主要分成两部分：任务管理、线程管理。任务管理部分充当生产者的角色，当任务提交后，线程池会判断该任务后续的流转：直接申请线程执行该任务；缓冲到队列中等待线程执行；拒绝该任务。线程管理部分是消费者，它们被统一维护在线程池内，根据任务请求进行线程的分配，当线程执行完任务后则会继续获取新的任务去执行，最终当线程获取不到任务的时候，线程就会被回收。\")])]),e._v(\" \"),t(\"li\",[t(\"p\",[e._v(\"总结：在创建线程池后，等待提交过来的任务请求\")])]),e._v(\" \"),t(\"li\",[t(\"p\",[e._v(\"总结：当调用execute()方法添加一个请求任务时，线程池会做如下判断：如果正在运行的线程数量小于corePoolSize，那么马上创建线程运行这个任务；如果正在运行的线程数量大于或等于corePoolSize，那么将这个任务放入队列；如果这个时候队列满了且正在运行的线程数量还小于maximumPoolSize，那么创建非核心线程立刻运行这个任务；如果队列满了且正在运行的线程数量大于或等于maximumPoolSize，那么线程池会启动饱和拒绝策略来执行\")])]),e._v(\" \"),t(\"li\",[t(\"p\",[e._v(\"总结：当一个线程完成任务时，它会从队列中取下一个任务来执行\")])]),e._v(\" \"),t(\"li\",[t(\"p\",[e._v(\"总结：当一个线程无事可做超过一定的时间（keepAliveTime）时，线程池会判断：如果当前运行的线程数大于 corePoolSize，那么这个线程就被停掉；所以线程池的所有任务完成后它最终会收缩到 corePoolSize 的大小\")])])]),e._v(\" \"),t(\"p\",[e._v(\"4.10. 线程池怎么关闭知道吗？\")]),e._v(\" \"),t(\"ul\",[t(\"li\",[e._v(\"shutdown() 将线程池状态置为shutdown,并不会立即停止：停止接收外部submit的任务；内部正在跑的任务和队列里等待的任务，会执行完；等到第二步完成后，才真正停止\")]),e._v(\" \"),t(\"li\",[e._v(\"shutdownNow() 将线程池状态置为stop。一般会立即停止，事实上不一定：和shutdown()一样，先停止接收外部提交的任务；忽略队列里等待的任务；尝试将正在跑的任务interrupt中断；返回未执行的任务列表\")])]),e._v(\" \"),t(\"p\",[e._v(\"4.11. 常见的线程池的使用方式：\")]),e._v(\" \"),t(\"ul\",[t(\"li\",[e._v(\"newFixedThreadPool 创建一个指定工作线程数量的线程池：该方法返回一个固定线程数量的线程池。该线程池中的线程数量始终不变。当有一个新的任务提交时，线程池中若有空闲线程，则立即执行。若没有，则新的任务会被暂存在一个任务队列中，待有线程空闲时，便处理在任务队列中的任务。\")]),e._v(\" \"),t(\"li\",[e._v(\"newSingleThreadExecutor创建一个单线程化的Executor：方法返回一个只有一个线程的线程池。若多余一个任务被提交到该线程池，任务会被保存在一个任务队列中，待线程空闲，按先入先出的顺序执行队列中的任务。\")]),e._v(\" \"),t(\"li\",[e._v(\"newCachedThreadPool 创建一个可缓存线程池：该方法返回一个可根据实际情况调整线程数量的线程池。线程池的线程数量不确定，但若有空闲线程可以复用，则会优先使用可复用的线程。若所有线程均在工作，又有新的任务提交，则会创建新的线程处理任务。所有线程在当前任务执行完毕后，将返回线程池进行复用。\")]),e._v(\" \"),t(\"li\",[e._v(\"newScheduledThreadPool 创建一个定长的线程池，而且支持定时的以及周期性的任务执行，支持定时及周期性任务执行：通过这个线程池的名字可以看出,它支持定时或者周期性执行任务,实现这种功能的方法主要有三种: ScheduledExecutorService service = Executors.newScheduledThreadPool(10); service.schedule(new Task(), 10, TimeUnit.SECONDS); service.scheduleAtFixedRate(new Task(), 10, 10, TimeUnit.SECONDS); service.scheduleWithFixedDelay(new Task(), 10, 10, TimeUnit.SECONDS); 第一种是schedule,通过延迟指定时间后执行一次任务,代码中设置的是10秒,所以10秒后执行一次任务就结束.\")]),e._v(\" \"),t(\"li\",[e._v(\"newWorkStealingPool Java8 新特性，使用目前机器上可用的处理器作为它的并行级别\")])]),e._v(\" \"),t(\"p\",[e._v(\"4.12. 线程池其他问题\")]),e._v(\" \"),t(\"ul\",[t(\"li\",[e._v(\"此时线程数小于核心线程数，并且线程都处于空闲状态，现提交一个任务，是新起一个线程还是给之前创建的线程？此时线程池会新起一个线程来执行这个新任务，不管老线程是否空闲。\")]),e._v(\" \"),t(\"li\",[e._v(\"你可能会觉得核心线程在线程池里面会有特殊标记？并没有，不论是核心还是非核心线程，在线程池里面都是一视同仁，当淘汰的时候不会管是哪些线程，反正留下核心线程数个线程即可\")]),e._v(\" \"),t(\"li\",[e._v(\"你是怎么理解 KeepAliveTime 的？线程池其实想要的只是核心线程数个线程，但是又预留了一些数量来预防突发状况，当突发状况过去之后，线程池希望只维持核心线程数的线程，所以就弄了个 KeepAliveTime，当线程数大于核心数之后，如果线程空闲了一段时间（KeepAliveTime），就回收线程，直到数量与核心数持平。\")]),e._v(\" \"),t(\"li\",[e._v(\"线程池里的 ctl 是干嘛的？ctl 是一个涵盖了两个概念的原子整数类，它将工作线程数和线程池状态结合在一起维护，低 29 位存放 workerCount，高 3 位存放 runState。\")]),e._v(\" \"),t(\"li\",[e._v(\"你知道线程池有几种状态吗？RUNNING：能接受新任务，并处理阻塞队列中的任务；SHUTDOWN：不接受新任务，但是可以处理阻塞队列中的任务；STOP：不接受新任务，并且不处理阻塞队列中的任务，并且还打断正在运行任务的线程，就是直接撂担子不干了；TIDYING：所有任务都终止，并且工作线程也为0，处于关闭之前的状态；TERMINATED：已关闭。\")]),e._v(\" \"),t(\"li\",[e._v(\"为什么要把任务先放在任务队列里面，而不是把线程先拉满到最大线程数？线程池本意只是让核心数量的线程工作着，不论是 core 的取名，还是 keepalive 的设定，所以你可以直接把 core 的数量设为你想要线程池工作的线程数，而任务队列起到一个缓冲的作用。最大线程数这个参数更像是无奈之举，在最坏的情况下做最后的努力，去新建线程去帮助消化任务。\")]),e._v(\" \"),t(\"li\",[e._v(\"keepAliveTime=0会怎么样？在JDK1.8中，keepAliveTime=0表示非核心线程执行完立刻终止。默认情况下，keepAliveTime小于0，初始化的时候才会报错；但如果allowsCoreThreadTimeOut，keepAliveTime必须大于0，不然初始化报错。\")]),e._v(\" \"),t(\"li\",[e._v(\"当提交新任务时，异常如何处理?在任务代码try/catch捕获异常；通过Future对象的get方法接收抛出的异常，再处理；为工作者线程设置UncaughtExceptionHandler，在uncaughtException方法中处理异常；重写ThreadPoolExecutor的afterExecute方法，处理传递的异常引用\")])]),e._v(\" \"),t(\"p\",[e._v(\"5.0 ThreadLocal 是什么？有哪些使用场景？\")]),e._v(\" \"),t(\"ul\",[t(\"li\",[e._v(\"原理：线程局部变量是局限于线程内部的变量，属于线程自身所有，不在多个线程间共享。Java提供ThreadLocal类来支持线程局部变量，是一种实现线程安全的方式。但是在管理环境下（如 web 服务器）使用线程局部变量的时候要特别小心，在这种情况下，工作线程的生命周期比任何应用变量的生命周期都要长。任何线程局部变量一旦在工作完成后没有释放，Java 应用就存在内存泄露的风险。\")]),e._v(\" \"),t(\"li\",[e._v(\"hreadLocal造成内存泄漏的原因？：ThreadLocalMap 中使用的 key 为 ThreadLocal 的弱引用，而 value 是强引用。所以，如果 ThreadLocal 没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉。这样一来，ThreadLocalMap 中就会出现key为null的Entry。假如我们不做任何措施的话，value 永远无法被GC 回收，这个时候就可能会产生内存泄露。ThreadLocalMap实现中已经考虑了这种情况，在调用 set()、get()、remove() 方法的时候，会清理掉 key 为 null 的记录。使用完 ThreadLocal方法后 最好手动调用remove()方法\")]),e._v(\" \"),t(\"li\",[e._v(\"ThreadLocal内存泄漏解决方案？每次使用完ThreadLocal，都调用它的remove()方法，清除数据。\\n在使用线程池的情况下，没有及时清理ThreadLocal，不仅是内存泄漏的问题，更严重的是可能导致业务逻辑出现问题。所以，使用ThreadLocal就跟加锁完要解锁一样，用完就清理。\")]),e._v(\" \"),t(\"li\",[e._v(\"ThreadLocalMap的enrty的key为什么要设置成弱引用：将Entry的Key设置成弱引用，在配合线程池使用的情况下可能会有内存泄露的风险。之设计成弱引用的目的是为了更好地对ThreadLocal进行回收，当我们在代码中将ThreadLocal的强引用置为null后，这时候Entry中的ThreadLocal理应被回收了，但是如果Entry的key被设置成强引用则该ThreadLocal就不能被回收，这就是将其设置成弱引用的目的。\")])]),e._v(\" \"),t(\"p\",[e._v(\"5.1 能不能给我简单介绍一下 AtomicInteger 类的原理\")]),e._v(\" \"),t(\"ul\",[t(\"li\",[e._v(\"AtomicInteger 类主要利用 CAS (compare and swap) + volatile 和 native 方法来保证原子操作，从而避免 synchronized 的高开销，执行效率大为提升。\")]),e._v(\" \"),t(\"li\",[e._v(\"CAS的原理是拿期望的值和原本的一个值作比较，如果相同则更新成新的值。UnSafe 类的 objectFieldOffset() 方法是一个本地方法，这个方法是用来拿到“原来的值”的内存地址，返回值是 valueOffset。另外 value 是一个volatile变量，在内存中可见，因此 JVM 可以保证任何时刻任何线程总能拿到该变量的最新值。\")]),e._v(\" \"),t(\"li\",[e._v(\"大量的线程同时并发修改一个AtomicInteger，可能有很多线程会不停的自旋，进入一个无限重复的循环中。这些线程不停地获取值，然后发起CAS操作，但是发现这个值被别人改过了，于是再次进入下一个循环，获取值，发起CAS操作又失败了，再次进入下一个循环。在大量线程高并发更新AtomicInteger的时候，这种问题可能会比较明显，导致大量线程空循环，自旋转，性能和效率都不是特别好。于是，当当当当，Java 8推出了一个新的类，LongAdder，他就是尝试使用分段CAS以及自动分段迁移的方式来大幅度提升多线程高并发执行CAS操作的性能！\")])]),e._v(\" \"),t(\"p\",[e._v(\"6.0. synchronized 关键字和 volatile 关键字的区别\")]),e._v(\" \"),t(\"ul\",[t(\"li\",[e._v(\"volatile本质是在告诉jvm当前变量在寄存器（工作内存）中的值是不确定的，需要从主存中读取； synchronized则是锁定当前变量，只有当前线程可以访问该变量，其他线程被阻塞住。因为一个线程 A 修改了变量还没结束时，另外的线程 B 可以看到已修改的值，而且可以修改这个变量，而不用等待 A 释放锁，因为volatile变量没上锁。\")]),e._v(\" \"),t(\"li\",[e._v(\"volatile仅能使用在变量级别；synchronized则可以使用在变量、方法、和类级别的\")]),e._v(\" \"),t(\"li\",[e._v(\"volatile仅能实现变量的修改可见性，不能保证原子性；而synchronized则可以保证变量的修改可见性和原子性\")]),e._v(\" \"),t(\"li\",[e._v(\"volatile不会造成线程的阻塞；synchronized可能会造成线程的阻塞。\")]),e._v(\" \"),t(\"li\",[e._v(\"volatile标记的变量不会被编译器优化；synchronized标记的变量可以被编译器优化\")]),e._v(\" \"),t(\"li\",[e._v(\"volatile 表示变量在 CPU 的寄存器中是不确定的，必须从主存中读取。保证多线程环境下变量的可见性；禁止指令重排序。\")])]),e._v(\" \"),t(\"p\",[e._v(\"6.1. synchronized和Lock区别\")]),e._v(\" \"),t(\"ul\",[t(\"li\",[e._v(\"原始构成：synchronized 是关键字属于JVM 层面monitorenter(底层是通过monitor对象完成，其实 wait/notify等方法也依赖于monitor对象只有在同步代码块或方法中才能调wait/notify等方法)；Lock是具体类（java.util.concurrent.locks.Lock）是api 层面的锁\")]),e._v(\" \"),t(\"li\",[e._v(\"使用方法：synchronized 不需要用户手动释放锁，当 synchronized 代码执行完后系统会自动让线程释放对象锁的占用；RenntrantLock则需要用户去手动释放锁，若没有手动释放，可能造成死锁\")]),e._v(\" \"),t(\"li\",[e._v(\"等待是否可中断：synchronized 不可中断，除非抛出异常或正常运行结束；RenntrantLock可中断，设置超时时间 tryLock(long timeout,TimeUnit unit)lockIntteruptiby()放代码块中，调用interrupt() 方法可中断\")]),e._v(\" \"),t(\"li\",[e._v(\"加锁是否公平：synchronized 是非公平锁；RenntrantLock两者都可以，默认是非公平锁\")]),e._v(\" \"),t(\"li\",[e._v(\"锁绑定多个条件Condition；synchronized 没有，RenntrantLock用来实现分组唤醒需要唤醒的线程们，可以精准唤醒，而不是像synchronized那样随机唤醒一个线程要么唤醒全部线程。\")])]),e._v(\" \"),t(\"p\",[e._v(\"6.2. synchronized关键字与ReentrantLock区别\")]),e._v(\" \"),t(\"ul\",[t(\"li\",[t(\"p\",[e._v(\"可重入性：从名字上理解，ReenTrantLock的字面意思就是再进入的锁，其实synchronized关键字所使用的锁也是可重入的，两者关于这个的区别不大。两者都是同一个线程没进入一次，锁的计数器都自增1，所以要等到锁的计数器下降为0时才能释放锁。\")])]),e._v(\" \"),t(\"li\",[t(\"p\",[e._v(\"公平性：ReentrantLock提供了公平锁和非公平锁两种API，开发人员完全可以根据应用场景选择锁的公平性；synchronized是作为Java关键字是依赖于JVM实现，Java团队应该是优先考虑性能问题，因此synchronized是非公平锁。\")])]),e._v(\" \"),t(\"li\",[t(\"p\",[e._v(\"可中断的，Synchronized是不可中断的。ReentrantLock提供可中断和不可中断两种方式。其中lockInterruptibly方法表示可中断，lock方法表示不可中断。\")])]),e._v(\" \"),t(\"li\",[t(\"p\",[e._v(\"锁的实现：Synchronized是依赖于JVM实现的，而ReenTrantLock是JDK实现的，有什么区别，说白了就类似于操作系统来控制实现和用户自己敲代码实现的区别。前者的实现是比较难见到的，后者有直接的源码可供阅读。\")])]),e._v(\" \"),t(\"li\",[t(\"p\",[e._v(\"性能的区别：在Synchronized优化以前，synchronized的性能是比ReenTrantLock差很多的，但是自从Synchronized引入了偏向锁，轻量级锁（自旋锁）后，两者的性能就差不多了。在两种方法都可用的情况下，官方甚至建议使用synchronized，其实synchronized的优化我感觉就借鉴了ReenTrantLock中的CAS技术。都是试图在用户态就把加锁问题解决，避免进入内核态的线程阻塞。\")])]),e._v(\" \"),t(\"li\",[t(\"p\",[e._v(\"用法比较：Lock使用起来比较灵活，但是必须有释放锁的配合动作Lock必须手动获取与释放锁，而 synchronized不需要手动释放和开启锁Lock只适用于代码块锁，而 synchronized可用于修饰方法、代码块等\")])]),e._v(\" \"),t(\"li\",[t(\"p\",[e._v(\"功能区别：便利性：很明显Synchronized的使用比较方便简洁，并且由编译器去保证锁的加锁和释放，而ReenTrantLock需要手工声明来加锁和释放锁，为了避免忘记手工释放锁造成死锁，所以最好在finally中声明释放锁。锁的细粒度和灵活度：很明显ReenTrantLock优于Synchronized。ReenTrantLock独有的能力：\")]),e._v(\" \"),t(\"ul\",[t(\"li\",[e._v(\"ReenTrantLock可以指定是公平锁还是非公平锁。而synchronized只能是非公平锁。所谓的公平锁就是先等待的线程先获得锁。\")]),e._v(\" \"),t(\"li\",[e._v(\"ReenTrantLock提供了一个Condition（条件）类，用来实现分组唤醒需要唤醒的线程们，而不是像synchronized要么随机唤醒一个线程要么唤醒全部线程。\")]),e._v(\" \"),t(\"li\",[e._v(\"ReenTrantLock提供了一种能够中断等待锁的线程的机制，通过lock.lockInterruptibly()来实现这个机制。\")])])]),e._v(\" \"),t(\"li\",[t(\"p\",[e._v(\"Lock 是一个接口，而 synchronized 是 Java 中的关键字， synchronized 是内置的语言实现。\")])]),e._v(\" \"),t(\"li\",[t(\"p\",[e._v(\"synchronized 在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；而 Lock 在发生异常时，如果没有主动通过 unLock()去释放锁，则很可能造成死锁现象，因此使用 Lock 时需要在 finally 块中释放锁。\")])])]),e._v(\" \"),t(\"p\",[e._v(\"6.3. 锁对比\")]),e._v(\" \"),t(\"ul\",[t(\"li\",[e._v(\"synchronized关键字它的底层实现，是通过hotspot虚拟机内置实现的，在对某个共享资源进行加锁之后，只能允许一个线程进行访问，其他线程只能在对象锁上的等待池中进行等待，并且是不可中断，无休止等待下去，只有等持有锁的线程执行结束，会随机唤醒等待池中的某个线程去执行。所以synchronized所提供的是一个排它锁，可重入锁，非公平锁。synchronized在1.6之后就对锁的实现进行了优化，大部分情况下synchronized的性能还是可以的。\")]),e._v(\" \"),t(\"li\",[e._v(\"ReentrantLock 可重入锁，它的实现是AQS+CAS一段代码来实现的，CAS操作是通过unsafe提供的原子操作，来对状态进行更新，相较于synchronized提供的锁，ReentrantLock提供的锁，有了更细粒度的操作，比如可以知道当前线程是否获取到了锁，如果没有获取到锁，那么在多久之后，可以进行终止等待，避免了无休止的等到操作。ReentrantLock提供的锁是，排它锁，可重入的，可以是公平也可以使非公平 （公平锁相对于非公平锁会消耗一点性能，因为每次在尝试获取到锁的时候，都需要来计算是否要将线程放入等待队列中去）\")]),e._v(\" \"),t(\"li\",[e._v(\"ReentrantReadWriteLock 读写锁 ，实现方式也是AQS+CAS 代码实现，它的不同就是对于共享资源，如果我们只是读取的话，可以多个线程同时访问，如果对共享资源进行修改的话，同一时间只能有一个线程持有，当然如果有线程正在读取共享资源，写线程必须要进行等待，这一点也正是读写线程速度相对来说比较慢的一个原因，因为在实际场景当中，我们都是读多写少，但是在读的时候不能写，也就意味着写操作会一直阻塞直到所有读操作结束。\")]),e._v(\" \"),t(\"li\",[e._v(\"StampedLock 读写锁 由于我们大部分场景都是读多写少，JDK1.8提供了一个全新的读写锁，其实现方式是通过CAS+双向链表，他的特点就是提供了乐观读，乐观是相对于数据库中悲观锁和乐观锁而言的，在读取的时候，先不加锁，也不通过CAS去修改数据，当乐观锁失败后，转为悲观锁，进行加锁操作，而StampedLock最棒的地方就是乐观锁，即乐观读取，因为我们大部分时候是读多写少，就不需要通过CAS来修改状态，这样进一步提高了性能。StampedLock是不可重入的，但是其性能不会因为不可重入受影响。缺点是：使用时每个锁的获取和释放都基于票据，如果一不小心，代码逻辑或者票据错误很容易造成死锁\")]),e._v(\" \"),t(\"li\",[e._v(\"StampedLock 并不能完全代替ReentrantReadWriteLock ，在读多写少的场景下因为乐观读的模式，允许一个写线程获取写锁，解决了写线程饥饿问题，大大提高吞吐量。在使用乐观读的时候需要注意按照编程模型模板方式去编写，否则很容易造成死锁或者意想不到的线程安全问题。\")])])])}),[],!1,null,null,null);i.default=l.exports}}]);","extractedComments":[]}