{"code":"(window.webpackJsonp=window.webpackJsonp||[]).push([[270],{651:function(e,a,r){\"use strict\";r.r(a);var t=r(13),v=Object(t.a)({},(function(){var e=this,a=e.$createElement,r=e._self._c||a;return r(\"ContentSlotsDistributor\",{attrs:{\"slot-key\":e.$parent.slotKey}},[r(\"p\",[e._v(\"我在陌陌主要负责三块地法的内容：产品、游戏和活动\")]),e._v(\" \"),r(\"ul\",[r(\"li\",[r(\"p\",[e._v(\"产品包括：抽奖、转盘奖池、财富值、接龙\")])]),e._v(\" \"),r(\"li\",[r(\"p\",[e._v(\"游戏包括：飞机大战、套牛\")])]),e._v(\" \"),r(\"li\",[r(\"p\",[e._v(\"活动包括：惊喜夜晚抽奖、神龙、锦鲤、打怪兽、盛典、年报\")])])]),e._v(\" \"),r(\"p\",[e._v(\"其中收获最多的是，抽奖、飞机大战、惊喜夜晚抽奖\")]),e._v(\" \"),r(\"p\",[e._v(\"飞机大战：不能相应前端的任何数据、不能相信前端数据的顺序性，前端数据可能会多次发出\")]),e._v(\" \"),r(\"p\",[e._v(\"GC次数5000-100的过程\")]),e._v(\" \"),r(\"p\",[e._v(\"分布式限流全网更新数据奖池的金额，一发子弹10块，0.5进入奖池，更新全网数据，单机限流是没有意义的（分布式限流的两种方式：计数和令牌桶的方式）\")]),e._v(\" \"),r(\"p\",[e._v(\"两个人同时开宝箱，设置锁时间是1s，其中一个机器GC，线程停顿锁释放，另外一个加锁，review代码时候发现的这个问题，通过版本号进行再次重试\")]),e._v(\" \"),r(\"p\",[e._v(\"两个人同时去抢一个奖池的时候，更新数据有问题，分布式锁，但是GC的时候分布式锁会失效， 两个会同时怎么样\")]),e._v(\" \"),r(\"p\",[e._v(\"同一个奖池，把奖池拆分20个，利用分段锁提高并发\")]),e._v(\" \"),r(\"p\",[e._v(\"抽奖主要是在架构上设计\")]),e._v(\" \"),r(\"p\",[e._v(\"重构：\")]),e._v(\" \"),r(\"p\",[e._v(\"发奖提前拆包、非核心业务可降、统一代码风格\")]),e._v(\" \"),r(\"h3\",{attrs:{id:\"本抽奖不并发和并发问题解决\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#本抽奖不并发和并发问题解决\"}},[e._v(\"#\")]),e._v(\" 本抽奖不并发和并发问题解决\")]),e._v(\" \"),r(\"p\",[e._v(\"1、现在流程不存在并发问题：\")]),e._v(\" \"),r(\"p\",[e._v(\"用户经过风控、spam、权重计算之后加入到zset里边去，在倒计时5秒的时候，根据权重进行计算，取出相应的值，然后根据中奖的人数order by 其中相应的个数，更新数据库，告知所有中奖的用户，发钱；退款以相反的顺序order by就可以\")]),e._v(\" \"),r(\"p\",[e._v(\"2、并发抽奖问题：\")]),e._v(\" \"),r(\"p\",[e._v(\"1、提前拆包；2、可以对同一个红包进行加分布式锁（悲观的方式），所有的抢红包都变成穿行操作，更新成功的返回，不成功的也返回；3、同一个红包的抽奖用户哈希到同一个机器上去或者使用队列，也是同步处理的思路；4、每次更新都会查询order by，两个同时update同一个记录，必然有一个会失败，失败那个再次查询再次更新；如果会有饥饿问题，order by另一个方向，从另外一个方向更新数据；退钱在开完奖一分钟后左右进行\")]),e._v(\" \"),r(\"h3\",{attrs:{id:\"gc的总结\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#gc的总结\"}},[e._v(\"#\")]),e._v(\" GC的总结：\")]),e._v(\" \"),r(\"p\",[e._v(\"我们线上20台机器一上线就5000多次GC，明显次数不合理，然后我们就jmap -heap看了一下，发现newSize（一个S+一个E）才332M，但是我们线上的机器是4核8G的，所以肯定不是这些，应该在1365MB才对，然后我们就找到了JVM的这个bug，这个bug是，在JDK6的时候，newRatio这个默认参数会失效，然后是在jdk7的时候fix了，但是我们用的是8，而且我们在我们内网的机器上是32核128G，发现内网的机器分配内存就是1365M，然后就找了，JDK8和9存在的一个问题，就是默认newRatio参数不指定的时候会采用GC算法（）计算，ScaleForWordSize(young_gen_per_worker * parallel_gc_threads) ，具体算法是64M * 32 * 13 / 10 ＝ 2662.4M，内网算出来是2662M，采用最小的也就是正常的了，\")]),e._v(\" \"),r(\"p\",[e._v(\"官方推家的解决方案是：显示的用newRatio参数，或者不用CMS\")]),e._v(\" \"),r(\"h3\",{attrs:{id:\"线程池参数总结\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#线程池参数总结\"}},[e._v(\"#\")]),e._v(\" 线程池参数总结：\")]),e._v(\" \"),r(\"p\",[e._v(\"项目在多线程优化kafka消费的时候就采用了这种方式，如果请求大于所设置的最大队列的线程数据，则退化为当前主线程单线程处理，而不是默认的抛弃或者抛出异常\")]),e._v(\" \"),r(\"ol\",[r(\"li\",[r(\"p\",[e._v(\"corePoolSize：线程池的基本大小。当提交一个任务到线程池时，线程池会创建一个线程来执行任务，即使有其它空闲的线程，直到线程数达到corePoolSize时就不再创建，这时会把提交的新任务放到阻塞队列。如果调用了线程池的prestartAllCoreThreads()方法，线程池会提前创建并启动所有基本线程。\")])]),e._v(\" \"),r(\"li\",[r(\"p\",[e._v(\"maximumPoolSize：线程池允许创建的最大线程数。如果阻塞队列满了，并且已经创建的线程数小于最大线程数，则线程池会再创建新的线程执行任务。\")])]),e._v(\" \"),r(\"li\",[r(\"p\",[e._v(\"keepAliveTime：线程活动保持时间。指工作线程空闲后，继续保持存活的时间。默认情况下，这个参数只有在线程数大于corePoolSize时才起作用。所以，如果任务很多，且每个任务的执行时间比较短，可以调大keepAliveTime，提高线程的利用率。\")])])]),e._v(\" \"),r(\"p\",[e._v(\"4.时间单位\")]),e._v(\" \"),r(\"ol\",{attrs:{start:\"5\"}},[r(\"li\",[e._v(\"workQueue：用来保存等待执行的任务的阻塞队列。\\n－ ArrayBlockingQueue：基于数组结构的有界阻塞队列，按FIFO原则对元素进行排序。\\n－ LinkedBlockingQuene：基于链表结构的阻塞队列，按FIFO排序元素，吞吐量通常要高于ArrayBlockingQuene。\\n－ SynchronousQuene：一个不存储元素的阻塞队列，每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于LinkedBlockingQuene。\\n－ priorityBlockingQuene：具有优先级的无界阻塞队列。\")])]),e._v(\" \"),r(\"ul\",[r(\"li\",[e._v(\"DelayedWorkQueue\")])]),e._v(\" \"),r(\"p\",[e._v(\"PriorityBlockingQueue的數據結構是數組表示的最小堆，入隊時不會造成阻塞，當隊列中元素已滿時會拋出OutOfMemoryError異常。\")]),e._v(\" \"),r(\"p\",[e._v(\"DelayedWorkQueue是ScheduledThreadPoolExecutor的靜態內部類，其原理和DelayQueue基本一致。DelayQueue叫做延遲隊列，隊列中的元素必須是Delayed的實現類，隊列中的元素不但會按照延遲時間delay進行排序，且只有等待元素的延遲時間delay到期後才能出隊。\")]),e._v(\" \"),r(\"ol\",{attrs:{start:\"6\"}},[r(\"li\",[e._v(\"rejectedExecutionHandler：饱和策略。当阻塞队列满了且没有空闲的工作线程，说明线程池处于饱和状态，那么必须采取一种策略处理提交的新任务。这个策略在默认情况下是AbortPolicy，表示无法处理新任务时抛出异常。不过，线程池提供了4种策略：\\n－ AbortPolicy：直接抛出异常。（默认的是抛出异常，这就是我们不能用默认参数的原因）\\n－ CallerRunsPolicy：只用调用者所在的线程来运行任务。（使用当前线程退化为单线程处理）\\n－ DiscardOldestPolicy：丢弃阻塞队列中最近的一个任务，并执行当前任务。（丢弃最老的线程）\\n－ DiscardPolicy：直接丢弃。\")])]),e._v(\" \"),r(\"p\",[e._v(\"Exectors是java线程池的工厂类，通过它可以快速初始化一个符合业务需求的线程池，主要提供了以下几种便捷的方式：\")]),e._v(\" \"),r(\"p\",[e._v(\"1.newFixedThreadPool\")]),e._v(\" \"),r(\"div\",{staticClass:\"language- line-numbers-mode\"},[r(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[r(\"code\",[e._v(\"public static ExecutorService newFixedThreadPool(int nThreads) {\\n        return new ThreadPoolExecutor(nThreads, nThreads,\\n                                      0L, TimeUnit.MILLISECONDS,\\n                                      new LinkedBlockingQueue<Runnable>());\\n    }\\n\\n\")])]),e._v(\" \"),r(\"div\",{staticClass:\"line-numbers-wrapper\"},[r(\"span\",{staticClass:\"line-number\"},[e._v(\"1\")]),r(\"br\"),r(\"span\",{staticClass:\"line-number\"},[e._v(\"2\")]),r(\"br\"),r(\"span\",{staticClass:\"line-number\"},[e._v(\"3\")]),r(\"br\"),r(\"span\",{staticClass:\"line-number\"},[e._v(\"4\")]),r(\"br\"),r(\"span\",{staticClass:\"line-number\"},[e._v(\"5\")]),r(\"br\"),r(\"span\",{staticClass:\"line-number\"},[e._v(\"6\")]),r(\"br\")])]),r(\"p\",[e._v(\"2.newSingleThreadExecutor\")]),e._v(\" \"),r(\"div\",{staticClass:\"language- line-numbers-mode\"},[r(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[r(\"code\",[e._v(\"public static ExecutorService newSingleThreadExecutor() {\\n        return new FinalizableDelegatedExecutorService\\n            (new ThreadPoolExecutor(1, 1,\\n                                    0L, TimeUnit.MILLISECONDS,\\n                                    new LinkedBlockingQueue<Runnable>()));\\n    }\\n\")])]),e._v(\" \"),r(\"div\",{staticClass:\"line-numbers-wrapper\"},[r(\"span\",{staticClass:\"line-number\"},[e._v(\"1\")]),r(\"br\"),r(\"span\",{staticClass:\"line-number\"},[e._v(\"2\")]),r(\"br\"),r(\"span\",{staticClass:\"line-number\"},[e._v(\"3\")]),r(\"br\"),r(\"span\",{staticClass:\"line-number\"},[e._v(\"4\")]),r(\"br\"),r(\"span\",{staticClass:\"line-number\"},[e._v(\"5\")]),r(\"br\"),r(\"span\",{staticClass:\"line-number\"},[e._v(\"6\")]),r(\"br\")])]),r(\"p\",[e._v(\"3.newCachedThreadPool\")]),e._v(\" \"),r(\"div\",{staticClass:\"language- line-numbers-mode\"},[r(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[r(\"code\",[e._v(\"public static ExecutorService newCachedThreadPool() {\\n        return new ThreadPoolExecutor(0, Integer.MAX_VALUE,\\n                                      60L, TimeUnit.SECONDS,\\n                                      new SynchronousQueue<Runnable>());\\n    }\\n\")])]),e._v(\" \"),r(\"div\",{staticClass:\"line-numbers-wrapper\"},[r(\"span\",{staticClass:\"line-number\"},[e._v(\"1\")]),r(\"br\"),r(\"span\",{staticClass:\"line-number\"},[e._v(\"2\")]),r(\"br\"),r(\"span\",{staticClass:\"line-number\"},[e._v(\"3\")]),r(\"br\"),r(\"span\",{staticClass:\"line-number\"},[e._v(\"4\")]),r(\"br\"),r(\"span\",{staticClass:\"line-number\"},[e._v(\"5\")]),r(\"br\")])]),r(\"p\",[e._v(\"4.newScheduledThreadPool  ScheduledThreadPoolExecutor DelayedWorkQueue()\")]),e._v(\" \"),r(\"div\",{staticClass:\"language- line-numbers-mode\"},[r(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[r(\"code\",[e._v(\"    public ScheduledThreadPoolExecutor(int corePoolSize) {\\n        super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS,\\n              new DelayedWorkQueue());\\n    }\\n\")])]),e._v(\" \"),r(\"div\",{staticClass:\"line-numbers-wrapper\"},[r(\"span\",{staticClass:\"line-number\"},[e._v(\"1\")]),r(\"br\"),r(\"span\",{staticClass:\"line-number\"},[e._v(\"2\")]),r(\"br\"),r(\"span\",{staticClass:\"line-number\"},[e._v(\"3\")]),r(\"br\"),r(\"span\",{staticClass:\"line-number\"},[e._v(\"4\")]),r(\"br\")])]),r(\"h3\",{attrs:{id:\"kafka优化思路总结\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#kafka优化思路总结\"}},[e._v(\"#\")]),e._v(\" kafka优化思路总结\")]),e._v(\" \"),r(\"p\",[e._v(\"先对kafka过来的数据，会有很多不同的数据，你只需要取用自己需要的数据，不需要的数据直接返回提交就可以了，对于需要业务处理的数据，看看是不是要做一个聚合处理，聚合完成之后多线程处理，但是这里要考虑一个问题，你的代码多线程处理的时候有没有查改，一查一改的的情况就会出问题，如果有的话就必须做好幂等或者并发处理。最后一步就异步处理，kafka的数据其实都是可以异步处理的。\")]),e._v(\" \"),r(\"h3\",{attrs:{id:\"抽奖迁移库\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#抽奖迁移库\"}},[e._v(\"#\")]),e._v(\" 抽奖迁移库\")]),e._v(\" \"),r(\"p\",[e._v(\"我先说一下为什么要做分库分表这么一个处理，分库的目的其实就是提高并发写的能力，分表的目的是为了提高查询的效率，可以根据自己的业务情况来决定，是分库的情况多还是分表的情况多；\")]),e._v(\" \"),r(\"p\",[e._v(\"迁移的过程总的来说就是双写，整个过程是这样的，我们先用测试号在内网进行双写，然后验证数据，然后上线，只把测试号的入口打开写入新的库，然后迁移测试号的老数据，然后验证数据，验证完成之后，再把正式号的入口打开，再把旧的正式号的数据再迁移到新的库中\")]),e._v(\" \"),r(\"h3\",{attrs:{id:\"项目中的分布式锁\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#项目中的分布式锁\"}},[e._v(\"#\")]),e._v(\" 项目中的分布式锁\")]),e._v(\" \"),r(\"p\",[e._v(\"项目中的分布式锁采用的是redis的方案，设置key，设置成功了之后再设置一个过期时间，但是这块有一个明显的问题，就是redis的key设置成功了，如果设置过期时间失败了，这个锁就永久锁住了，这里其实可以采用\")]),e._v(\" \"),r(\"p\",[e._v(\"优化：\")]),e._v(\" \"),r(\"ul\",[r(\"li\",[e._v(\"报警\")]),e._v(\" \"),r(\"li\",[e._v(\"如果时间设置失败，直接删除已经设置成功的key\")]),e._v(\" \"),r(\"li\",[e._v(\"采用SET ex（单位是秒） XX（不存在的时候）模式，一个语句\")]),e._v(\" \"),r(\"li\",[e._v(\"直接使用zk的创建临时节点的方案，如果时间到了就会自动删除\\n\"),r(\"blockquote\",[r(\"p\",[e._v(\"判断刚刚建立的子节点顺序号是否是最小的节点，假如是最小节点，则获得该锁对资源进行访问。假如不是该节点，就获得该节点的上一顺序节点，并给该节点是否存在注册监听事件。同时在这里阻塞。等待监听事件的发生，获得锁控制权。 线程阻塞，监听的是上一个节点。\")])])])]),e._v(\" \"),r(\"h3\",{attrs:{id:\"飞机遇到的问题\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#飞机遇到的问题\"}},[e._v(\"#\")]),e._v(\" 飞机遇到的问题\")]),e._v(\" \"),r(\"p\",[e._v(\"1、请求不是顺序的，以故障为例\")]),e._v(\" \"),r(\"ul\",[r(\"li\",[e._v(\"幂等处理，每一次都会拉一个数据\")])]),e._v(\" \"),r(\"p\",[e._v(\"2、永远不要相信前端的任何一个参数\")]),e._v(\" \"),r(\"ul\",[r(\"li\",[e._v(\"通过幂等和接口对数据进行管理，幂等同一个数据不能多次请求，等级切换，轮次切换以及节点切换\")])]),e._v(\" \"),r(\"p\",[e._v(\"3、数据一致性的处理，多个人去抢一个奖池\")]),e._v(\" \"),r(\"ul\",[r(\"li\",[e._v(\"分布式锁，GC分布式锁失效，以时间为版本号解决\")])]),e._v(\" \"),r(\"p\",[e._v(\"4、流量控制\")]),e._v(\" \"),r(\"ul\",[r(\"li\",[e._v(\"分布式限流\")])]),e._v(\" \"),r(\"p\",[e._v(\"5、结算\")]),e._v(\" \"),r(\"ul\",[r(\"li\",[e._v(\"各种拆分\")])]),e._v(\" \"),r(\"h3\",{attrs:{id:\"限流以及分布式限流\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#限流以及分布式限流\"}},[e._v(\"#\")]),e._v(\" 限流以及分布式限流\")]),e._v(\" \"),r(\"p\",[e._v(\"抽奖：一个对上的限流，抽奖1000个名额，当参与抽奖的用户到达1000个时候，所有的用户都会进入参与的池子，但是不会进入奖池进行权重计算，计算风控、敏感词以及权重最后的计算可以根据尾号进行控制。两层限流，第一是纯的流量，第二当用池子到达1000的时候是尾号进行数据耗时的服务操作\")]),e._v(\" \"),r(\"p\",[e._v(\"飞机大战：有一个是对下的限流，下游服务最多接受1s一个请求，而每次更新奖池一秒可能有几百次会对下游服务有压力，单机限流会有数据限限不住的情况，所以下边的服务必须用分布式的方式进行限流\")]),e._v(\" \"),r(\"p\",[e._v(\"单机限流采用的是谷歌的RateLimiter\")]),e._v(\" \"),r(\"p\",[e._v(\"分布式采用的是redis的方式，1s然后10个的话，初始的时候设置过期时间，然后incr到达10个之后，就不再放行了，这其实是一种计数的方式（注意这是计数器的方式），另外一种是桶的方式\")]),e._v(\" \"),r(\"p\",[e._v(\"两种的介绍：\")]),e._v(\" \"),r(\"ul\",[r(\"li\",[r(\"p\",[e._v(\"漏桶算法：请求先进入“桶”中，然后桶以一定的速率处理请求。如果请求的速率过快会导致桶溢出。根据描述可以知道，漏桶算法会强制限制请求处理的速度。任你请求的再快还是再慢，我都是以这种速率来处理。 但是对于很多情况下，除了要求能够限制平均处理速度外，还要求能允许一定程度的的突发情况。这样的话，漏桶算法就不合适了，用令牌桶算法更合适。\")])]),e._v(\" \"),r(\"li\",[r(\"p\",[e._v(\"令牌桶算法的原理是：系统以恒定的速率往桶里丢一定数量的令牌，请求只有拿到了令牌才能处理。当桶里没有令牌时便可拒绝服务。RateLimiter实现的令牌桶算法，不仅可以应对正常流量的限速，而且可以处理突发暴增的请求，实现平滑限流。\")])])]),e._v(\" \"),r(\"h4\",{attrs:{id:\"ratelimiter原理\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#ratelimiter原理\"}},[e._v(\"#\")]),e._v(\" RateLimiter原理\")]),e._v(\" \"),r(\"p\",[e._v(\"两种模式：\")]),e._v(\" \"),r(\"p\",[e._v(\"1、稳定模式，SmoothBursty，令牌生成的速度恒定。\")]),e._v(\" \"),r(\"p\",[e._v(\"2、预热模式，SmoothWarmingUp，令牌生成速度缓慢提升直到维持在一个稳定值。比如在系统刚启动的时候，第一次访问的接口需要加载缓存等等，这时系统的处理速度较慢，就需要这种模式\")]),e._v(\" \"),r(\"p\",[e._v(\"令牌桶算法比较有意思：\")]),e._v(\" \"),r(\"p\",[e._v(\"https://blog.csdn.net/u014730658/article/details/79374356\")]),e._v(\" \"),r(\"p\",[e._v(\"根据令牌桶算法，桶中的令牌是持续生成存放的，有请求时需要先从桶中拿到令牌才能开始执行，谁来持续生成令牌存放呢？\")]),e._v(\" \"),r(\"p\",[e._v(\"一种解法是，开启一个定时任务，由定时任务持续生成令牌。这样的问题在于会极大的消耗系统资源，如，某接口需要分别对每个用户做访问频率限制，假设系统中存在6W用户，则至多需要开启6W个定时任务来维持每个桶中的令牌数，这样的开销是巨大的。\")]),e._v(\" \"),r(\"p\",[e._v(\"另一种解法则是延迟计算，如上resync函数。该函数会在每次获取令牌之前调用，其实现思路为，若当前时间晚于nextFreeTicketMicros，则计算该段时间内可以生成多少令牌，将生成的令牌加入令牌桶中并更新数据。这样一来，只需要在获取令牌时计算一次即可。\")]),e._v(\" \"),r(\"p\",[e._v(\"核心思路：RateLimiter不需要记住上个请求的时间,它只需要记住“希望下个请求到来的时间”即可。这样使得我们能够马上识别出，一个确切的超时时间（跟tryAcquire(timeout)相关）是否满足下一个计划时间点。 如果当前时间大于“期望的下个请求到来的时间”，那么这两个时间的差值就是Ratelimiter的未使用时间t，通过t*QPS计算出storedPermits。\")]),e._v(\" \"),r(\"h3\",{attrs:{id:\"synchronized和reentrantlock的区别\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#synchronized和reentrantlock的区别\"}},[e._v(\"#\")]),e._v(\" synchronized和ReentrantLock的区别\")]),e._v(\" \"),r(\"p\",[e._v(\"https://github.com/txxs/interview/blob/master/interview/%E8%BF%9B%E7%A8%8B%E7%BA%BF%E7%A8%8B%E7%9B%B8%E5%85%B3.md\")]),e._v(\" \"),r(\"p\",[e._v(\"1、synchronized不是公平锁，不是依靠队列实现的；ReentrantLock可以实现公平锁，但是需要指定，默认是非公平的\")]),e._v(\" \"),r(\"p\",[e._v(\"2、synchronized底层是通过JVM实现的，每一个非空对象都是一个锁， 当执行 monitorenter 指令时，线程试图获取锁也就是获取 monitor(monitor对象存在于每个Java对象的对象头中，synchronized 锁便是通过这种方式获取锁的，也是为什么Java中任意对象可以作为锁的原因)的持有权。当计数器为0则可以成功获取，获取后将锁计数器设为1也就是加1。相应的在执行monitorexit指令后，将锁计数器设为0，表明锁被释放。如果获取对象锁失败，那当前线程就要阻塞等待，直到锁被另外一个线程释放为止。\")]),e._v(\" \"),r(\"p\",[e._v(\"ReentrantLock是通过AQS实现的，AQS的底层又是依赖于CLH队列实现的，AQS核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。CLH(Craig,Landin,and Hagersten)队列是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系）。AQS是将每条请求共享资源的线程封装成一个CLH锁队列的一个结点（Node）来实现锁的分配。AQS使用一个int成员变量来表示同步状态，通过内置的FIFO队列来完成获取资源线程的排队工作。AQS使用CAS对该同步状态进行原子操作实现对其值的修改。\")]),e._v(\" \"),r(\"p\",[e._v(\"3、性能其实两者差不多：guava cache源码中在创建新元素的时候就使用的synchronized锁，synchronized在底层做了各种各样的优化：\")]),e._v(\" \"),r(\"p\",[e._v(\"①偏向锁：轻量级锁在无竞争的情况下使用 CAS 操作去代替使用互斥量。而偏向锁在无竞争的情况下会把整个同步都消除掉。\")]),e._v(\" \"),r(\"p\",[e._v(\"② 轻量级锁\")]),e._v(\" \"),r(\"p\",[e._v(\"③ 自旋锁和自适应自旋：轻量级锁失败后，虚拟机为了避免线程真实地在操作系统层面挂起，还会进行一项称为自旋锁的优化手段。另外,在 JDK1.6中引入了自适应的自旋锁。自适应的自旋锁带来的改进就是：自旋的时间不在固定了，而是和前一次同一个锁上的自旋时间以及锁的拥有者的状态来决定，虚拟机变得越来越“聪明”了。\")]),e._v(\" \"),r(\"p\",[e._v(\"④ 锁消除：锁消除理解起来很简单，它指的就是虚拟机即使编译器在运行时，如果检测到那些共享数据不可能存在竞争，那么就执行锁消除。锁消除可以节省毫无意义的请求锁的时间。\")]),e._v(\" \"),r(\"p\",[e._v(\"⑤ 锁粗化：原则上，我们在编写代码的时候，总是推荐将同步块的作用范围限制得尽量小，——直在共享数据的实际作用域才进行同步，这样是为了使得需要同步的操作数量尽可能变小，如果存在锁竞争，那等待线程也能尽快拿到锁。\")]),e._v(\" \"),r(\"p\",[e._v(\"4、两者都是可以重入的\")]),e._v(\" \"),r(\"p\",[e._v(\"5、ReentrantLock 比 synchronized 增加了一些高级功能\")]),e._v(\" \"),r(\"h3\",{attrs:{id:\"kafka是如何扩容的\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#kafka是如何扩容的\"}},[e._v(\"#\")]),e._v(\" kafka是如何扩容的\")]),e._v(\" \"),r(\"p\",[e._v(\"payorder 由原来的60分区，增加到120个分区，下游服务重启，重启注册\")]),e._v(\" \"),r(\"p\",[e._v(\"kafka集群扩容后，新的broker上面不会数据进入这些节点，也就是说，这些节点是空闲的；它只有在创建新的topic时才会参与工作。除非将已有的partition迁移到新的服务器上面；\\n所以需要将一些topic的分区迁移到新的broker上。下游服务为了增加消费的数量，不至于阻塞。\")]),e._v(\" \"),r(\"ol\",[r(\"li\",[r(\"p\",[e._v(\"新建Kafka 节点\")])]),e._v(\" \"),r(\"li\",[r(\"p\",[e._v(\"创建要迁移的Topic 列表（在已有的Topic 上增加分区）\")])]),e._v(\" \"),r(\"li\",[r(\"p\",[e._v(\"生成Topic 分区分配表\")])]),e._v(\" \"),r(\"li\",[r(\"p\",[e._v(\"执行迁移操作\")])])]),e._v(\" \"),r(\"p\",[e._v(\"对比：\")]),e._v(\" \"),r(\"p\",[e._v(\"https://github.com/txxs/interview/blob/master/mq/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E6%9C%89%E4%BB%80%E4%B9%88%E4%BC%98%E7%82%B9%E5%92%8C%E7%BC%BA%E7%82%B9%E4%BB%A5%E5%8F%8A%E5%90%84%E4%B8%AA%E5%AF%B9%E6%AF%94.md\")]),e._v(\" \"),r(\"p\",[e._v(\"高可用、延迟地、量大\")]),e._v(\" \"),r(\"h3\",{attrs:{id:\"kafka如何保证可靠性传输\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#kafka如何保证可靠性传输\"}},[e._v(\"#\")]),e._v(\" kafka如何保证可靠性传输\")]),e._v(\" \"),r(\"p\",[e._v(\"1、生产者会不会弄丢数据？\")]),e._v(\" \"),r(\"p\",[e._v(\"如果按照上述的思路设置了acks=all，一定不会丢，要求是，你的leader接收到消息，所有的follower都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试，重试无限次。\")]),e._v(\" \"),r(\"p\",[e._v(\"2、消费者丢数据\")]),e._v(\" \"),r(\"p\",[e._v(\"唯一可能导致消费者弄丢数据的情况，就是说，你消费到了这个消息，然后消费者那边自动提交了offset，让Kafka以为你已经消费好了这个消息，但其实你才刚准备处理这个消息，你还没处理，你自己就挂了，此时这条消息就丢咯。大家都知道 Kafka 会自动提交 offset，那么只要关闭自动提交offset，在处理完之后自己手动提交offset，就可以保证数据不会丢。\")]),e._v(\" \"),r(\"p\",[e._v(\"3、kafka自己丢数据\")]),e._v(\" \"),r(\"p\",[e._v(\"就是 Kafka 某个 broker 宕机，然后重新选举 partition 的 leader。大家想想，要是此时其他的 follower 刚好还有些数据没有同步，结果此时 leader 挂了，然后选举某个 follower 成 leader 之后，不就少了一些数据？这就丢了一些数据啊。\")]),e._v(\" \"),r(\"ul\",[r(\"li\",[e._v(\"给 topic 设置 replication.factor 参数：这个值必须大于 1，要求每个 partition 必须有至少 2 个副本。\")]),e._v(\" \"),r(\"li\",[e._v(\"在 Kafka 服务端设置 min.insync.replicas 参数：这个值必须大于 1，这个是要求一个 leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队，这样才能确保 leader 挂了还有一个 follower 吧。\")]),e._v(\" \"),r(\"li\",[e._v(\"在 producer 端设置 acks=all：这个是要求每条数据，必须是写入所有 replica 之后，才能认为是写成功了。\")]),e._v(\" \"),r(\"li\",[e._v(\"在 producer 端设置 retries=MAX（很大很大很大的一个值，无限次重试的意思）：这个是要求一旦写入失败，就无限重试，卡在这里了。\")])]),e._v(\" \"),r(\"h3\",{attrs:{id:\"mysql-整型长度的含义\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#mysql-整型长度的含义\"}},[e._v(\"#\")]),e._v(\" MySQL 整型长度的含义\")]),e._v(\" \"),r(\"p\",[e._v(\"https://www.jianshu.com/p/61293b416335\")]),e._v(\" \"),r(\"p\",[e._v(\"这里指定的 int(11) 是指的显示宽度, 跟数据的存储和计算没有影响( ZEROFILL 除外 ). 如果数字宽度小于指定跨度, 左边补充空格显示, 否则原样显示( ZEROFILL 除外 ). int 显示宽度的默认值是有符号的 int 的最小负数的长度, 也就是 11 位.不论是int(3)还是int(11)，它在数据库里面存储的都是4个字节的长度，在使用int(3)的时候如果你输入的是10，会默认给你存储位010,也就是说这个3代表的是默认的一个长度，当你不足3位时，会帮你不全，当你超过3位时，就没有任何的影响。\")]),e._v(\" \"),r(\"h3\",{attrs:{id:\"mysql中char与varchar的区别\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#mysql中char与varchar的区别\"}},[e._v(\"#\")]),e._v(\" mysql中char与varchar的区别：\")]),e._v(\" \"),r(\"p\",[e._v(\"char：定长，效率高，一般用于固定长度的表单提交数据存储  ；例如：身份证号，手机号，电话，密码等\")]),e._v(\" \"),r(\"p\",[e._v(\"varchar：不定长，效率偏低\")]),e._v(\" \"),r(\"h3\",{attrs:{id:\"读写分离思想\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#读写分离思想\"}},[e._v(\"#\")]),e._v(\" 读写分离思想\")]),e._v(\" \"),r(\"p\",[e._v(\"MVCC\")]),e._v(\" \"),r(\"p\",[e._v(\"CopyOnWriteArrayList\")]),e._v(\" \"),r(\"p\",[e._v(\"https://blog.csdn.net/maoyeqiu/article/details/97180347\")])])}),[],!1,null,null,null);a.default=v.exports}}]);","extractedComments":[]}