{"code":"(window.webpackJsonp=window.webpackJsonp||[]).push([[201],{584:function(a,t,r){\"use strict\";r.r(t);var s=r(13),o=Object(s.a)({},(function(){var a=this,t=a.$createElement,r=a._self._c||t;return r(\"ContentSlotsDistributor\",{attrs:{\"slot-key\":a.$parent.slotKey}},[r(\"h3\",{attrs:{id:\"消费模型\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#消费模型\"}},[a._v(\"#\")]),a._v(\" 消费模型\")]),a._v(\" \"),r(\"p\",[a._v(\"消息由生产者发布到Kafka集群后，会被消费者消费。消息的消费模型有两种：推送模型（push）和拉取模型（pull）。\")]),a._v(\" \"),r(\"p\",[a._v(\"基于推送模型（push）的消息系统，由消息代理记录消费者的消费状态。消息代理在将消息推送到消费者后，标记这条消息为已消费，但这种方式无法很好地保证消息被处理。比如，消息代理把消息发送出去后，当消费进程挂掉或者由于网络原因没有收到这条消息时，就有可能造成消息丢失（因为消息代理已经把这条消息标记为已消费了，但实际上这条消息并没有被实际处理）。如果要保证消息被处理，消息代理发送完消息后，要设置状态为“已发送”，只有收到消费者的确认请求后才更新为“已消费”，这就需要消息代理中记录所有的消费状态，这种做法显然是不可取的。\")]),a._v(\" \"),r(\"p\",[a._v(\"Kafka采用拉取模型，由消费者自己记录消费状态，每个消费者互相独立地顺序读取每个分区的消息。如下图所示，有两个消费者（不同消费者组）拉取同一个主题的消息，消费者A的消费进度是3，消费者B的消费进度是6。消费者拉取的最大上限通过最高水位（watermark）控制，生产者最新写入的消息如果还没有达到备份数量，对消费者是不可见的。这种由消费者控制偏移量的优点是：消费者可以按照任意的顺序消费消息。比如，消费者可以重置到旧的偏移量，重新处理之前已经消费过的消息；或者直接跳到最近的位置，从当前的时刻开始消费。\")]),a._v(\" \"),r(\"h4\",{attrs:{id:\"两者对比\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#两者对比\"}},[a._v(\"#\")]),a._v(\" 两者对比\")]),a._v(\" \"),r(\"p\",[a._v(\"push（推）模式很难适应消费速率不同的消费者，因为消息发送速率是由broker决定的。它的目标是尽可能以最快速度传递消息，但是这样很容易造成consumer来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。而pull模式则可以根据consumer的消费能力以适当的速率消费消息。\")]),a._v(\" \"),r(\"p\",[a._v(\"对于Kafka而言，pull模式更合适，它可简化broker的设计，consumer可自主控制消费消息的速率，同时consumer可以自己控制消费方式——即可批量消费也可逐条消费，同时还能选择不同的提交方式从而实现不同的传输语义。\")]),a._v(\" \"),r(\"p\",[a._v(\"pull模式不足之处是，如果kafka没有数据，消费者可能会陷入循环中，一直等待数据到达。为了避免这种情况，我们在我们的拉请求中有参数，允许消费者请求在等待数据到达的“长轮询”中进行阻塞（并且可选地等待到给定的字节数，以确保大的传输大小）。\")]),a._v(\" \"),r(\"p\",[r(\"img\",{attrs:{src:\"https://img-blog.csdnimg.cn/20191023170959677.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L21hb3llcWl1,size_16,color_FFFFFF,t_70\",alt:\"在这里插入图片描述\"}})]),a._v(\" \"),r(\"h3\",{attrs:{id:\"消费组\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#消费组\"}},[a._v(\"#\")]),a._v(\" 消费组\")]),a._v(\" \"),r(\"p\",[a._v(\"消费者是以consumer group消费者组的方式工作，由一个或者多个消费者组成一个组，共同消费一个topic。每个分区在同一时间只能由group中的一个消费者读取，但是多个group可以同时消费这个partition。在下图中，有一个由三个消费者组成的group，有一个消费者读取主题中的两个分区，另外两个分别读取一个分区。某个消费者读取某个分区，也可以叫做某个消费者是某个分区的拥有者。在这种情况下，消费者可以通过水平扩展的方式同时读取大量的消息。另外，如果一个消费者失败了，那么其他的group成员会自动负载均衡读取之前失败的消费者读取的分区。\\n\"),r(\"img\",{attrs:{src:\"https://img-blog.csdnimg.cn/2019102317101549.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L21hb3llcWl1,size_16,color_FFFFFF,t_70\",alt:\"在这里插入图片描述\"}})]),a._v(\" \"),r(\"h3\",{attrs:{id:\"消费组与分区重平衡\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#消费组与分区重平衡\"}},[a._v(\"#\")]),a._v(\" 消费组与分区重平衡\")]),a._v(\" \"),r(\"p\",[a._v(\"可以看到，当新的消费者加入消费组，它会消费一个或多个分区，而这些分区之前是由其他消费者负责的；另外，当消费者离开消费组（比如重启、宕机等）时，它所消费的分区会分配给其他分区。这种现象称为重平衡（rebalance）。重平衡是Kafka一个很重要的性质，这个性质保证了高可用和水平扩展。不过也需要注意到，在重平衡期间，所有消费者都不能消费消息，因此会造成整个消费组短暂的不可用。而且，将分区进行重平衡也会导致原来的消费者状态过期，从而导致消费者需要重新更新状态，这段期间也会降低消费性能。后面我们会讨论如何安全的进行重平衡以及如何尽可能避免。\")]),a._v(\" \"),r(\"p\",[a._v(\"消费者通过定期发送心跳（hearbeat）到一个作为组协调者（group coordinator）的broker来保持在消费组内存活。这个broker不是固定的，每个消费组都可能不同。当消费者拉取消息或者提交时，便会发送心跳。\")]),a._v(\" \"),r(\"p\",[a._v(\"如果消费者超过一定时间没有发送心跳，那么它的会话（session）就会过期，组协调者会认为该消费者已经宕机，然后触发重平衡。可以看到，从消费者宕机到会话过期是有一定时间的，这段时间内该消费者的分区都不能进行消息消费；通常情况下，我们可以进行优雅关闭，这样消费者会发送离开的消息到组协调者，这样组协调者可以立即进行重平衡而不需要等待会话过期。\")]),a._v(\" \"),r(\"p\",[a._v(\"在0.10.1版本，Kafka对心跳机制进行了修改，将发送心跳与拉取消息进行分离，这样使得发送心跳的频率不受拉取的频率影响。另外更高版本的Kafka支持配置一个消费者多长时间不拉取消息但仍然保持存活，这个配置可以避免活锁（livelock）。活锁，是指应用没有故障但是由于某些原因不能进一步消费。\")]),a._v(\" \"),r(\"h3\",{attrs:{id:\"消费者处理offset\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#消费者处理offset\"}},[a._v(\"#\")]),a._v(\" 消费者处理offset\")]),a._v(\" \"),r(\"p\",[a._v(\"消费数据的API和处理方式很简单，我们只需要循环不断拉取消息即可。Kafka对外暴露了一个非常简洁的poll方法，其内部实现了协作、分区重平衡、心跳、数据拉取等功能，但使用时这些细节都被隐藏了，我们也不需要关注这些。\")]),a._v(\" \"),r(\"p\",[a._v(\"当我们调用poll()时，该方法会返回我们没有消费的消息。当消息从broker返回消费者时，broker并不跟踪这些消息是否被消费者接收到；Kafka让消费者自身来管理消费的位移，并向消费者提供更新位移的接口，这种更新位移方式称为提交（commit）。\")]),a._v(\" \"),r(\"p\",[a._v(\"在正常情况下，消费者会发送分区的提交信息到Kafka，Kafka进行记录。当消费者宕机或者新消费者加入时，Kafka会进行重平衡，这会导致消费者负责之前并不属于它的分区。重平衡完成后，消费者会重新获取分区的位移。\")]),a._v(\" \"),r(\"h4\",{attrs:{id:\"自动提交\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#自动提交\"}},[a._v(\"#\")]),a._v(\" 自动提交\")]),a._v(\" \"),r(\"p\",[a._v(\"这种方式让消费者来管理位移，应用本身不需要显式操作。当我们将enable.auto.commit设置为true，那么消费者会在poll方法调用后每隔5秒（由auto.commit.interval.ms指定）提交一次位移。和很多其他操作一样，自动提交也是由poll()方法来驱动的；在调用poll()时，消费者判断是否到达提交时间，如果是则提交上一次poll返回的最大位移。需要注意到，这种方式可能会导致消息重复消费。假如，某个消费者poll消息后，应用正在处理消息，在3秒后Kafka进行了重平衡，那么由于没有更新位移导致重平衡后这部分消息重复消费。\")]),a._v(\" \"),r(\"h4\",{attrs:{id:\"手动提交\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#手动提交\"}},[a._v(\"#\")]),a._v(\" 手动提交\")]),a._v(\" \"),r(\"p\",[a._v(\"为了减少消息重复消费或者避免消息丢失，很多应用选择自己主动提交位移。设置auto.commit.offset为false，那么应用需要自己通过调用commitSync()来主动提交位移，该方法会提交poll返回的最后位移。为了避免消息丢失，我们应当在完成业务逻辑后才提交位移。而如果在处理消息时发生了重平衡，那么只有当前poll的消息会重复消费。\")]),a._v(\" \"),r(\"h4\",{attrs:{id:\"异步提交\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#异步提交\"}},[a._v(\"#\")]),a._v(\" 异步提交\")]),a._v(\" \"),r(\"p\",[a._v(\"手动提交有一个缺点，那就是当发起提交调用时应用会阻塞。当然我们可以减少手动提交的频率，但这个会增加消息重复的概率（和自动提交一样）。另外一个解决办法是，使用异步提交的API。但是异步提交也有个缺点，那就是如果服务器返回提交失败，异步提交不会进行重试。相比较起来，同步提交会进行重试直到成功或者最后抛出异常给应用。异步提交没有实现重试是因为，如果同时存在多个异步提交，进行重试可能会导致位移覆盖。举个例子，假如我们发起了一个异步提交commitA，此时的提交位移为2000，随后又发起了一个异步提交commitB且位移为3000；commitA提交失败但commitB提交成功，此时commitA进行重试并成功的话，会将实际上将已经提交的位移从3000回滚到2000，导致消息重复消费。\")]),a._v(\" \"),r(\"h4\",{attrs:{id:\"提交特定位移\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#提交特定位移\"}},[a._v(\"#\")]),a._v(\" 提交特定位移\")]),a._v(\" \"),r(\"p\",[a._v(\"commitSync()和commitAsync()会提交上一次poll()的最大位移，但如果poll()返回了批量消息，而且消息数量非常多，我们可能会希望在处理这些批量消息过程中提交位移，以免重平衡导致从头开始消费和处理。幸运的是，commitSync()和commitAsync()允许我们指定特定的位移参数，参数为一个分区与位移的map。\")]),a._v(\" \"),r(\"h4\",{attrs:{id:\"从指定位移开始消费\"}},[r(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#从指定位移开始消费\"}},[a._v(\"#\")]),a._v(\" 从指定位移开始消费\")]),a._v(\" \"),r(\"p\",[a._v(\"在此之前，我们使用poll()来从最后的提交位移开始消费，但我们也可以从一个指定的位移开始消费。如果想从分区开始端重新开始消费，那么可以使用seekToBeginning(TopicPartition tp)；如果想从分区的最末端消费最新的消息，那么可以使用seekToEnd(TopicPartition tp)。而且，Kafka还支持我们从指定位移开始消费。从指定位移开始消费的应用场景有很多，其中最典型的一个是：位移存在其他系统（例如数据库）中，并且以其他系统的位移为准。\")]),a._v(\" \"),r(\"p\",[a._v(\"参考地址：\")]),a._v(\" \"),r(\"p\",[a._v(\"https://blog.csdn.net/qq_35641192/article/details/80956244\")]),a._v(\" \"),r(\"p\",[a._v(\"http://www.dengshenyu.com/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/2017/11/14/kafka-consumer.html\")])])}),[],!1,null,null,null);t.default=o.exports}}]);","extractedComments":[]}