{"code":"(window.webpackJsonp=window.webpackJsonp||[]).push([[201],{581:function(a,t,s){\"use strict\";s.r(t);var e=s(13),r=Object(e.a)({},(function(){var a=this,t=a.$createElement,s=a._self._c||t;return s(\"ContentSlotsDistributor\",{attrs:{\"slot-key\":a.$parent.slotKey}},[s(\"p\",[a._v(\"原文地址：\")]),a._v(\" \"),s(\"p\",[a._v(\"https://www.itcodemonkey.com/article/6858.html；https://mp.weixin.qq.com/s?__biz=MzIxMjAzMDA1MQ==&mid=2648945468&idx=1&sn=b622788361b384e152080b60e5ea69a7#rd\")]),a._v(\" \"),s(\"h3\",{attrs:{id:\"顺序io-写入\"}},[s(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#顺序io-写入\"}},[a._v(\"#\")]),a._v(\" 顺序IO（写入）\")]),a._v(\" \"),s(\"p\",[a._v(\"首先，Kafka使用了顺序IO（Sequential IO），并极力避免随机磁盘访问（Random Disk Access）。前者的写入速度比后者快了一个数量级，比如在一个由6块7200转SATA硬盘组成的磁盘阵列上，顺序写入的速度可以达到300MB/S，而随机写入速度只有50KB/S。差距如此之大，难怪Kafka会快得飞起来。\")]),a._v(\" \"),s(\"p\",[a._v(\"Kafka所采用的提交日志就是以追加的方式写入分区的，就是说单个分区的写入是可以保证顺序的，没有删除和更新操作，因此避免了随机写入。另外，从分区读取数据的时候也是按顺序读取的，避免了随机读取。\")]),a._v(\" \"),s(\"p\",[s(\"img\",{attrs:{src:\"https://txxs.github.io/pic/tofuturekafka/13-1.png\",alt:\"1\"}})]),a._v(\" \"),s(\"p\",[a._v(\"那么问题来了，就算顺序IO再快，也快不过内存，那么为什么Kafka不用内存来保存数据呢？第一个原因大概所有人都知道，内存虽快，但比硬盘要贵得多。Kafka作为一个大数据生态系统的一员，是为保存海量数据而生的，使用内存来保存海量数据显然是不现实的。另外，Kafka的高可用是通过创建多个副本来实现的，一个消息可能会被复制三份五份，这无疑又增加了存储开销，使用内存来存储就更是天方夜谭。除此之外，Kafka运行在JVM上，如果内存堆中的对象太多，必然会在垃圾回收时造成严重的延迟，从而影响系统的整体性能。\")]),a._v(\" \"),s(\"h3\",{attrs:{id:\"内存映射文件-写入\"}},[s(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#内存映射文件-写入\"}},[a._v(\"#\")]),a._v(\" 内存映射文件（写入）\")]),a._v(\" \"),s(\"p\",[a._v(\"即便是顺序写入硬盘，硬盘的访问速度还是不可能追上内存。所以Kafka的数据并不是实时的写入硬盘，它充分利用了现代操作系统分页存储来利用内存提高I/O效率。内存映射文件将磁盘上的文件内容与内存映射起来，我们往内存里写入数据，操作系统会在稍后把数据冲刷到磁盘上。所以，在写入数据时几乎就是写入内存的速度，这是Kafka快到飞起的另一个原因。那么问题又来了，既然可以使用内存映射文件，那么为什么不直接使用内存呢？这个问题已经回答过了，就不再累述了。\")]),a._v(\" \"),s(\"p\",[a._v(\"Memory Mapped Files(后面简称mmap)也被翻译成内存映射文件，在64位操作系统中一般可以表示20G的数据文件，它的工作原理是直接利用操作系统的Page来实现文件到物理内存的直接映射。完成映射之后你对物理内存的操作会被同步到硬盘上（操作系统在适当的时候）。\")]),a._v(\" \"),s(\"p\",[a._v(\"通过mmap，进程像读写硬盘一样读写内存（当然是虚拟机内存），也不必关心内存的大小有虚拟内存为我们兜底。使用这种方式可以获取很大的I/O提升，省去了用户空间到内核空间复制的开销（调用文件的read会把数据先放到内核空间的内存中，然后再复制到用户空间的内存中。）也有一个很明显的缺陷——不可靠，写到mmap中的数据并没有被真正的写到硬盘，操作系统会在程序主动调用flush的时候才把数据真正的写到硬盘。Kafka提供了一个参数——producer.type来控制是不是主动flush，如果Kafka写入到mmap之后就立即flush然后再返回Producer叫同步(sync)；写入mmap之后立即返回Producer不调用flush叫异步(async)。mmap其实是Linux中的一个函数就是用来实现内存映射的，谢谢Java NIO，它给我提供了一个mappedbytebuffer类可以用来实现内存映射（所以是沾了Java的光才可以如此神速和Scala没关系！！）\")]),a._v(\" \"),s(\"h3\",{attrs:{id:\"零拷贝-读取\"}},[s(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#零拷贝-读取\"}},[a._v(\"#\")]),a._v(\" 零拷贝（读取）\")]),a._v(\" \"),s(\"p\",[a._v(\"当Kafka客户端从服务器读取数据时，如果不使用零拷贝技术，那么大致需要经历这样的一个过程：\")]),a._v(\" \"),s(\"p\",[a._v(\"1、操作系统将数据从磁盘上读入到内核空间的读缓冲区中。\")]),a._v(\" \"),s(\"p\",[a._v(\"2、应用程序（也就是Kafka）从内核空间的读缓冲区将数据拷贝到用户空间的缓冲区中。\")]),a._v(\" \"),s(\"p\",[a._v(\"3、应用程序将数据从用户空间的缓冲区再写回到内核空间的socket缓冲区中。\")]),a._v(\" \"),s(\"p\",[a._v(\"4、操作系统将socket缓冲区中的数据拷贝到NIC缓冲区中，然后通过网络发送给客户端。\")]),a._v(\" \"),s(\"p\",[s(\"img\",{attrs:{src:\"https://txxs.github.io/pic/tofuturekafka/13-2.png\",alt:\"1\"}})]),a._v(\" \"),s(\"p\",[a._v(\"从图中可以看到，数据在内核空间和用户空间之间穿梭了两次，那么能否避免这个多余的过程呢？当然可以，Kafka使用了零拷贝技术，也就是直接将数据从内核空间的读缓冲区直接拷贝到内核空间的socket缓冲区，然后再写入到NIC缓冲区，避免了在内核空间和用户空间之间穿梭。\")]),a._v(\" \"),s(\"p\",[s(\"img\",{attrs:{src:\"https://txxs.github.io/pic/tofuturekafka/13-3.png\",alt:\"1\"}})]),a._v(\" \"),s(\"p\",[a._v(\"可见，这里的零拷贝并非指一次拷贝都没有，而是避免了在内核空间和用户空间之间的拷贝。如果真是一次拷贝都没有，那么数据发给客户端就没了不是？不过，光是省下了这一步就可以带来性能上的极大提升。\")]),a._v(\" \"),s(\"h3\",{attrs:{id:\"应用层面的优化-读取\"}},[s(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#应用层面的优化-读取\"}},[a._v(\"#\")]),a._v(\" 应用层面的优化（读取）\")]),a._v(\" \"),s(\"p\",[a._v(\"除了利用底层的技术外，Kafka还在应用程序层面提供了一些手段来提升性能。最明显的就是使用批次。在向Kafka写入数据时，可以启用批次写入，这样可以避免在网络上频繁传输单个消息带来的延迟和带宽开销。假设网络带宽为10MB/S，一次性传输10MB的消息比传输1KB的消息10000万次显然要快得多。\")]),a._v(\" \"),s(\"h3\",{attrs:{id:\"支持压缩-读取\"}},[s(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#支持压缩-读取\"}},[a._v(\"#\")]),a._v(\" 支持压缩（读取）\")])])}),[],!1,null,null,null);t.default=r.exports}}]);","extractedComments":[]}