{"code":"(window.webpackJsonp=window.webpackJsonp||[]).push([[67],{449:function(s,t,h){\"use strict\";h.r(t);var a=h(13),v=Object(a.a)({},(function(){var s=this,t=s.$createElement,h=s._self._c||t;return h(\"ContentSlotsDistributor\",{attrs:{\"slot-key\":s.$parent.slotKey}},[h(\"p\",[s._v(\"原文地址\")]),s._v(\" \"),h(\"p\",[s._v(\"https://www.cnblogs.com/myseries/p/10959050.html\")]),s._v(\" \"),h(\"p\",[s._v(\"https://www.cnblogs.com/abc-begin/p/8203613.html\")]),s._v(\" \"),h(\"p\",[s._v(\"https://www.cnblogs.com/study-everyday/p/8629100.html\")]),s._v(\" \"),h(\"h3\",{attrs:{id:\"简单的hash算法\"}},[h(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#简单的hash算法\"}},[s._v(\"#\")]),s._v(\" 简单的Hash算法\")]),s._v(\" \"),h(\"p\",[s._v(\"hash 算法（大量缓存重建）,这种算法就是简单的取模，没有拓展性，没有优化的必要，是把数据mod后直接映射到真实节点上面，这造成节点个数和数据的紧密关联、后期缺乏灵活扩展。\")]),s._v(\" \"),h(\"h3\",{attrs:{id:\"一致性哈希算法\"}},[h(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#一致性哈希算法\"}},[s._v(\"#\")]),s._v(\" 一致性哈希算法\")]),s._v(\" \"),h(\"p\",[s._v(\"一致性 hash 算法（自动缓存迁移）+ 虚拟节点--多增加一层虚拟映射层，数据与虚拟节点映射、虚拟节点与真实节点再映射，一致性哈希的ketama算法实现在扩容或down的情况下，需要重新计算节点，这对之前的分配可能会有一些影响。所以可以引入hash slot的方式，即某些hash slot区间对应一台机器，对于扩容或down机情况下，就改变某个hash slot区间就可以了，改动比较小，对之前分配的影响也较小。\")]),s._v(\" \"),h(\"p\",[s._v(\"做成一个圆环，解决命中率问题。\")]),s._v(\" \"),h(\"p\",[s._v(\"一致性 hash 算法将整个 hash 值空间组织成一个虚拟的圆环，整个空间按顺时针方向组织，下一步将各个 master 节点（使用服务器的 ip 或主机名）进行 hash。这样就能确定每个节点在其哈希环上的位置。\")]),s._v(\" \"),h(\"p\",[s._v(\"来了一个 key，首先计算 hash 值，并确定此数据在环上的位置，从此位置沿环顺时针“行走”，遇到的第一个 master 节点就是 key 所在位置。\")]),s._v(\" \"),h(\"p\",[s._v(\"在一致性哈希算法中，如果一个节点挂了，受影响的数据仅仅是此节点到环空间前一个节点（沿着逆时针方向行走遇到的第一个节点）之间的数据，其它不受影响。增加一个节点也同理。\")]),s._v(\" \"),h(\"p\",[s._v(\"然而，一致性哈希算法在节点太少时，容易因为节点分布不均匀而造成缓存热点的问题。为了解决这种热点问题，一致性 hash 算法引入了虚拟节点机制，即对每一个节点计算多个 hash，每个计算结果位置都放置一个虚拟节点。这样就实现了数据的均匀分布，负载均衡。一致性hash算法更详细的请看这篇：一致性Hash算法\")]),s._v(\" \"),h(\"h3\",{attrs:{id:\"hash-slot-虚拟桶\"}},[h(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#hash-slot-虚拟桶\"}},[s._v(\"#\")]),s._v(\" Hash slot（虚拟桶）\")]),s._v(\" \"),h(\"p\",[s._v(\"redis cluster 的 hash slot 算法，重点了解一下这个算法\\n\"),h(\"strong\",[s._v(\"缓存的key hash结果是和slot绑定的，而不是和服务器节点绑定，所以节点的更替只需要迁移slot即可平滑过渡\")])]),s._v(\" \"),h(\"p\",[s._v(\"redis cluster 有固定的 16384 个 hash slot，对每个 key 计算 CRC16 值，然后对 16384 取模，可以获取 key 对应的 hash slot。\"),h(\"strong\",[s._v(\"每个节点负责维护一部分槽以及槽所映射的键值数据。\")])]),s._v(\" \"),h(\"p\",[s._v(\"redis cluster 中每个 master 都会持有部分 slot，比如有 3 个 master，那么可能每个 master 持有 5000 多个 hash slot。hash slot 让 node 的增加和移除很简单，增加一个 master，就将其他 master 的 hash slot 移动部分过去，减少一个 master，就将它的 hash slot 移动到其他 master 上去。移动 hash slot 的成本是非常低的。客户端的 api，可以对指定的数据，让他们走同一个 hash slot，通过 hash tag 来实现。\")]),s._v(\" \"),h(\"p\",[s._v(\"Redis Cluster 采用虚拟槽分区，所有的键根据哈希函数映射到 0~16383 整数槽内，计算公式：slot = CRC16（key）& 16384。每个节点负责维护一部分槽以及槽所映射的键值数据\")]),s._v(\" \"),h(\"p\",[s._v(\"当前集群有 5 个节点，每个节点平均大约负责 3276 个槽。由于采用高质量的哈希算法，每个槽所映射的数据通常比较均匀，将数据平均划分到 5 个节点进行数据分区。Redis Cluster 就是采用虚拟槽分区。\")]),s._v(\" \"),h(\"p\",[s._v(\"节点1： 包含 0 到 3276 号哈希槽。\")]),s._v(\" \"),h(\"p\",[s._v(\"节点2：包含 3277 到 6553 号哈希槽。\")]),s._v(\" \"),h(\"p\",[s._v(\"节点3：包含 6554 到 9830 号哈希槽。\")]),s._v(\" \"),h(\"p\",[s._v(\"节点4：包含 9831 到 13107 号哈希槽。\")]),s._v(\" \"),h(\"p\",[s._v(\"节点5：包含 13108 到 16383 号哈希槽。\")]),s._v(\" \"),h(\"p\",[s._v(\"所以hash slot的好处是可以像磁盘分区一样自由分配槽位，在配置文件里可以指定，也可以让redis自己选择分配，结果均匀。\")]),s._v(\" \"),h(\"p\",[s._v(\"这种结构很容易添加或者删除节点。如果增加一个节点 6，就需要从节点 1 ~ 5 获得部分槽分配到节点 6 上。如果想移除节点 1，需要将节点 1 中的槽移到节点 2 ~ 5 上，然后将没有任何槽的节点 1 从集群中移除即可。\")]),s._v(\" \"),h(\"p\",[s._v(\"由于从一个节点将哈希槽移动到另一个节点并不会停止服务，所以无论添加删除或者改变某个节点的哈希槽的数量都不会造成集群不可用的状态.\")])])}),[],!1,null,null,null);t.default=v.exports}}]);","extractedComments":[]}